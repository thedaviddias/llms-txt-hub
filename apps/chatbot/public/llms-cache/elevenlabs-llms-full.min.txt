# ElevenLabs
> ElevenLabs is an AI audio research and deployment company.
{/* Light mode wave */}
<div id="overview-wave">
<ElevenLabsWaveform color="blue" />
</div>
{/* Dark mode wave */}
<div id="overview-wave">
<ElevenLabsWaveform color="gray" />
</div>
## Most popular
<CardGroup>
<Card title="Developer quickstart" href="/docs/quickstart">
Learn how to integrate ElevenLabs
</Card>
<Card title="Conversational AI" href="/docs/conversational-ai/overview">
Deploy voice agents in minutes
</Card>
<Card title="Product guides" href="/docs/product-guides/overview">
Learn how to use ElevenLabs
</Card>
<Card title="API reference" href="/docs/api-reference/introduction">
Dive into our API reference
</Card>
</CardGroup>
## Meet the models
<CardGroup cols={2} rows={2}>
<Card title="Eleven Multilingual v2" href="/docs/models#multilingual-v2">
Our most lifelike, emotionally rich speech synthesis model
<div>
<div>
Most natural-sounding output
</div>
<div>
29 languages supported
</div>
<div>
10,000 character limit
</div>
<div>
Rich emotional expression
</div>
</div>
</Card>
<Card title="Eleven Flash v2.5" href="/docs/models#flash-v25">
Our fast, affordable speech synthesis model
<div>
<div>
Ultra-low latency (~75ms†)
</div>
<div>
32 languages supported
</div>
<div>
40,000 character limit
</div>
<div>
Faster model, 50% lower price per character
</div>
</div>
</Card>
</CardGroup>
<CardGroup cols={1} rows={1}>
<Card title="Scribe v1" href="/docs/models#scribe-v1">
State-of-the-art speech recognition model
<div>
<div>
Accurate transcription in 99 languages
</div>
<div>
Precise word-level timestamps
</div>
<div>
Speaker diarization
</div>
<div>
Dynamic audio tagging
</div>
</div>
</Card>
</CardGroup>
<div>
<div>
[Explore all](/docs/models)
</div>
</div>
## Capabilities
<CardGroup cols={2}>
<Card href="/docs/capabilities/text-to-speech">
<div>
<div>
<div>
Text to Speech
</div>
<p>
Convert text into lifelike speech
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/speech-to-text">
<div>
<div>
<div>
Speech to Text
</div>
<p>
Transcribe spoken audio into text
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/voice-changer">
<div>
<div>
<div>
Voice changer
</div>
<p>
Modify and transform voices
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/voice-isolator">
<div>
<div>
<div>
Voice isolator
</div>
<p>
Isolate voices from background noise
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/dubbing">
<div>
<div>
<div>
Dubbing
</div>
<p>
Dub audio and videos seamlessly
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/sound-effects">
<div>
<div>
<div>
Sound effects
</div>
<p>
Create cinematic sound effects
</p>
</div>
</div>
</Card>
<Card href="/docs/capabilities/voices">
<div>
<div>
<div>
Voices
</div>
<p>
Clone and design custom voices
</p>
</div>
</div>
</Card>
<Card href="/docs/conversational-ai/overview">
<div>
<div>
<div>
Conversational AI
</div>
<p>
Deploy intelligent voice agents
</p>
</div>
</div>
</Card>
</CardGroup>
## Product guides
<CardGroup cols={1}>
<Card href="/docs/product-guides/overview">
<div>
<div>
<div>
Product guides
</div>
<p>
Explore our product guides for step-by-step guidance
</p>
</div>
<div>
<img src="file:239135e2-5ad7-4521-a303-986b1b83c538" alt="Voice library" />
</div>
</div>
</Card>
</CardGroup>
<small>
† Excluding application & network latency
</small>
# Developer quickstart
> Learn how to make your first ElevenLabs API request.
The ElevenLabs API provides a simple interface to state-of-the-art audio [models](/docs/models) and [features](/docs/api-reference/introduction). Follow this guide to learn how to create lifelike speech, generate and modify voices, produce immersive sound effects, isolate background noise from audio, and seamlessly dub audio/videos.
## Create an API key
[Create an API key in the dashboard here](https://elevenlabs.io/app/settings/api-keys), which you’ll use to securely [access the API](/docs/api-reference/authentication).
Store the key as a managed secret and pass it to the SDKs either as a environment variable via an `.env` file, or directly in your app’s configuration depending on your preference.
```js title=".env"
ELEVENLABS_API_KEY = 'your_api_key_here';
```
## Make your first request
You can either use the [REST API](/docs/api-reference/introduction) directly with the HTTP client of your choice, or use one of our official SDKs as shown below. This guide will use the official SDKs to make requests.
<Tabs>
<Tab title="Python" language="python">
```bash
pip install elevenlabs
```
</Tab>
<Tab title="JavaScript" language="javascript">
```bash
npm install elevenlabs
```
</Tab>
</Tabs>
<Note>
To play the audio through your speakers, you may be prompted to install [MPV](https://mpv.io/)
and/or [ffmpeg](https://ffmpeg.org/).
</Note>
<Tabs>
<Tab title="Python" language="python">
The environment variables are loaded automatically when using the SDK, but we need to install the `python-dotenv` package to load them.
```bash title="Install python-dotenv"
pip install python-dotenv
```
With the ElevenLabs SDK installed, create a file called `example.py` and copy one of the following examples into it:
<Tabs>
<Tab title="Text to Speech">
```python Convert text into life-like audio
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs import play
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
audio = client.text_to_speech.convert(
text="The first move is what sets everything in motion.",
voice_id="JBFqnCBsd6RMkjVDRZzb",
model_id="eleven_multilingual_v2",
output_format="mp3_44100_128",
)
play(audio)
```
</Tab>
<Tab title="Speech to Text">
```python Convert spoken audio into text
from dotenv import load_dotenv
from io import BytesIO
import requests
from elevenlabs.client import ElevenLabs
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
audio_url = (
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
)
response = requests.get(audio_url)
audio_data = BytesIO(response.content)
transcription = client.speech_to_text.convert(
file=audio_data,
model_id="scribe_v1",
)
print(transcription)
```
</Tab>
<Tab title="Voice changer">
```python Transform audio from one voice to another
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs import play
import requests
from io import BytesIO
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
voice_id = "JBFqnCBsd6RMkjVDRZzb"
audio_url = (
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
)
response = requests.get(audio_url)
audio_data = BytesIO(response.content)
audio_stream = client.speech_to_speech.convert(
voice_id=voice_id,
audio=audio_data,
model_id="eleven_multilingual_sts_v2",
output_format="mp3_44100_128",
)
play(audio_stream)
```
</Tab>
<Tab title="Sound effects">
```python Convert text into sound effects
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs import play
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
audio = client.text_to_sound_effects.convert(text="Cinematic Braam, Horror")
play(audio)
```
</Tab>
<Tab title="Voice isolator">
```python Removes background noise from audio.
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs import play
import requests
from io import BytesIO
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
audio_url = "https://storage.googleapis.com/eleven-public-cdn/audio/marketing/fin.mp3"
response = requests.get(audio_url)
audio_data = BytesIO(response.content)
audio_stream = client.audio_isolation.audio_isolation(audio=audio_data)
play(audio_stream)
```
</Tab>
<Tab title="Voice design">
```python Generate voices from a single text prompt.
from dotenv import load_dotenv
import base64
from elevenlabs.client import ElevenLabs
from elevenlabs import play
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
voices = client.text_to_voice.create_previews(
voice_description="A sassy squeaky mouse",
text="Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted.",
)
voice_preview = voices.previews[0].audio_base_64
audio_bytes = base64.b64decode(voice_preview)
play(audio_bytes)
```
</Tab>
<Tab title="Dubbing">
```python Dub audio/video from one language to another
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from elevenlabs import play
import requests
from io import BytesIO
import time
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
target_lang = "es"  # Spanish
audio_url = (
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
)
response = requests.get(audio_url)
audio_data = BytesIO(response.content)
audio_data.name = "audio.mp3"
# Start dubbing
dubbed = client.dubbing.dub_a_video_or_an_audio_file(
file=audio_data, target_lang=target_lang
)
while True:
status = client.dubbing.get_dubbing_project_metadata(dubbed.dubbing_id).status
if status == "dubbed":
dubbed_file = client.dubbing.get_dubbed_file(dubbed.dubbing_id, target_lang)
play(dubbed_file)
break
else:
print("Audio is still being dubbed...")
time.sleep(5)
```
</Tab>
</Tabs>
Execute the code with the command below. Within a few seconds you should hear the audio play through your speaker.
```bash title="Run the script"
python example.py
```
</Tab>
<Tab title="Javascript" language="javascript">
With the ElevenLabs SDK installed, create a file called `example.mjs` and copy one of the following examples into it:
<Tabs>
<Tab title="Text to Speech">
```javascript Convert text into life-like audio
import { ElevenLabsClient, play } from "elevenlabs";
const client = new ElevenLabsClient();
const audio = await client.textToSpeech.convert("JBFqnCBsd6RMkjVDRZzb", {
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2",
output_format: "mp3_44100_128",
});
await play(audio);
```
</Tab>
<Tab title="Speech to Text">
```javascript Convert spoken audio into text
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient();
const response = await fetch(
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
);
const audioBlob = new Blob([await response.arrayBuffer()], { type: "audio/mp3" });
const transcription = await client.speechToText.convert({
file: audioBlob,
model_id: "scribe_v1",
});
console.log(transcription);
```
</Tab>
<Tab title="Voice changer">
```javascript Transform audio from one voice to another
import { ElevenLabsClient, play } from "elevenlabs";
const client = new ElevenLabsClient();
const voiceId = "JBFqnCBsd6RMkjVDRZzb";
const response = await fetch(
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
);
const audioBlob = new Blob([await response.arrayBuffer()], { type: "audio/mp3" });
const audioStream = await client.speechToSpeech.convert(voiceId, {
audio: audioBlob,
model_id: "eleven_multilingual_sts_v2",
output_format: "mp3_44100_128",
});
await play(audioStream);
```
</Tab>
<Tab title="Sound effects">
```javascript Convert text into sound effects
import { ElevenLabsClient, play } from "elevenlabs";
const client = new ElevenLabsClient();
const audio = await client.textToSoundEffects.convert({
text: "Cinematic Braam, Horror",
});
await play(audio);
```
</Tab>
<Tab title="Voice isolator">
```javascript Removes background noise from audio.
import { ElevenLabsClient, play } from "elevenlabs";
const client = new ElevenLabsClient();
const audioUrl =
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/fin.mp3";
const response = await fetch(audioUrl);
const audioBlob = new Blob([await response.arrayBuffer()], {
type: "audio/mp3",
});
const audioStream = await client.audioIsolation.audioIsolation({
audio: audioBlob,
});
await play(audioStream);
```
</Tab>
<Tab title="Voice design">
```javascript Generate voices from a single text prompt.
import { ElevenLabsClient, play } from "elevenlabs";
import { Readable } from "stream";
const client = new ElevenLabsClient();
const voices = await client.textToVoice.createPreviews({
voice_description: "A sassy squeaky mouse",
text: "Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted.",
});
const voicePreview1 = voices.previews[0].audio_base_64;
await play(Readable.from(Buffer.from(voicePreview1, "base64")));
```
</Tab>
<Tab title="Dubbing">
```javascript Dub audio/video from one language to another
import { ElevenLabsClient, play } from "elevenlabs";
const client = new ElevenLabsClient();
const targetLang = "es"; // spanish
const sourceAudio = await fetch(
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
);
const audioBlob = new Blob([await sourceAudio.arrayBuffer()], {
type: "audio/mp3",
});
// Start dubbing
const dubbed = await client.dubbing.dubAVideoOrAnAudioFile({
file: audioBlob,
target_lang: targetLang,
});
while (true) {
const { status } = await client.dubbing.getDubbingProjectMetadata(
dubbed.dubbing_id
);
if (status === "dubbed") {
const dubbedFile = await client.dubbing.getDubbedFile(
dubbed.dubbing_id,
targetLang
);
await play(dubbedFile);
break;
} else {
console.log("Audio is still being dubbed...");
}
await new Promise((resolve) => setTimeout(resolve, 5000)); // Wait 5 seconds between checks
}
```
</Tab>
</Tabs>
Execute the code with the command below. Within a few seconds you should hear the audio play through your speaker.
```bash title="Run the script"
node --env-file=.env example.mjs
```
</Tab>
</Tabs>
<Note>
To play the audio through your speakers, you may be prompted to install [MPV](https://mpv.io/)
and/or [ffmpeg](https://ffmpeg.org/).
</Note>
## Next steps
Now that you've made your first ElevenLabs API request, you can explore the following resources:
<CardGroup cols={2}>
<Card title="Tutorials" href="/docs/cookbooks">
Explore our developer guides
</Card>
<Card title="Text to Speech" href="/docs/capabilities/text-to-speech">
Turn text into lifelike spoken audio
</Card>
<Card title="Conversational AI" iconPosition="left" href="/docs/conversational-ai/overview">
Deploy conversational voice agents
</Card>
<Card title="API reference" iconPosition="left" href="/docs/api-reference/introduction">
Dive into our API reference
</Card>
</CardGroup>
# Models
> Learn about the models that power the ElevenLabs API.
## Flagship models
<CardGroup cols={2} rows={2}>
<Card title="Eleven Multilingual v2" href="/docs/models#multilingual-v2">
Our most lifelike, emotionally rich speech synthesis model
<div>
<div>
Most natural-sounding output
</div>
<div>
29 languages supported
</div>
<div>
10,000 character limit
</div>
<div>
Rich emotional expression
</div>
</div>
</Card>
<Card title="Eleven Flash v2.5" href="/docs/models#flash-v25">
Our fast, affordable speech synthesis model
<div>
<div>
Ultra-low latency (~75ms†)
</div>
<div>
32 languages supported
</div>
<div>
40,000 character limit
</div>
<div>
Faster model, 50% lower price per character
</div>
</div>
</Card>
</CardGroup>
<CardGroup cols={1} rows={1}>
<Card title="Scribe v1" href="/docs/models#scribe-v1">
State-of-the-art speech recognition model
<div>
<div>
Accurate transcription in 99 languages
</div>
<div>
Precise word-level timestamps
</div>
<div>
Speaker diarization
</div>
<div>
Dynamic audio tagging
</div>
</div>
</Card>
</CardGroup>
<div>
<div>
[Pricing](https://elevenlabs.io/pricing/api)
</div>
</div>
## Models overview
The ElevenLabs API offers a range of audio models optimized for different use cases, quality levels, and performance requirements.
| Model ID                     | Description                                                          | Languages                                                                                                                                                                     |
| ---------------------------- | -------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `eleven_multilingual_v2`     | Our most lifelike model with rich emotional expression               | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru` |
| `eleven_flash_v2_5`          | Ultra-fast model optimized for real-time use (\~75ms†)               | All `eleven_multilingual_v2` languages plus: `hu`, `no`, `vi`                                                                                                                 |
| `eleven_flash_v2`            | Ultra-fast model optimized for real-time use (\~75ms†)               | `en`                                                                                                                                                                          |
| `eleven_multilingual_sts_v2` | State-of-the-art multilingual voice changer model (Speech to Speech) | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru` |
| `eleven_english_sts_v2`      | English-only voice changer model (Speech to Speech)                  | `en`                                                                                                                                                                          |
| `scribe_v1`                  | State-of-the-art speech recognition model                            | [99 languages](/docs/capabilities/speech-to-text#supported-languages)                                                                                                         |
<small>
† Excluding application & network latency
</small>
<Accordion title="Older Models">
<Warning>
These models are maintained for backward compatibility but are not recommended for new projects.
</Warning>
| Model ID                 | Description                                                                  | Languages                                                                                                                                                                                       |
| ------------------------ | ---------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `eleven_monolingual_v1`  | First generation TTS model (outclassed by v2 models)                         | `en`                                                                                                                                                                                            |
| `eleven_multilingual_v1` | First multilingual model (outclassed by v2 models)                           | `en`, `fr`, `de`, `hi`, `it`, `pl`, `pt`, `es`                                                                                                                                                  |
| `eleven_turbo_v2_5`      | High quality, low-latency model (\~250ms-300ms) (outclassed by Flash models) | `en`, `ja`, `zh`, `de`, `hi`, `fr`, `ko`, `pt`, `it`, `es`, `id`, `nl`, `tr`, `fil`, `pl`, `sv`, `bg`, `ro`, `ar`, `cs`, `el`, `fi`, `hr`, `ms`, `sk`, `da`, `ta`, `uk`, `ru`, `hu`, `no`, `vi` |
| `eleven_turbo_v2`        | High quality, low-latency model (\~250ms-300ms) (outclassed by Flash models) | `en`                                                                                                                                                                                            |
</Accordion>
## Multilingual v2
Eleven Multilingual v2 is our most advanced, emotionally-aware speech synthesis model. It produces natural, lifelike speech with high emotional range and contextual understanding across multiple languages.
The model delivers consistent voice quality and personality across all supported languages while maintaining the speaker's unique characteristics and accent.
This model excels in scenarios requiring high-quality, emotionally nuanced speech:
* **Audiobook Production**: Perfect for long-form narration with complex emotional delivery
* **Character Voiceovers**: Ideal for gaming and animation due to its emotional range
* **Professional Content**: Well-suited for corporate videos and e-learning materials
* **Multilingual Projects**: Maintains consistent voice quality across language switches
While it has a higher latency & cost per character than Flash models, it delivers superior quality for projects where lifelike speech is important.
Our v2 models support 29 languages:
*English (USA, UK, Australia, Canada), Japanese, Chinese, German, Hindi, French (France, Canada), Korean, Portuguese (Brazil, Portugal), Italian, Spanish (Spain, Mexico), Indonesian, Dutch, Turkish, Filipino, Polish, Swedish, Bulgarian, Romanian, Arabic (Saudi Arabia, UAE), Czech, Greek, Finnish, Croatian, Malay, Slovak, Danish, Tamil, Ukrainian & Russian.*
## Flash v2.5
Eleven Flash v2.5 is our fastest speech synthesis model, designed for real-time applications and conversational AI. It delivers high-quality speech with ultra-low latency (\~75ms†) across 32 languages.
The model balances speed and quality, making it ideal for interactive applications while maintaining natural-sounding output and consistent voice characteristics across languages.
This model is particularly well-suited for:
* **Conversational AI**: Perfect for real-time voice agents and chatbots
* **Interactive Applications**: Ideal for games and applications requiring immediate response
* **Large-Scale Processing**: Efficient for bulk text-to-speech conversion
With its lower price point and 75ms latency, Flash v2.5 is the cost-effective option for anyone needing fast, reliable speech synthesis across multiple languages.
Flash v2.5 supports 32 languages - all languages from v2 models plus:
*Hungarian, Norwegian & Vietnamese*
### Considerations
<AccordionGroup>
<Accordion title="Text normalization with numbers">
When using Flash v2.5, numbers aren't normalized in a way you might expect. For example, phone numbers might be read out in way that isn't clear for the user. Dates and currencies are affected in a similar manner.
This is expected as normalization is disabled for Flash v2.5 to maintain the low latency.
The Multilingual v2 model does a better job of normalizing numbers, so we recommend using it for phone numbers and other cases where number normalization is important.
For low-latency or Conversational AI applications, best practice is to have your LLM [normalize the text](/docs/best-practices/prompting/normalization) before passing it to the TTS model.
</Accordion>
</AccordionGroup>
## Model selection guide
<AccordionGroup>
<Accordion title="Requirements">
<CardGroup cols={1}>
<Card title="Quality">
Use `eleven_multilingual_v2`
Best for high-fidelity audio output with rich emotional expression
</Card>
<Card title="Low-latency">
Use Flash models
Optimized for real-time applications (\~75ms latency)
</Card>
<Card title="Multilingual">
Use either either `eleven_multilingual_v2` or `eleven_flash_v2_5`
Both support up to 32 languages
</Card>
</CardGroup>
</Accordion>
<Accordion title="Use case">
<CardGroup cols={1}>
<Card title="Content creation">
Use `eleven_multilingual_v2`
Ideal for professional content, audiobooks & video narration.
</Card>
<Card title="Conversational AI">
Use `eleven_flash_v2_5`, `eleven_flash_v2` or `eleven_multilingual_v2`
Perfect for real-time conversational applications
</Card>
<Card title="Voice changer">
Use `eleven_multilingual_sts_v2`
Specialized for Speech-to-Speech conversion
</Card>
</CardGroup>
</Accordion>
</AccordionGroup>
## Character limits
The maximum number of characters supported in a single text-to-speech request varies by model.
| Model ID                 | Character limit | Approximate audio duration |
| ------------------------ | --------------- | -------------------------- |
| `eleven_flash_v2_5`      | 40,000          | \~40 minutes               |
| `eleven_flash_v2`        | 30,000          | \~30 minutes               |
| `eleven_multilingual_v2` | 10,000          | \~10 minutes               |
| `eleven_multilingual_v1` | 10,000          | \~10 minutes               |
| `eleven_english_sts_v2`  | 10,000          | \~10 minutes               |
| `eleven_english_sts_v1`  | 10,000          | \~10 minutes               |
<Note>
For longer content, consider splitting the input into multiple requests.
</Note>
## Scribe v1
Scribe v1 is our state-of-the-art speech recognition model designed for accurate transcription across 99 languages. It provides precise word-level timestamps and advanced features like speaker diarization and dynamic audio tagging.
This model excels in scenarios requiring accurate speech-to-text conversion:
* **Transcription Services**: Perfect for converting audio/video content to text
* **Meeting Documentation**: Ideal for capturing and documenting conversations
* **Content Analysis**: Well-suited for audio content processing and analysis
* **Multilingual Recognition**: Supports accurate transcription across 99 languages
Key features:
* Accurate transcription with word-level timestamps
* Speaker diarization for multi-speaker audio
* Dynamic audio tagging for enhanced context
* Support for 99 languages
Read more about Scribe v1 [here](/docs/capabilities/speech-to-text).
## Concurrency and priority
Your subscription plan determines how many requests can be processed simultaneously and the priority level of your requests in the queue.
| Plan       | Concurrency limit | Priority level |
| ---------- | ----------------- | -------------- |
| Free       | 2                 | 3              |
| Starter    | 3                 | 4              |
| Creator    | 5                 | 5              |
| Pro        | 10                | 5              |
| Scale      | 15                | 5              |
| Business   | 15                | 5              |
| Enterprise | Custom            | Highest        |
<Note>
To increase your concurrency limit & queue priority, [upgrade your subscription
plan](https://elevenlabs.io/pricing/api).
Enterprise customers can request a higher concurrency limit by contacting their account manager.
</Note>
The response headers include `current-concurrent-requests` and `maximum-concurrent-requests` which you can use to monitor your concurrency.
# March 17, 2025
### Conversational AI
- **Default LLM update**: Changed the default agent LLM from Gemini 1.5 Flash to Gemini 2.0 Flash for improved performance.
- **Fixed incorrect conversation abandons**: Improved detection of conversation continuations, preventing premature abandons when users repeat themselves.
- **Twilio information in history**: Added Twilio call details to conversation history for better tracking.
- **Knowledge base redesign**: Redesigned the knowledge base interface.
- **System dynamic variables**: Added system dynamic variables to use time, conversation id, caller id and other system values as dynamic variables in prompts and tools.
- **Twilio client initialisation**: Adds an agent level override for conversation initiation client data twilio webhook.
- **RAG chunks in history**: Added retrieved chunks by RAG to the call transcripts in the [history view](https://elevenlabs.io/app/conversational-ai/history).
### Speech to Text
- **Reduced pricing**: Reduced the pricing of our Scribe model, see more [here](/docs/capabilities/speech-to-text#pricing).
- **Improved VAD detection**: Enhanced Voice Activity Detection with better pause detection at segment boundaries and improved handling of silent segments.
- **Enhanced diarization**: Improved speaker clustering with a better ECAPA model, symmetric connectivity matrix, and more selective speaker embedding generation.
- **Fixed ASR bugs**: Resolved issues with VAD rounding, silence and clustering that affected transcription accuracy.
### Studio
- **Disable publishing UI**: Added ability to disable the publishing interface for specific workspace members to support enterprise workflows.
- **Snapshot API improvement**: Modified endpoints for project and chapter snapshots to return an empty list instead of throwing errors when snapshots can't be downloaded.
- **Disabled auto-moderation**: Turned off automatic moderation based on Text to Speech generations in Studio.
### Workspaces
- **Fixed API key editing**: Resolved an issue where editing workspace API keys would reset character limits to zero, causing the keys to stop working.
- **Optimized free subscriptions**: Fixed an issue with refreshing free subscription character limits,
### API
<Accordion title="View API changes">
## New Endpoints
- Added 3 new endpoints:
- [Get workspace resource](/docs/api-reference/workspace/get-resource)
- [Share workspace resource](/docs/api-reference/workspace/share-workspace-resource)
- [Unshare workspace resource](/docs/api-reference/workspace/unshare-workspace-resource)
## Updated Endpoints
### Dubbing
- Updated Dubbing endpoints:
- [Dub a video or audio file](/docs/api-reference/dubbing/dub-a-video-or-an-audio-file) - Added `use_replacement_voices_from_library` property and made `source_path`, `target_language`, `source_language` nullable
- [Resource dubbing](/docs/api-reference/dubbing/dub-segments) - Made `language_codes` array nullable
- [Add language to dubbing resource](/docs/api-reference/dubbing/add-language-to-resource) - Made `language_code` nullable
- [Add speaker segment](/docs/api-reference/dubbing/create-segment-for-speaker) - Made `text` nullable
- [Translate dubbing resource](/docs/api-reference/dubbing/translate-segments) - Made `target_languages` array nullable
- [Update dubbing segment](/docs/api-reference/dubbing/update-segment-language) - Made `start_time` and `end_time` nullable
### Project Management
- Updated Project endpoints:
- [Add project](/docs/api-reference/studio/add-project) - Made `metadata`, `project_name`, `description` nullable
- [Create podcast](/docs/api-reference/studio/create-podcast) - Made `title`, `description`, `author` nullable
- [Get project](/docs/api-reference/studio/get-project) - Made `last_modified_at`, `created_at`, `project_name` nullable
- [Add chapter](/docs/api-reference/studio/add-chapter) - Made `chapter_id`, `word_count`, `statistics` nullable
- [Update chapter](/docs/api-reference/studio/update-chapter) - Made `content` and `blocks` properties nullable
### Conversational AI
- Updated Conversational AI endpoints:
- [Update agent](/docs/api-reference/agents/update-agent) - Made `conversation_config`, `platform_settings` nullable and added `workspace_overrides` property
- [Create agent](/docs/api-reference/agents/create-agent) - Made `agent_name`, `prompt`, `widget_config` nullable and added `workspace_overrides` property
- [Add to knowledge base](/docs/api-reference/knowledge-base/add-to-knowledge-base) - Made `document_name` nullable
- [Get conversation](/docs/api-reference/conversations/get-conversation) - Added `twilio_call_data` model and made `transcript`, `metadata` nullable
### Text to Speech
- Updated Text to Speech endpoints:
- [Convert text to speech](/docs/api-reference/text-to-speech/convert) - Made `voice_settings`, `text_input` nullable and deprecated `use_pvc_as_ivc` property
- [Stream text to speech](/docs/api-reference/text-to-speech/convert-as-stream) - Made `voice_settings`, `text_input` nullable and deprecated `use_pvc_as_ivc` property
- [Convert with timestamps](/docs/api-reference/text-to-speech/convert-with-timestamps) - Made `character_alignment` and `word_alignment` nullable
### Voice Management
- Updated Voice endpoints:
- [Create voice previews](/docs/api-reference/text-to-voice/create-previews) - Added `loudness`, `quality`, `guidance_scale` properties
- [Create voice from preview](/docs/api-reference/text-to-voice/create-voice-from-preview) - Added `speaker_separation` properties and made `voice_id`, `name`, `labels` nullable
- [Get voice](/docs/api-reference/voices/get) - Added `speaker_boost`, `speaker_clarity`, `speaker_isolation` properties
### Speech to Text
- Updated Speech to Text endpoint:
- [Convert speech to text](/docs/api-reference/speech-to-text/convert) - Added `biased_keywords` property
### Other Updates
- [Download history](/docs/api-reference/history/download) - Added application/zip content type and 400 response
- [Add pronunciation dictionary from file](/docs/api-reference/pronunciation-dictionary/add-from-file) - Made `dictionary_name` and `description` nullable
</Accordion>
# March 10, 2025
### Conversational AI
- **HIPAA compliance**: Conversational AI is now [HIPAA compliant](/docs/conversational-ai/customization/hipaa-compliance) on appropriate plans, when a BAA is signed, zero-retention mode is enabled and appropriate LLMs are used. For access please [contact sales](/contact-sales)
- **Cascade LLM**: Added dynamic dispatch during the LLM step to other LLMs if your default LLM fails. This results in higher latency but prevents the turn failing.
- **Better error messages**: Added better error messages for websocket failures.
- **Audio toggling**: Added ability to select only user or agent audio in the conversation playback.
### Scribe
- **HIPAA compliance**: Added a zero retention mode to Scribe to be HIPAA compliant.
- **Diarization**: Increased time length of audio files that can be transcribed with diarization from 8 minutes to 2 hours.
- **Cheaper pricing**: Updated Scribe's pricing to be cheaper, as low as $0.22 per hour for the Business tier.
- **Memory usage**: Shipped improvements to Scribe's memory usage.
- **Fixed timestamps**: Fixed an issue that was causing incorrect timestamps to be returned.
- **Biased keywords**: Added biased keywords to improve Scribe's performance.
### Text to Speech
- **Pronunciation dictionaries**: Fixed pronunciation dictionary rule application for replacements that contain symbols.
### Dubbing
- **Studio support**: Added support for creating dubs with `dubbing_studio` enabled, allowing for more advanced dubbing workflows beyond one-off dubs.
### Voices
- **Verification**: Fixed an issue where users on probation could not verify their voice clone.
### API
<Accordion title="View API changes">
## New Endpoints
- Added 7 new endpoints:
- [Add a shared voice to your collection](/docs/api-reference/voice-library/add-sharing-voice)
- [Archive a project snapshot](/docs/api-reference/studio/archive-snapshot)
- [Update a project](/docs/api-reference/studio/edit-project)
- [Create an Audio Native enabled project](/docs/api-reference/audio-native/create)
- [Get all voices](/docs/api-reference/voices/get-all)
- [Download a pronunciation dictionary](/docs/api-reference/pronunciation-dictionary/download)
- [Get Audio Native project settings](/docs/api-reference/audio-native/get-settings)
## Updated Endpoints
### Studio Projects
- Updated Studio project endpoints to add `source_type` property and deprecate `quality_check_on` and `quality_check_on_when_bulk_convert` properties:
- [Get projects](/docs/api-reference/studio/get-projects)
- [Get project](/docs/api-reference/studio/get-project)
- [Add project](/docs/api-reference/studio/add-project)
- [Update content](/docs/api-reference/studio/update-content)
- [Create podcast](/docs/api-reference/studio/create-podcast)
### Voice Management
- Updated Voice endpoints with several property changes:
- [Get voice](/docs/api-reference/voices/get) - Made several properties optional and added `preview_url`
- [Create voice](/docs/api-reference/voices/add) - Made several properties optional and added `preview_url`
- [Create voice from preview](/docs/api-reference/text-to-voice/create-voice-from-preview) - Made several properties optional and added `preview_url`
- [Get similar voices](/docs/api-reference/voices/get-similar-library-voices) - Made `language`, `description`, `preview_url`, and `rate` properties optional
### Conversational AI
- Updated Conversational AI agent endpoints:
- [Update agent](/docs/api-reference/agents/update-agent) - Modified `conversation_config`, `agent`, `platform_settings`, and `widget` properties
- [Create agent](/docs/api-reference/agents/create-agent) - Modified `conversation_config`, `agent`, `prompt`, platform_settings, widget properties and added `shareable_page_show_terms`
- [Get agent](/docs/api-reference/agents/get-agent) - Modified `conversation_config`, `agent`, `platform_settings`, and `widget` properties
- [Get widget](/docs/api-reference/widget/get-agent-widget) - Modified `widget_config` property and added `shareable_page_show_terms`
### Knowledge Base
- Updated Knowledge Base endpoints to add metadata property:
- [List knowledge base documents](/docs/api-reference/knowledge-base/get-knowledge-base-document-by-id#response.body.metadata)
- [Get knowledge base document](/docs/api-reference/knowledge-base/get-knowledge-base-document-by-id#response.body.metadata)
### Other Updates
- [Dub a video or audio file](/docs/api-reference/dubbing/dub-a-video-or-an-audio-file) - Added `dubbing_studio` property
- [Convert text to sound effects](/docs/api-reference/text-to-sound-effects/convert) - Added `output_format` query parameter
- [Convert speech to text](/docs/api-reference/speech-to-text/convert) - Added `enable_logging` query parameter
- [Get secrets](/docs/api-reference/workspace/get-secrets) - Modified `secrets` and `used_by` properties
- [Get all pronunciation dictionaries](/docs/api-reference/pronunciation-dictionary/get-all) - Made `next_cursor` property optional
## Removed Endpoints
- Temporarily removed Conversational AI tools endpoints:
- Get tool
- List tools
- Update tool
- Create tool
- Delete tool
</Accordion>
# March 3, 2025
### Dubbing
- **Scribe for speech recognition**: Dubbing Studio now uses Scribe by default for speech recognition to improve accuracy.
### Speech to Text
- **Fixes**: Shipped several fixes improving the stability of Speech to Text.
### Conversational AI
- **Speed control**: Added speed control to an agent's settings in Conversational AI.
- **Post call webhook**: Added the option of sending [post-call webhooks](/docs/conversational-ai/customization/personalization/post-call-webhooks) after conversations are completed.
- **Improved error messages**: Added better error messages to the Conversational AI websocket.
- **Claude 3.7 Sonnet**: Added Claude 3.7 Sonnet as a new LLM option in Conversational AI.
### API
<Accordion title="View API changes">
#### New Endpoints
- Added new Dubbing resource management endpoints:
- for adding [languages to dubs](/docs/api-reference/dubbing/add-language-to-resource)
- for retrieving [dubbing resources](/docs/api-reference/dubbing/get-dubbing-resource)
- for creating [segments](/docs/api-reference/dubbing/create-segment-for-speaker)
- for modifying [segments](/docs/api-reference/dubbing/update-segment-language)
- for removing [segments](/docs/api-reference/dubbing/delete-segment)
- for dubbing [segments](/docs/api-reference/dubbing/dub-segments)
- for transcribing [segments](/docs/api-reference/dubbing/transcribe-segments)
- for translating [segments](/docs/api-reference/dubbing/translate-segments)
- Added Knowledge Base RAG indexing [endpoint](/docs/api-reference/knowledge-base/rag-index-status)
- Added Studio snapshot retrieval endpoints for [projects](docs/api-reference/studio/get-project-snapshot-by-id) and [chapters](docs/api-reference/studio/get-chapter-snapshot-by-id)
#### Updated Endpoints
- Added `prompt_injectable` property to knowledge base [endpoints](docs/api-reference/knowledge-base/get-knowledge-base-document-by-id#response.body.prompt_injectable)
- Added `name` property to Knowledge Base document [creation](/docs/api-reference/knowledge-base/add-to-knowledge-base#request.body.name) and [retrieval](/docs/api-reference/knowledge-base/get-knowledge-base-document-by-id#response.body.name) endpoints:
- Added `speed` property to [agent creation](/docs/api-reference/agents/create-agent#request.body.conversation_config.tts.speed)
- Removed `secrets` property from agent endpoints (now handled by dedicated secrets endpoints)
- Added [secret deletion endpoint](/docs/api-reference/workspace/delete-secret) for removing secrets
- Removed `secrets` property from settings [endpoints](/docs/api-reference/workspace/get-settings)
</Accordion>
# February 25, 2025
### Speech to Text
- **ElevenLabs launched a new state of the art [Speech to Text API](/docs/capabilities/speech-to-text) available in 99 languages.**
### Text to Speech
- **Speed control**: Added speed control to the Text to Speech API.
### Studio
- **Auto-assigned projects**: Increased token limits for auto-assigned projects from 1 month to 3 months worth of tokens, addressing user feedback about working on longer projects.
- **Language detection**: Added automatic language detection when generating audio for the first time, with suggestions to switch to Eleven Turbo v2.5 for languages not supported by Multilingual v2 (Hungarian, Norwegian, Vietnamese).
- **Project export**: Enhanced project exporting in ElevenReader with better metadata tracking.
### Dubbing
- **Clip overlap prevention**: Added automatic trimming of overlapping clips in dubbing jobs to ensure clean audio tracks for each speaker and language.
### Voice Management
- **Instant Voice Cloning**: Improved preview generation for Instant Voice Cloning v2, making previews available immediately.
### Conversational AI
- **Agent ownership**: Added display of agent creators in the agent list, improving visibility and management of shared agents.
### Web app
- **Dark mode**: Added dark mode to the web app.
### API
<Accordion title="View API changes">
- Launched **/v1/speech-to-text** [endpoint](/docs/api-reference/speech-to-text/convert)
- Added `agents.level` property to [Conversational AI agents endpoint](/docs/api-reference/agents/get-agents#response.body.agents.access_level)
- Added `platform_settings` to [Conversational AI agent endpoint](/docs/api-reference/agents/update-agent#request.body.platform_settings)
- Added `expandable` variant to `widget_config`, with configuration options `show_avatar_when_collapsed` and `disable_banner` to [Conversational AI agent widget endpoint](/docs/api-reference/agents/get-agent#response.body.widget)
- Added `webhooks` property and `used_by` to `secrets` to [secrets endpoint](/docs/api-reference/workspace/get-secrets#response.body.secrets.used_by)
- Added `verified_languages` to [voices endpoint](/docs/api-reference/voices/get#response.body.verified_languages)
- Added `speed` property to [voice settings endpoints](/docs/api-reference/voices/get#response.body.settings.speed)
- Added `verified_languages`, `is_added_by_user` to `voices` and `min_notice_period_days` query parameter to [shared voices endpoint](/docs/api-reference/voice-library/get-shared#request.query)
- Added `verified_languages`, `is_added_by_user` to `voices` in [similar voices endpoint](/docs/api-reference/voices/get-similar-library-voices)
- Added `search`, `show_only_owned_documents`, `use_typesense` query parameters to [knowledge base endpoint](/docs/api-reference/knowledge-base/get-knowledge-base-list#request.query.search)
- Added `used_by` to Conversation AI [secrets endpoint](/docs/api-reference/workspace/get-secrets)
- Added `invalidate_affected_text` property to Studio [pronunciation dictionaries endpoint](/docs/api-reference/studio/create-pronunciation-dictionaries#request.body.invalidate_affected_text)
</Accordion>
# February 17, 2025
### Conversational AI
- **Tool calling fix**: Fixed an issue where tool calling was not working with agents using gpt-4o mini. This was due to a breaking change in the OpenAI API.
- **Tool calling improvements**: Added support for tool calling with dynamic variables inside objects and arrays.
- **Dynamic variables**: Fixed an issue where dynamic variables of a conversation were not being displayed correctly.
### Voice Isolator
- **Fixed**: Fixed an issue that caused the voice isolator to not work correctly temporarily.
### Workspace
- **Billing**: Improved billing visibility by differentiating rollover, cycle, gifted, and usage-based credits.
- **Usage Analytics**: Improved usage analytics load times and readability.
- **Fine grained fiat billing**: Added support for customizable pricing based on several factors.
### API
<Accordion title="View API changes">
- Added `phone_numbers` property to [Agent responses](/docs/api-reference/agents/get-agent)
- Added usage metrics to subscription_extras in [User endpoint](/docs/api-reference/user/get):
- `unused_characters_rolled_over_from_previous_period`
- `overused_characters_rolled_over_from_previous_period`
- `usage` statistics
- Added `enable_conversation_initiation_client_data_from_webhook` to [Agent creation](/docs/api-reference/agents/create-agent)
- Updated [Agent](/docs/api-reference/agents) endpoints with consolidated settings for:
- `platform_settings`
- `overrides`
- `safety`
- Deprecated `with_settings` parameter in [Voice retrieval endpoint](/docs/api-reference/voices/get)
</Accordion>
# February 10, 2025
## Conversational AI
- **Updated Pricing**: Updated self-serve pricing for Conversational AI with [reduced cost and a more generous free tier](/docs/conversational-ai/overview#pricing-tiers).
- **Knowledge Base UI**: Created a new page to easily manage your [knowledge base](/app/conversational-ai/knowledge-base).
- **Live calls**: Added number of live calls in progress in the user [dashboard](/app/conversational-ai) and as a new endpoint.
- **Retention**: Added ability to customize transcripts and audio recordings [retention settings](/docs/conversational-ai/customization/privacy/retention).
- **Audio recording**: Added a new option to [disable audio recordings](/docs/conversational-ai/customization/privacy/audio-saving).
- **8k PCM support**: Added support for 8k PCM audio for both input and output.
## Studio
- **GenFM**: Updated the create podcast endpoint to accept [multiple input sources](/docs/api-reference/projects/create-podcast).
- **GenFM**: Fixed an issue where GenFM was creating empty podcasts.
## Enterprise
- **New workspace group endpoints**: Added new endpoints to manage [workspace groups](/docs/api-reference/workspace/search-user-groups).
### API
<AccordionGroup>
<Accordion title="Deprecated Endpoints">
**Studio (formerly Projects)**
All `/v1/projects/*` endpoints have been deprecated in favor of the new `/v1/studio/projects/*` endpoints. The following endpoints are now deprecated:
- All operations on `/v1/projects/`
- All operations related to chapters, snapshots, and content under `/v1/projects/*`
**Conversational AI**
- `POST /v1/convai/add-tool` - Use `POST /v1/convai/tools` instead
</Accordion>
<Accordion title="Breaking Changes">
- `DELETE /v1/convai/agents/{agent_id}` - Response type is no longer an object
- `GET /v1/convai/tools` - Response type changed from array to object with a `tools` property
</Accordion>
<Accordion title="Modified Endpoints">
**Conversational AI Updates**
- `GET /v1/convai/agents/{agent_id}` - Updated conversation configuration and agent properties
- `PATCH /v1/convai/agents/{agent_id}` - Added `use_tool_ids` parameter for tool management
- `POST /v1/convai/agents/create` - Added tool integration via `use_tool_ids`
**Knowledge Base & Tools**
- `GET /v1/convai/agents/{agent_id}/knowledge-base/{documentation_id}` - Added `name` and `access_level` properties
- `GET /v1/convai/knowledge-base/{documentation_id}` - Added `name` and `access_level` properties
- `GET /v1/convai/tools/{tool_id}` - Added `dependent_agents` property
- `PATCH /v1/convai/tools/{tool_id}` - Added `dependent_agents` property
**GenFM**
- `POST /v1/projects/podcast/create` - Added support for multiple input sources
</Accordion>
<Accordion title="New Endpoints">
**Studio (formerly Projects)**
New endpoints replacing the deprecated `/v1/projects/*` endpoints
- `GET /v1/studio/projects`: List all projects
- `POST /v1/studio/projects`: Create a project
- `GET /v1/studio/projects/{project_id}`: Get project details
- `DELETE /v1/studio/projects/{project_id}`: Delete a project
**Knowledge Base Management**
- `GET /v1/convai/knowledge-base`: List all knowledge base documents
- `DELETE /v1/convai/knowledge-base/{documentation_id}`: Delete a knowledge base
- `GET /v1/convai/knowledge-base/{documentation_id}/dependent-agents`: List agents using this knowledge base
**Workspace Groups** - New enterprise features for team management
- `GET /v1/workspace/groups/search`: Search workspace groups
- `POST /v1/workspace/groups/{group_id}/members`: Add members to a group
- `POST /v1/workspace/groups/{group_id}/members/remove`: Remove members from a group
**Tools**
- `POST /v1/convai/tools`: Create new tools for agents
</Accordion>
</AccordionGroup>
## Socials
- **ElevenLabs Developers**: Follow our new developers account on X [@ElevenLabsDevs](https://x.com/ElevenLabsDevs)
# February 4, 2025
### Conversational AI
- **Agent monitoring**: Added a new dashboard for monitoring conversational AI agents' activity. Check out your's [here](/app/conversational-ai).
- **Proactive conversations**: Enhanced capabilities with improved timeout retry logic. [Learn more](/docs/conversational-ai/customization/conversation-flow)
- **Tool calls**: Fixed timeout issues occurring during tool calls
- **Allowlist**: Fixed implementation of allowlist functionality.
- **Content summarization**: Added Gemini as a fallback model to ensure service reliability
- **Widget stability**: Fixed issue with dynamic variables causing the Conversational AI widget to fail
### Reader
- **Trending content**: Added carousel showcasing popular articles and trending content
- **New publications**: Introduced dedicated section for recent ElevenReader Publishing releases
### Studio (formerly Projects)
- **Projects is now Studio** and is now generally available to everyone
- **Chapter content editing**: Added support for editing chapter content through the public API, enabling programmatic updates to chapter text and metadata
- **GenFM public API**: Added public API support for podcast creation through GenFM. Key features include:
- Conversation mode with configurable host and guest voices
- URL-based content sourcing
- Customizable duration and highlights
- Webhook callbacks for status updates
- Project snapshot IDs for audio downloads
### SDKs
- **Swift**: fixed an issue where resources were not being released after the end of a session
- **Python**: added uv support
- **Python**: fixed an issue where calls were not ending correctly
### API
<Accordion title="View API changes">
- Added POST `v1/workspace/invites/add-bulk` [endpoint](/docs/api-reference/workspace/invite-multiple-users) to enable inviting multiple users simultaneously
- Added POST `v1/projects/podcast/create` [endpoint](/docs/api-reference/projects/create-podcast) for programmatic podcast generation through GenFM
- Added 'v1/convai/knowledge-base/:documentation_id' [endpoints](/docs/api-reference/knowledge-base/) with CRUD operations for Conversational AI
- Added PATCH `v1/projects/:project_id/chapters/:chapter_id` [endpoint](/docs/api-reference/studio/update-chapter) for updating project chapter content and metadata
- Added `group_ids` parameter to [Workspace Invite endpoint](/docs/api-reference/workspace/invite-user) for group-based access control
- Added structured `content` property to [Chapter response objects](/docs/api-reference/chapters/get-chapter)
- Added `retention_days` and `delete_transcript_and_pii` data retention parameters to [Agent creation](/docs/api-reference/agents/create-agent)
- Added structured response to [AudioNative content](/docs/api-reference/audio-native/create#response.body.project_id)
- Added `convai_chars_per_minute` usage metric to [User endpoint](/docs/api-reference/user/get)
- Added `media_metadata` field to [Dubbing response objects](/docs/api-reference/dubbing/get-dubbing-project-metadata)
- Added GDPR-compliant `deletion_settings` to [Conversation responses](/docs/api-reference/conversations/get-conversation#response.body.metadata.deletion_settings)
- Deprecated Knowledge Base legacy endpoints:
- POST `/v1/convai/agents/{agent_id}/add-to-knowledge-base`
- GET `/v1/convai/agents/{agent_id}/knowledge-base/{documentation_id}`
- Updated Agent endpoints with consolidated [privacy control parameters](/docs/api-reference/agents/create-agent)
</Accordion>
# January 27, 2025
### Docs
- **Shipped our new docs**: we're keen to hear your thoughts, you can reach out by opening an issue on [GitHub](https://github.com/elevenlabs/elevenlabs-docs) or chatting with us on [Discord](https://discord.gg/elevenlabs)
### Conversational AI
- **Dynamic variables**: Available in the dashboard and SDKs. [Learn more](/docs/conversational-ai/customization/personalization/dynamic-variables)
- **Interruption handling**: Now possible to ignore user interruptions in Conversational AI. [Learn more](/docs/conversational-ai/customization/conversation-flow#interruptions)
- **Twilio integration**: Shipped changes to increase audio quality when integrating with Twilio
- **Latency optimization**: Published detailed blog post on latency optimizations. [Read more](/blog/how-do-you-optimize-latency-for-conversational-ai)
- **PCM 8000**: Added support for PCM 8000 to Conversational AI agents
- **Websocket improvements**: Fixed unexpected websocket closures
### Projects
- **Auto-regenerate**: Auto-regeneration now available by default at no extra cost
- **Content management**: Added `updateContent` method for dynamic content updates
- **Audio conversion**: New auto-convert and auto-publish flags for seamless workflows
### API
<Accordion title="View API changes">
- Added `Update Project` endpoint for [project editing](/docs/api-reference/studio/edit-project#:~:text=List%20projects-,POST,Update%20project,-GET)
- Added `Update Content` endpoint for [AudioNative content management](/docs/api-reference/audio-native/update-content)
- Deprecated `quality_check_on` parameter in [project operations](/docs/api-reference/projects/add-project#request.body.quality_check_on). It is now enabled for all users at no extra cost
- Added `apply_text_normalization` parameter to project creation with modes 'auto', 'on', 'apply_english' and 'off' for controlling text normalization during [project creation](/docs/api-reference/projects/add-project#request.body.apply_text_normalization)
- Added alpha feature `auto_assign_voices` in [project creation](/docs/api-reference/projects/add-project#request.body.auto_assign_voices) to automatically assign voices to phrases
- Added `auto_convert` flag to project creation to automatically convert [projects to audio](/docs/api-reference/audio-native/create#request.body.auto_convert)
- Added support for creating Conversational AI agents with [dynamic variables](/docs/api-reference/agents/create-agent#request.body.conversation_config.agent.dynamic_variables)
- Added `voice_slots_used` to `Subscription` model to track number of custom voices used in a workspace to the `User` [endpoint](/docs/api-reference/user/get-subscription#response.body.voice_slots_used)
- Added `user_id` field to `User` [endpoint](/docs/api-reference/user/get#response.body.user_id)
- Marked legacy AudioNative creation parameters (`image`, `small`, `sessionization`) as deprecated [parameters](/docs/api-reference/audio-native/create#request.body.image)
- Agents platform now supports `call_limits` containing either `agent_concurrency_limit` or `daily_limit` or both parameters to control simultaneous and daily conversation limits for [agents](docs/api-reference/agents/create-agent#request.body.platform_settings.call_limits)
- Added support for `language_presets` in `conversation_config` to customize language-specific [settings](/docs/api-reference/agents/create-agent#request.body.conversation_config.language_presets)
</Accordion>
### SDKs
- **Cross-Runtime Support**: Now compatible with **Bun 1.1.45+** and **Deno 2.1.7+**
- **Regenerated SDKs**: We regenerated our SDKs to be up to date with the latest API spec. Check out the latest [Python SDK release](https://github.com/elevenlabs/elevenlabs-python/releases/tag/1.50.5) and [JS SDK release](https://github.com/elevenlabs/elevenlabs-js/releases/tag/v1.50.4)
- **Dynamic Variables**: Fixed an issue where dynamic variables were not being handled correctly, they are now correctly handled in all SDKs
# January 16, 2025
## Product
### Conversational AI
- **Additional languages**: Add a language dropdown to your widget so customers can launch conversations in their preferred language. Learn more [here](/docs/conversational-ai/customization/language).
- **End call tool**: Let the agent automatically end the call with our new “End Call” tool. Learn more [here](/docs/conversational-ai/customization/tools)
- **Flash default**: Flash, our lowest latency model, is now the default for new agents. In your agent dashboard under “voice”, you can toggle between Turbo and Flash. Learn more about Flash [here](https://elevenlabs.io/blog/meet-flash).
- **Privacy**: Set concurrent call and daily call limits, turn off audio recordings, add feedback collection, and define customer terms & conditions.
- **Increased tool limits**: Increase the number of tools available to your agent from 5 to 15. Learn more [here](/docs/conversational-ai/customization/tools).
# January 2, 2025
## Product
- **Workspace Groups and Permissions**: Introduced new workspace group management features to enhance access control within organizations. [Learn more](https://elevenlabs.io/blog/workspace-groups-and-permissions).
# December 19, 2024
## Model
- **Introducing Flash**: Our fastest text-to-speech model yet, generating speech in just 75ms. Access it via the API with model IDs `eleven_flash_v2` and `eleven_flash_v2_5`. Perfect for low-latency conversational AI applications. [Try it now](https://elevenlabs.io/docs/api-reference/text-to-speech).
## Launches
- **[TalkToSanta.io](https://www.talktosanta.io)**: Experience Conversational AI in action by talking to Santa this holiday season. For every conversation with santa we donate 2 dollars to [Bridging Voice](https://www.bridgingvoice.org) (up to $11,000).
- **[AI Engineer Pack](https://aiengineerpack.com)**: Get $50+ in credits from leading AI developer tools, including ElevenLabs.
# December 6, 2024
## Product
- **GenFM Now on Web**: Access GenFM directly from the website in addition to the ElevenReader App, [try it now](https://elevenlabs.io/app/projects).
# December 3, 2024
## API
- **Credit Usage Limits**: Set specific credit limits for API keys to control costs and manage usage across different use cases by setting "Access" or "No Access" to features like Dubbing, Audio Native, and more. [Check it out](https://elevenlabs.io/app/settings/api-keys)
- **Workspace API Keys**: Now support access permissions, such as "Read" or "Read and Write" for User, Workspace, and History resources.
- **Improved Key Management**:
- Redesigned interface moving from modals to dedicated pages
- Added detailed descriptions and key information
- Enhanced visibility of key details and settings
# November 29, 2024
## Product
- **GenFM**: Launched in the ElevenReader app. [Learn more](https://elevenlabs.io/blog/genfm-on-elevenreader)
- **Conversational AI**: Now generally available to all customers. [Try it now](https://elevenlabs.io/conversational-ai)
- **TTS Redesign**: The website TTS redesign is now rolled out to all customers.
- **Auto-regenerate**: Now available in Projects. [Learn more](https://elevenlabs.io/blog/auto-regenerate-is-live-in-projects)
- **Reader Platform Improvements**:
- Improved content sharing with enhanced landing pages and social media previews.
- Added podcast rating system and improved voice synchronization.
- **Projects revamp**:
- Restore past generations, lock content, assign speakers to sentence fragments, and QC at 2x speed. [Learn more](https://elevenlabs.io/blog/narrate-any-project)
- Auto-regeneration identifies mispronunciations and regenerates audio at no extra cost. [Learn more](https://elevenlabs.io/blog/auto-regenerate-is-live-in-projects)
## API
- **Conversational AI**: [SDKs and APIs](https://elevenlabs.io/docs/conversational-ai/docs/introduction) now available.
# October 27, 2024
## API
- **u-law Audio Formats**: Added u-law audio formats to the Convai API for integrations with Twilio.
- **TTS Websocket Improvements**: TTS websocket improvements, flushes and generation work more intuitively now.
- **TTS Websocket Auto Mode**: A streamlined mode for using websockets. This setting reduces latency by disabling chunk scheduling and buffers. Note: Using partial sentences will result in significantly reduced quality.
- **Improvements to latency consistency**: Improvements to latency consistency for all models.
## Website
- **TTS Redesign**: The website TTS redesign is now in alpha!
# October 20, 2024
## API
- **Normalize Text with the API**: Added the option normalize the input text in the TTS API. The new parameter is called `apply_text_normalization` and works on all non-turbo & non-flash models.
## Product
- **Voice Design**: The Voice Design feature is now in beta!
# October 13, 2024
## Model
- **Stability Improvements**: Significant audio stability improvements across all models, most noticeable on `turbo_v2` and `turbo_v2.5`, when using:
- Websockets
- Projects
- Reader app
- TTS with request stitching
- ConvAI
- **Latency Improvements**: Reduced time to first byte latency by approximately 20-30ms for all models.
## API
- **Remove Background Noise Voice Samples**: Added the ability to remove background noise from voice samples using our audio isolation model to improve quality for IVCs and PVCs at no additional cost.
- **Remove Background Noise STS Input**: Added the ability to remove background noise from STS audio input using our audio isolation model to improve quality at no additional cost.
## Feature
- **Conversational AI Beta**: Conversational AI is now in beta.
# Text to Speech
> Learn how to turn text into lifelike spoken audio with ElevenLabs.
## Overview
ElevenLabs [Text to Speech (TTS)](/docs/api-reference/text-to-speech) API turns text into lifelike audio with nuanced intonation, pacing and emotional awareness. [Our models](/docs/models) adapt to textual cues across 32 languages and multiple voice styles and can be used to:
* Narrate global media campaigns & ads
* Produce audiobooks in multiple languages with complex emotional delivery
* Stream real-time audio from text
Listen to a sample:
<elevenlabs-audio-player audio-title="George" audio-src="https://storage.googleapis.com/eleven-public-cdn/audio/marketing/george.mp3" />
Explore our [voice library](https://elevenlabs.io/community) to find the perfect voice for your project.
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Learn how to integrate text to speech into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/playground/text-to-speech">
Step-by-step guide for using text to speech in ElevenLabs.
</Card>
</CardGroup>
### Voice quality
For real-time applications, Flash v2.5 provides ultra-low 75ms latency, while Multilingual v2 delivers the highest quality audio with more nuanced expression.
<CardGroup cols={2} rows={2}>
<Card title="Eleven Multilingual v2" href="/docs/models#multilingual-v2">
Our most lifelike, emotionally rich speech synthesis model
<div>
<div>
Most natural-sounding output
</div>
<div>
29 languages supported
</div>
<div>
10,000 character limit
</div>
<div>
Rich emotional expression
</div>
</div>
</Card>
<Card title="Eleven Flash v2.5" href="/docs/models#flash-v25">
Our fast, affordable speech synthesis model
<div>
<div>
Ultra-low latency (~75ms†)
</div>
<div>
32 languages supported
</div>
<div>
40,000 character limit
</div>
<div>
Faster model, 50% lower price per character
</div>
</div>
</Card>
</CardGroup>
<div>
<div>
[Explore all](/docs/models)
</div>
</div>
### Voice options
ElevenLabs offers thousands of voices across 32 languages through multiple creation methods:
* [Voice library](/docs/capabilities/voices) with 3,000+ community-shared voices
* [Professional voice cloning](/docs/capabilities/voices#cloned) for highest-fidelity replicas
* [Instant voice cloning](/docs/capabilities/voices#cloned) for quick voice replication
* [Voice design](/docs/capabilities/voices#voice-design) to generate custom voices from text descriptions
Learn more about our [voice options](/docs/capabilities/voices).
### Supported formats
The default response format is "mp3", but other formats like "PCM", & "μ-law" are available.
* **MP3**
* Sample rates: 22.05kHz - 44.1kHz
* Bitrates: 32kbps - 192kbps
* **PCM (S16LE)**
* Sample rates: 16kHz - 44.1kHz
* **μ-law**
* 8kHz sample rate
* Optimized for telephony applications
<Success>
Higher quality audio options are only available on paid tiers - see our [pricing
page](https://elevenlabs.io/pricing/api) for details.
</Success>
### Supported languages
Our v2 models support 29 languages:
*English (USA, UK, Australia, Canada), Japanese, Chinese, German, Hindi, French (France, Canada), Korean, Portuguese (Brazil, Portugal), Italian, Spanish (Spain, Mexico), Indonesian, Dutch, Turkish, Filipino, Polish, Swedish, Bulgarian, Romanian, Arabic (Saudi Arabia, UAE), Czech, Greek, Finnish, Croatian, Malay, Slovak, Danish, Tamil, Ukrainian & Russian.*
Flash v2.5 supports 32 languages - all languages from v2 models plus:
*Hungarian, Norwegian & Vietnamese*
Simply input text in any of our supported languages and select a matching voice from our [voice library](https://elevenlabs.io/community). For the most natural results, choose a voice with an accent that matches your target language and region.
### Prompting
The models interpret emotional context directly from the text input. For example, adding
descriptive text like "she said excitedly" or using exclamation marks will influence the speech
emotion. Voice settings like Stability and Similarity help control the consistency, while the
underlying emotion comes from textual cues.
Read the [prompting guide](/docs/best-practices/prompting) for more details.
<Note>
Descriptive text will be spoken out by the model and must be manually trimmed or removed from the
audio if desired.
</Note>
## FAQ
<AccordionGroup>
<Accordion title="Can I clone my own voice?">
Yes, you can create [instant voice clones](/docs/capabilities/voices#cloned) of your own voice
from short audio clips. For high-fidelity clones, check out our [professional voice
cloning](/docs/capabilities/voices#cloned) feature.
</Accordion>
<Accordion title="Do I own the audio output?">
Yes. You retain ownership of any audio you generate. However, commercial usage rights are only
available with paid plans. With a paid subscription, you may use generated audio for commercial
purposes and monetize the outputs if you own the IP rights to the input content.
</Accordion>
<Accordion title="What qualifies as a free regeneration?">
A free regeneration allows you to regenerate the same text to speech content without additional cost, subject to these conditions:
* You can regenerate each piece of content up to 2 times for free
* The content must be exactly the same as the previous generation. Any changes to the text, voice settings, or other parameters will require a new, paid generation
Free regenerations are useful in case there is a slight distortion in the audio output. According to ElevenLabs' internal benchmarks, regenerations will solve roughly half of issues with quality, with remaining issues usually due to poor training data.
</Accordion>
<Accordion title="How do I reduce latency for real-time cases?">
Use the low-latency Flash [models](/docs/models) (Flash v2 or v2.5) optimized for near real-time
conversational or interactive scenarios. See our [latency optimization
guide](/docs/best-practices/latency-optimization) for more details.
</Accordion>
<Accordion title="Why is my output sometimes inconsistent?">
The models are nondeterministic. For consistency, use the optional [seed
parameter](/docs/api-reference/text-to-speech/convert#request.body.seed), though subtle
differences may still occur.
</Accordion>
<Accordion title="What's the best practice for large text conversions?">
Split long text into segments and use streaming for real-time playback and efficient processing.
To maintain natural prosody flow between chunks, include [previous/next text or previous/next
request id parameters](/docs/api-reference/text-to-speech/convert#request.body.previous_text).
</Accordion>
</AccordionGroup>
# Speech to Text
> Learn how to turn spoken audio into text with ElevenLabs.
## Overview
The ElevenLabs [Speech to Text (STT)](/docs/api-reference/speech-to-text) API turns spoken audio into text with state of the art accuracy. Our Scribe v1 [model](/docs/models) adapts to textual cues across 99 languages and multiple voice styles and can be used to:
* Transcribe podcasts, interviews, and other audio or video content
* Generate transcripts for meetings and other audio or video recordings
<CardGroup cols={2}>
<Card title="Developer tutorial" icon="duotone book-sparkles" href="/docs/cookbooks/speech-to-text/synchronous">
Learn how to integrate speech to text into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/playground/speech-to-text">
Step-by-step guide for using speech to text in ElevenLabs.
</Card>
</CardGroup>
<Info>
Companies requiring HIPAA compliance must contact [ElevenLabs
Sales](https://elevenlabs.io/contact-sales) to sign a Business Associate Agreement (BAA)
agreement. Please ensure this step is completed before proceeding with any HIPAA-related
integrations or deployments.
</Info>
## State of the art accuracy
The Scribe v1 model is capable of transcribing audio from up to 32 speakers with high accuracy. Optionally it can also transcribe audio events like laughter, applause, and other non-speech sounds.
The transcribed output supports exact timestamps for each word and audio event, plus diarization to identify the speaker for each word.
The Scribe v1 model is best used for when high-accuracy transcription is required rather than real-time transcription. A low-latency, real-time version will be released soon.
## Pricing
Scribe is free in the [web app](https://elevenlabs.io/app/speech-to-text) until April 9th and has the following price via API:
| Tier     | Price   | Hours Included | Cost per Hour |
| -------- | ------- | -------------- | ------------- |
| Free     | \$0     | 2.5            | Unavailable   |
| Starter  | \$5     | 12.5           | \$0.4         |
| Creator  | \$22    | 63             | \$0.35        |
| Pro      | \$99    | 320            | \$0.31        |
| Scale    | \$330   | 1220           | \$0.27        |
| Business | \$1,320 | 6000           | \$0.22        |
<Note>
If you need more than 6,000 hours per month, please [contact
sales](https://elevenlabs.io/contact-sales)
</Note>
## Examples
The following example shows the output of the Scribe v1 model for a sample audio file.
<elevenlabs-audio-player audio-title="Nicole" audio-src="https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3" />
```javascript
{
"language_code": "en",
"language_probability": 1,
"text": "With a soft and whispery American accent, I'm the ideal choice for creating ASMR content, meditative guides, or adding an intimate feel to your narrative projects.",
"words": [
{
"text": "With",
"start": 0.119,
"end": 0.259,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 0.239,
"end": 0.299,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "a",
"start": 0.279,
"end": 0.359,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 0.339,
"end": 0.499,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "soft",
"start": 0.479,
"end": 1.039,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 1.019,
"end": 1.2,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "and",
"start": 1.18,
"end": 1.359,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 1.339,
"end": 1.44,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "whispery",
"start": 1.419,
"end": 1.979,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 1.959,
"end": 2.179,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "American",
"start": 2.159,
"end": 2.719,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 2.699,
"end": 2.779,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "accent,",
"start": 2.759,
"end": 3.389,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 4.119,
"end": 4.179,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "I'm",
"start": 4.159,
"end": 4.459,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 4.44,
"end": 4.52,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "the",
"start": 4.5,
"end": 4.599,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 4.579,
"end": 4.699,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "ideal",
"start": 4.679,
"end": 5.099,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 5.079,
"end": 5.219,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "choice",
"start": 5.199,
"end": 5.719,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 5.699,
"end": 6.099,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "for",
"start": 6.099,
"end": 6.199,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 6.179,
"end": 6.279,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "creating",
"start": 6.259,
"end": 6.799,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 6.779,
"end": 6.979,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "ASMR",
"start": 6.959,
"end": 7.739,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 7.719,
"end": 7.859,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "content,",
"start": 7.839,
"end": 8.45,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 9,
"end": 9.06,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "meditative",
"start": 9.04,
"end": 9.64,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 9.619,
"end": 9.699,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "guides,",
"start": 9.679,
"end": 10.359,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 10.359,
"end": 10.409,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "or",
"start": 11.319,
"end": 11.439,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 11.42,
"end": 11.52,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "adding",
"start": 11.5,
"end": 11.879,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 11.859,
"end": 12,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "an",
"start": 11.979,
"end": 12.079,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 12.059,
"end": 12.179,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "intimate",
"start": 12.179,
"end": 12.579,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 12.559,
"end": 12.699,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "feel",
"start": 12.679,
"end": 13.159,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 13.139,
"end": 13.179,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "to",
"start": 13.159,
"end": 13.26,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 13.239,
"end": 13.3,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "your",
"start": 13.299,
"end": 13.399,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 13.379,
"end": 13.479,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "narrative",
"start": 13.479,
"end": 13.889,
"type": "word",
"speaker_id": "speaker_0"
},
{
"text": " ",
"start": 13.919,
"end": 13.939,
"type": "spacing",
"speaker_id": "speaker_0"
},
{
"text": "projects.",
"start": 13.919,
"end": 14.779,
"type": "word",
"speaker_id": "speaker_0"
}
]
}
```
The output is classified in three category types:
* `word` - A word in the language of the audio
* `spacing` - The space between words, not applicable for languages that don't use spaces like Japanese, Mandarin, Thai, Lao, Burmese and Cantonese
* `audio_event` - Non-speech sounds like laughter or applause
## Models
<CardGroup cols={1} rows={1}>
<Card title="Scribe v1" href="/docs/models#scribe-v1">
State-of-the-art speech recognition model
<div>
<div>
Accurate transcription in 99 languages
</div>
<div>
Precise word-level timestamps
</div>
<div>
Speaker diarization
</div>
<div>
Dynamic audio tagging
</div>
</div>
</Card>
</CardGroup>
<div>
<div>
[Explore all](/docs/models)
</div>
</div>
## Supported languages
The Scribe v1 model supports 99 languages, including:
*Afrikaans (afr), Amharic (amh), Arabic (ara), Armenian (hye), Assamese (asm), Asturian (ast), Azerbaijani (aze), Belarusian (bel), Bengali (ben), Bosnian (bos), Bulgarian (bul), Burmese (mya), Cantonese (yue), Catalan (cat), Cebuano (ceb), Chichewa (nya), Croatian (hrv), Czech (ces), Danish (dan), Dutch (nld), English (eng), Estonian (est), Filipino (fil), Finnish (fin), French (fra), Fulah (ful), Galician (glg), Ganda (lug), Georgian (kat), German (deu), Greek (ell), Gujarati (guj), Hausa (hau), Hebrew (heb), Hindi (hin), Hungarian (hun), Icelandic (isl), Igbo (ibo), Indonesian (ind), Irish (gle), Italian (ita), Japanese (jpn), Javanese (jav), Kabuverdianu (kea), Kannada (kan), Kazakh (kaz), Khmer (khm), Korean (kor), Kurdish (kur), Kyrgyz (kir), Lao (lao), Latvian (lav), Lingala (lin), Lithuanian (lit), Luo (luo), Luxembourgish (ltz), Macedonian (mkd), Malay (msa), Malayalam (mal), Maltese (mlt), Mandarin Chinese (cmn), Māori (mri), Marathi (mar), Mongolian (mon), Nepali (nep), Northern Sotho (nso), Norwegian (nor), Occitan (oci), Odia (ori), Pashto (pus), Persian (fas), Polish (pol), Portuguese (por), Punjabi (pan), Romanian (ron), Russian (rus), Serbian (srp), Shona (sna), Sindhi (snd), Slovak (slk), Slovenian (slv), Somali (som), Spanish (spa), Swahili (swa), Swedish (swe), Tamil (tam), Tajik (tgk), Telugu (tel), Thai (tha), Turkish (tur), Ukrainian (ukr), Umbundu (umb), Urdu (urd), Uzbek (uzb), Vietnamese (vie), Welsh (cym), Wolof (wol), Xhosa (xho) and Zulu (zul).*
### Breakdown of language support
Word Error Rate (WER) is a key metric used to evaluate the accuracy of transcription systems. It measures how many errors are present in a transcript compared to a reference transcript. Below is a breakdown of the WER for each language that Scribe v1 supports.
<AccordionGroup>
<Accordion title="Excellent (≤ 5% WER)">
Bulgarian (bul), Catalan (cat), Czech (ces), Danish (dan), Dutch (nld), English (eng), Finnish
(fin), French (fra), Galician (glg), German (deu), Greek (ell), Hindi (hin), Indonesian (ind),
Italian (ita), Japanese (jpn), Kannada (kan), Malay (msa), Malayalam (mal), Macedonian (mkd),
Norwegian (nor), Polish (pol), Portuguese (por), Romanian (ron), Russian (rus), Serbian (srp),
Slovak (slk), Spanish (spa), Swedish (swe), Turkish (tur), Ukrainian (ukr) and Vietnamese (vie).
</Accordion>
<Accordion title="High Accuracy (>5% to ≤10% WER)">
Bengali (ben), Belarusian (bel), Bosnian (bos), Cantonese (yue), Estonian (est), Filipino (fil),
Gujarati (guj), Hungarian (hun), Kazakh (kaz), Latvian (lav), Lithuanian (lit), Mandarin (cmn),
Marathi (mar), Nepali (nep), Odia (ori), Persian (fas), Slovenian (slv), Tamil (tam) and Telugu
(tel)
</Accordion>
<Accordion title="Good (>10% to ≤25% WER)">
Afrikaans (afr), Arabic (ara), Armenian (hye), Assamese (asm), Asturian (ast), Azerbaijani
(aze), Burmese (mya), Cebuano (ceb), Croatian (hrv), Georgian (kat), Hausa (hau), Hebrew (heb),
Icelandic (isl), Javanese (jav), Kabuverdianu (kea), Korean (kor), Kyrgyz (kir), Lingala (lin),
Maltese (mlt), Mongolian (mon), Māori (mri), Occitan (oci), Punjabi (pan), Sindhi (snd), Swahili
(swa), Tajik (tgk), Thai (tha), Urdu (urd), Uzbek (uzb) and Welsh (cym).
</Accordion>
<Accordion title="Moderate (>25% to ≤50% WER)">
Amharic (amh), Chichewa (nya), Fulah (ful), Ganda (lug), Igbo (ibo), Irish (gle), Khmer (khm),
Kurdish (kur), Lao (lao), Luxembourgish (ltz), Luo (luo), Northern Sotho (nso), Pashto (pus),
Shona (sna), Somali (som), Umbundu (umb), Wolof (wol), Xhosa (xho) and Zulu (zul).
</Accordion>
</AccordionGroup>
## FAQ
<AccordionGroup>
<Accordion title="Can I use speech to text with video files?">
Yes, the API supports uploading both audio and video files for transcription.
</Accordion>
<Accordion title="What are the file size and duration limits?">
Files up to 1 GB in size and up to 2 hours in duration are supported.
</Accordion>
<Accordion title="Which audio and video formats are supported?">
The audio supported audio formats include:
* audio/aac
* audio/x-aac
* audio/x-aiff
* audio/ogg
* audio/mpeg
* audio/mp3
* audio/mpeg3
* audio/x-mpeg-3
* audio/opus
* audio/wav
* audio/x-wav
* audio/webm
* audio/flac
* audio/x-flac
* audio/mp4
* audio/aiff
* audio/x-m4a
Supported video formats include:
* video/mp4
* video/x-msvideo
* video/x-matroska
* video/quicktime
* video/x-ms-wmv
* video/x-flv
* video/webm
* video/mpeg
* video/3gpp
</Accordion>
<Accordion title="When will you support more languages?">
ElevenLabs is constantly expanding the number of languages supported by our models. Please check back frequently for updates.
</Accordion>
</AccordionGroup>
# Voice changer
> Learn how to transform audio between voices while preserving emotion and delivery.
## Overview
ElevenLabs [voice changer](/docs/api-reference/speech-to-speech/convert) API lets you transform any source audio (recorded or uploaded) into a different, fully cloned voice without losing the performance nuances of the original. It’s capable of capturing whispers, laughs, cries, accents, and subtle emotional cues to achieve a highly realistic, human feel and can be used to:
* Change any voice while preserving emotional delivery and nuance
* Create consistent character voices across multiple languages and recording sessions
* Fix or replace specific words and phrases in existing recordings
<CardGroup cols={1}>
<video width="100%" height="400" controls>
<source src="https://eleven-public-cdn.elevenlabs.io/payloadcms/z2o584jt3pn-speech-to-speech-promo.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
</CardGroup>
Explore our [voice library](https://elevenlabs.io/community) to find the perfect voice for your project.
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Learn how to integrate voice changer into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/playground/voice-changer">
Step-by-step guide for using voice changer in ElevenLabs.
</Card>
</CardGroup>
## Supported languages
Our v2 models support 29 languages:
*English (USA, UK, Australia, Canada), Japanese, Chinese, German, Hindi, French (France, Canada), Korean, Portuguese (Brazil, Portugal), Italian, Spanish (Spain, Mexico), Indonesian, Dutch, Turkish, Filipino, Polish, Swedish, Bulgarian, Romanian, Arabic (Saudi Arabia, UAE), Czech, Greek, Finnish, Croatian, Malay, Slovak, Danish, Tamil, Ukrainian & Russian.*
The `eleven_english_sts_v2` model only supports English.
## Best practices
### Audio quality
* Record in a quiet environment to minimize background noise
* Maintain appropriate microphone levels - avoid too quiet or peaked audio
* Use `remove_background_noise=true` if environmental sounds are present
### Recording guidelines
* Keep segments under 5 minutes for optimal processing
* Feel free to include natural expressions (laughs, sighs, emotions)
* The source audio's accent and language will be preserved in the output
### Parameters
* **Style**: Set to 0% when input audio is already expressive
* **Stability**: Use 100% for maximum voice consistency
* **Language**: Choose source audio that matches your desired accent and language
## FAQ
<AccordionGroup>
<Accordion title="Can I convert more than 5 minutes of audio?">
Yes, but you must split it into smaller chunks (each under 5 minutes). This helps ensure stability
and consistent output.
</Accordion>
<Accordion title="Can I use my own custom/cloned voice for output?">
Absolutely. Provide your custom voice’s <code>voice\_id</code> and specify the correct{' '}
<code>model\_id</code>.
</Accordion>
<Accordion title="How is billing handled?">
You’re charged at 1000 characters’ worth of usage per minute of processed audio. There’s no
additional fee based on file size.
</Accordion>
<Accordion title="Does the model reproduce background noise?">
Possibly. Use <code>remove\_background\_noise=true</code> or the Voice Isolator tool to minimize
environmental sounds in the final output.
</Accordion>
<Accordion title="Which model is best for English audio?">
Though <code>eleven\_english\_sts\_v2</code> is available, our{' '}
<code>eleven\_multilingual\_sts\_v2</code> model often outperforms it, even for English material.
</Accordion>
<Accordion title="How does style & stability work?">
“Style” adds interpretative flair; “stability” enforces consistency. For high-energy performances
in the source audio, turn style down and stability up.
</Accordion>
</AccordionGroup>
# Voice isolator
> Learn how to isolate speech from background noise, music, and ambient sounds from any audio.
## Overview
ElevenLabs [voice isolator](/docs/api-reference/audio-isolation/audio-isolation) API transforms audio recordings with background noise into clean, studio-quality speech. This is particularly useful for audio recorded in noisy environments, or recordings containing unwanted ambient sounds, music, or other background interference.
Listen to a sample:
<CardGroup cols={2}>
<elevenlabs-audio-player audio-title="Original audio" audio-src="https://eleven-public-cdn.elevenlabs.io/audio/voice-isolator/voice-isolator-promo-original.mp3" />
<elevenlabs-audio-player audio-title="Isolated audio" audio-src="https://eleven-public-cdn.elevenlabs.io/audio/voice-isolator/voice-isolator-promo-isolated.mp3" />
</CardGroup>
## Usage
The voice isolator model extracts speech from background noise in both audio and video files.
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Learn how to integrate voice isolator into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/audio-tools/voice-isolator">
Step-by-step guide for using voice isolator in ElevenLabs.
</Card>
</CardGroup>
### Supported file types
* **Audio**: AAC, AIFF, OGG, MP3, OPUS, WAV, FLAC, M4A
* **Video**: MP4, AVI, MKV, MOV, WMV, FLV, WEBM, MPEG, 3GPP
## FAQ
* **Cost**: Voice isolator costs 1000 characters for every minute of audio.
* **File size and length**: Supports files up to 500MB and 1 hour in length.
* **Music vocals**: Not specifically optimized for isolating vocals from music, but may work depending on the content.
# Dubbing
> Learn how to translate audio and video while preserving the emotion, timing & tone of speakers.
## Overview
ElevenLabs [dubbing](/docs/api-reference/dubbing/dub-a-video-or-an-audio-file) API translates audio and video across 32 languages while preserving the emotion, timing, tone and unique characteristics of each speaker. Our model separates each speaker’s dialogue from the soundtrack, allowing you to recreate the original delivery in another language. It can be used to:
* Grow your addressable audience by 4x to reach international audiences
* Adapt existing material for new markets while preserving emotional nuance
* Offer content in multiple languages without re-recording voice talent
<CardGroup cols={1}>
<video width="100%" height="400" controls>
<source src="https://eleven-public-cdn.elevenlabs.io/payloadcms/zi2mer0h44p-dubbing-studio-demo.mp4" type="video/mp4" />
Your browser does not support the video tag.
</video>
</CardGroup>
We also offer a [fully managed dubbing service](https://elevenlabs.io/elevenstudios) for video and podcast creators.
## Usage
ElevenLabs dubbing can be used in two ways:
* **Dubbing Studio** in the user interface for fast, interactive control and editing
* **Programmatic integration** via our [API](/docs/api-reference/dubbing/dub-a-video-or-an-audio-file) for large-scale or automated workflows
The UI supports files up to **500MB** and **45 minutes**. The API supports files up to **1GB** and **2.5 hours**.
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Learn how to integrate dubbing into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/products/dubbing">
Edit transcripts and translate videos step by step in Dubbing Studio.
</Card>
</CardGroup>
### Key features
**Speaker separation**\
Automatically detect multiple speakers, even with overlapping speech.
**Multi-language output**\
Generate localized tracks in 32 languages.
**Preserve original voices**\
Retain the speaker’s identity and emotional tone.
**Keep background audio**\
Avoid re-mixing music, effects, or ambient sounds.
**Customizable transcripts**\
Manually edit translations and transcripts as needed.
**Supported file types**\
Videos and audio can be dubbed from various sources, including YouTube, X, TikTok, Vimeo, direct URLs, or file uploads.
**Video transcript and translation editing**\
Our AI video translator lets you manually edit transcripts and translations to ensure your content is properly synced and localized. Adjust the voice settings to tune delivery, and regenerate speech segments until the output sounds just right.
<Note>
A Creator plan or higher is required to dub audio files. For videos, a watermark option is
available to reduce credit usage.
</Note>
### Cost
To reduce credit usage, you can:
* Dub only a selected portion of your file
* Use watermarks on video output (not available for audio)
* Fine-tune transcripts and regenerate individual segments instead of the entire clip
Refer to our [pricing page](https://elevenlabs.io/pricing) for detailed credit costs.
## FAQ
<AccordionGroup>
<Accordion title="What content can I dub?">
Dubbing can be performed on all types of short and long form video and audio content. We
recommend dubbing content with a maximum of 9 unique speakers at a time to ensure a high-quality
dub.
</Accordion>
<Accordion title="Does dubbing preserve the speaker's natural intonation?">
Yes. Our models analyze each speaker’s original delivery to recreate the same tone, pace, and
style in your target language.
</Accordion>
<Accordion title="What about overlapping speakers or background noise?">
We use advanced source separation to isolate individual voices from ambient sound. Multiple
overlapping speakers can be split into separate tracks.
</Accordion>
<Accordion title="Are there file size limits?">
Via the user interface, the maximum file size is 500MB up to 45 minutes. Through the API, you
can process files up to 1GB and 2.5 hours.
</Accordion>
<Accordion title="How do I handle fine-tuning or partial translations?">
You can choose to dub only certain portions of your video/audio or tweak translations/voices in
our interactive Dubbing Studio.
</Accordion>
</AccordionGroup>
# Sound effects
> Learn how to create high-quality sound effects from text with ElevenLabs.
## Overview
ElevenLabs [sound effects](/docs/api-reference/text-to-sound-effects/convert) API turns text descriptions into high-quality audio effects with precise control over timing, style and complexity. The model understands both natural language and audio terminology, enabling you to:
* Generate cinematic sound design for films & trailers
* Create custom sound effects for games & interactive media
* Produce Foley and ambient sounds for video content
Listen to an example:
<elevenlabs-audio-player audio-title="Cinematic braam" audio-src="https://github.com/elevenlabs/elevenlabs-docs/raw/refs/heads/main/fern/assets/audio/sfx-cinematic-braam.mp3" />
## Usage
Sound effects are generated using text descriptions & two optional parameters:
* **Duration**: Set a specific length for the generated audio (in seconds)
* Default: Automatically determined based on the prompt
* Range: 0.1 to 30 seconds
* Cost: 40 characters per second when duration is specified
* **Prompt influence**: Control how strictly the model follows the prompt
* High: More literal interpretation of the prompt
* Low: More creative interpretation with added variations
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Learn how to integrate sound effects into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/playground/sound-effects">
Step-by-step guide for using sound effects in ElevenLabs.
</Card>
</CardGroup>
### Prompting guide
#### Simple effects
For basic sound effects, use clear, concise descriptions:
* "Glass shattering on concrete"
* "Heavy wooden door creaking open"
* "Thunder rumbling in the distance"
<elevenlabs-audio-player audio-title="Wood chopping" audio-src="https://github.com/elevenlabs/elevenlabs-docs/raw/refs/heads/main/fern/assets/audio/sfx-wood-chopping.mp3" />
#### Complex sequences
For multi-part sound effects, describe the sequence of events:
* "Footsteps on gravel, then a metallic door opens"
* "Wind whistling through trees, followed by leaves rustling"
* "Sword being drawn, then clashing with another blade"
<elevenlabs-audio-player audio-title="Walking and then falling" audio-src="https://github.com/elevenlabs/elevenlabs-docs/raw/refs/heads/main/fern/assets/audio/sfx-walking-falling.mp3" />
#### Musical elements
The API also supports generation of musical components:
* "90s hip-hop drum loop, 90 BPM"
* "Vintage brass stabs in F minor"
* "Atmospheric synth pad with subtle modulation"
<elevenlabs-audio-player audio-title="90s drum loop" audio-src="https://github.com/elevenlabs/elevenlabs-docs/raw/refs/heads/main/fern/assets/audio/sfx-90s-drum-loop.mp3" />
#### Audio Terminology
Common terms that can enhance your prompts:
* **Impact**: Collision or contact sounds between objects, from subtle taps to dramatic crashes
* **Whoosh**: Movement through air effects, ranging from fast and ghostly to slow-spinning or rhythmic
* **Ambience**: Background environmental sounds that establish atmosphere and space
* **One-shot**: Single, non-repeating sound
* **Loop**: Repeating audio segment
* **Stem**: Isolated audio component
* **Braam**: Big, brassy cinematic hit that signals epic or dramatic moments, common in trailers
* **Glitch**: Sounds of malfunction, jittering, or erratic movement, useful for transitions and sci-fi
* **Drone**: Continuous, textured sound that creates atmosphere and suspense
## FAQ
<AccordionGroup>
<Accordion title="What's the maximum duration for generated effects?">
The maximum duration is 30 seconds per generation. For longer sequences, generate multiple
effects and combine them.
</Accordion>
<Accordion title="Can I generate music with this API?">
Yes, you can generate musical elements like drum loops, bass lines, and melodic samples.
However, for full music production, consider combining multiple generated elements.
</Accordion>
<Accordion title="How do I ensure consistent quality?">
Use detailed prompts, appropriate duration settings, and high prompt influence for more
predictable results. For complex sounds, generate components separately and combine them.
</Accordion>
<Accordion title="What audio formats are supported?">
Generated audio is provided in MP3 format with professional-grade quality (44.1kHz,
128-192kbps).
</Accordion>
</AccordionGroup>
# Voices
> Learn how to create, customize, and manage voices with ElevenLabs.
## Overview
ElevenLabs provides models for voice creation & customization. The platform supports a wide range of voice options, including voices from our extensive [voice library](https://elevenlabs.io/app/voice-library), voice cloning, and artificially designed voices using text prompts.
### Voice categories
* **Community**: Voices shared by the community from the ElevenLabs [voice library](/docs/product-guides/voices/voice-library).
* **Cloned**: Custom voices created using instant or professional [voice cloning](/docs/product-guides/voices/voice-cloning).
* **Voice design**: Artificially designed voices created with the [voice design](/docs/product-guides/voices/voice-design) tool.
* **Default**: Pre-designed, high-quality voices optimized for general use.
#### Community
The [voice library](/docs/product-guides/voices/voice-library) contains over 5,000 voices shared by the ElevenLabs community. Use it to:
* Discover unique voices shared by the ElevenLabs community.
* Add voices to your personal collection.
* Share your own voice clones for cash rewards when others use it.
<Success>
Share your voice with the community, set your terms, and earn cash rewards when others use it.
We've paid out over **\$1M** already.
</Success>
<CardGroup cols={1}>
<Card title="Product guide" icon="duotone book-user" iconPosition="left" href="/docs/product-guides/voices/voice-library">
Learn how to use voices from the voice library
</Card>
</CardGroup>
#### Cloned
Clone your own voice from 30-second samples with Instant Voice Cloning, or create hyper-realistic voices using Professional Voice Cloning.
* **Instant Voice Cloning**: Quickly replicate a voice from short audio samples.
* **Professional Voice Cloning**: Generate professional-grade voice clones with extended training audio.
Voice-captcha technology is used to verify that **all** voice clones are created from your own voice samples.
<Note>
A Creator plan or higher is required to create voice clones.
</Note>
<CardGroup cols={1}>
<Card title="Product guide" icon="duotone book-user" iconPosition="left" href="/docs/product-guides/voices/voice-cloning">
Learn how to create instant & professional voice clones
</Card>
</CardGroup>
#### Voice design
With [Voice Design](/docs/product-guides/voices/voice-design), you can create entirely new voices by specifying attributes like age, gender, accent, and tone. Generated voices are ideal for:
* Realistic voices with nuanced characteristics.
* Creative character voices for games and storytelling.
The voice design tool creates 3 voice previews, simply provide:
* A **voice description** between 20 and 1000 characters.
* Some **text** to preview the voice between 100 and 1000 characters.
<CardGroup cols={2}>
<Card title="Developer quickstart" icon="duotone book-sparkles" href="/docs/quickstart">
Integrate voice design into your application.
</Card>
<Card title="Product guide" icon="duotone book-user" href="/docs/product-guides/voices/voice-design">
Learn how to craft voices from a single prompt.
</Card>
</CardGroup>
#### Default
Our curated set of default voices is optimized for core use cases. These voices are:
* **Reliable**: Available long-term.
* **Consistent**: Carefully crafted and quality-checked for performance.
* **Model-ready**: Fine-tuned on new models upon release.
<Info>
Default voices are available to all users via the **my voices** tab in the [voice lab
dashboard](https://elevenlabs.io/app/voice-lab). Default voices were previously referred to as
`premade` voices. The latter term is still used when accessing default voices via the API.
</Info>
### Managing voices
All voices can be managed through **My Voices**, where you can:
* Search, filter, and categorize voices
* Add descriptions and custom tags
* Organize voices for quick access
Learn how to manage your voice collection in [My Voices documentation](/docs/product-guides/voices/voice-library).
* **Search and Filter**: Find voices using keywords or tags.
* **Preview Samples**: Listen to voice demos before adding them to **My Voices**.
* **Add to Collection**: Save voices for easy access in your projects.
> **Tip**: Try searching by specific accents or genres, such as "Australian narration" or "child-like character."
### Supported languages
All ElevenLabs voices support multiple languages. Experiment by converting phrases like `Hello! こんにちは! Bonjour!` into speech to hear how your own voice sounds across different languages.
ElevenLabs supports voice creation in 32 languages. Match your voice selection to your target region for the most natural results.
* **Default Voices**: Optimized for multilingual use.
* **Generated and Cloned Voices**: Accent fidelity depends on input samples or selected attributes.
Our v2 models support 29 languages:
*English (USA, UK, Australia, Canada), Japanese, Chinese, German, Hindi, French (France, Canada), Korean, Portuguese (Brazil, Portugal), Italian, Spanish (Spain, Mexico), Indonesian, Dutch, Turkish, Filipino, Polish, Swedish, Bulgarian, Romanian, Arabic (Saudi Arabia, UAE), Czech, Greek, Finnish, Croatian, Malay, Slovak, Danish, Tamil, Ukrainian & Russian.*
Flash v2.5 supports 32 languages - all languages from v2 models plus:
*Hungarian, Norwegian & Vietnamese*
[Learn more about our models](/docs/models)
## FAQ
<AccordionGroup>
<Accordion title="Can I create a custom voice?">
Yes, you can create custom voices with Voice Design or clone voices using Instant or
Professional Voice Cloning. Both options are accessible in **My Voices**.
</Accordion>
<Accordion title="What is the difference between Instant and Professional Voice Cloning?">
Instant Voice Cloning uses short audio samples for near-instantaneous voice creation.
Professional Voice Cloning requires longer samples but delivers hyper-realistic, high-quality
results.
</Accordion>
<Accordion title="Can I share my created voices?">
Professional Voice Clones can be shared privately or publicly in the Voice Library. Generated
voices and Instant Voice Clones cannot currently be shared.
</Accordion>
<Accordion title="How do I manage my voices?">
Use **My Voices** to search, filter, and organize your voice collection. You can also delete,
tag, and categorize voices for easier management.
</Accordion>
<Accordion title="How can I ensure my cloned voice matches the original?">
Use clean and consistent audio samples. For Professional Voice Cloning, provide a variety of
recordings in the desired speaking style.
</Accordion>
<Accordion title="Can I share voices I create?">
Yes, Professional Voice Clones can be shared in the Voice Library. Instant Voice Clones and
Generated Voices cannot currently be shared.
</Accordion>
<Accordion title="What are some common use cases for Generated Voices?">
Generated Voices are ideal for unique characters in games, animations, and creative
storytelling.
</Accordion>
<Accordion title="How do I access the Voice Library?">
Go to **Voices > Voice Library** in your dashboard or access it via API.
</Accordion>
</AccordionGroup>
# Streaming text to speech
> Learn how to stream text into speech in Python or Node.js.
In this tutorial, you'll learn how to convert [text to speech](https://elevenlabs.io/text-to-speech) with the ElevenLabs SDK. We’ll start by talking through how to generate speech and receive a file and then how to generate speech and stream the response back. Finally, as a bonus we’ll show you how to upload the generated audio to an AWS S3 bucket, and share it through a signed URL. This signed URL will provide temporary access to the audio file, making it perfect for sharing with users by SMS or embedding into an application.
If you want to jump straight to an example you can find them in the [Python](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/python) and [Node.js](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/node) example repositories.
## Requirements
* An ElevenLabs account with an API key (here’s how to [find your API key](/docs/developer-guides/quickstart#authentication)).
* Python or Node installed on your machine
* (Optionally) an AWS account with access to S3.
## Setup
### Installing our SDK
Before you begin, make sure you have installed the necessary SDKs and libraries. You will need the ElevenLabs SDK for the text to speech conversion. You can install it using pip:
<CodeGroup>
```bash Python
pip install elevenlabs
```
```bash TypeScript
npm install elevenlabs
```
</CodeGroup>
Additionally, install necessary packages to manage your environmental variables:
<CodeGroup>
```bash Python
pip install python-dotenv
```
```bash TypeScript
npm install dotenv
npm install @types/dotenv --save-dev
```
</CodeGroup>
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```bash .env
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
## Convert text to speech (file)
To convert text to speech and save it as a file, we’ll use the `convert` method of the ElevenLabs SDK and then it locally as a `.mp3` file.
<CodeGroup>
```python text_to_speech_file.py (Python)
import os
import uuid
from elevenlabs import VoiceSettings
from elevenlabs.client import ElevenLabs
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(
api_key=ELEVENLABS_API_KEY,
)
def text_to_speech_file(text: str) -> str:
# Calling the text_to_speech conversion API with detailed parameters
response = client.text_to_speech.convert(
voice_id="pNInz6obpgDQGcFmaJgB", # Adam pre-made voice
output_format="mp3_22050_32",
text=text,
model_id="eleven_turbo_v2_5", # use the turbo model for low latency
# Optional voice settings that allow you to customize the output
voice_settings=VoiceSettings(
stability=0.0,
similarity_boost=1.0,
style=0.0,
use_speaker_boost=True,
speed=1.0,
),
)
# uncomment the line below to play the audio back
# play(response)
# Generating a unique file name for the output MP3 file
save_file_path = f"{uuid.uuid4()}.mp3"
# Writing the audio to a file
with open(save_file_path, "wb") as f:
for chunk in response:
if chunk:
f.write(chunk)
print(f"{save_file_path}: A new audio file was saved successfully!")
# Return the path of the saved audio file
return save_file_path
```
```typescript text_to_speech_file.ts (Typescript)
import * as dotenv from 'dotenv';
import { ElevenLabsClient } from 'elevenlabs';
import { createWriteStream } from 'fs';
import { v4 as uuid } from 'uuid';
dotenv.config();
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const client = new ElevenLabsClient({
apiKey: ELEVENLABS_API_KEY,
});
export const createAudioFileFromText = async (text: string): Promise<string> => {
return new Promise<string>(async (resolve, reject) => {
try {
const audio = await client.textToSpeech.convert('JBFqnCBsd6RMkjVDRZzb', {
model_id: 'eleven_multilingual_v2',
text,
output_format: 'mp3_44100_128',
// Optional voice settings that allow you to customize the output
voice_settings: {
stability: 0,
similarity_boost: 0,
use_speaker_boost: true,
speed: 1.0,
},
});
const fileName = `${uuid()}.mp3`;
const fileStream = createWriteStream(fileName);
audio.pipe(fileStream);
fileStream.on('finish', () => resolve(fileName)); // Resolve with the fileName
fileStream.on('error', reject);
} catch (error) {
reject(error);
}
});
};
```
</CodeGroup>
You can then run this function with:
<CodeGroup>
```python Python
text_to_speech_file("Hello World")
```
```typescript TypeScript
await createAudioFileFromText('Hello World');
```
</CodeGroup>
## Convert text to speech (streaming)
If you prefer to stream the audio directly without saving it to a file, you can use our streaming feature.
<CodeGroup>
```python text_to_speech_stream.py (Python)
import os
from typing import IO
from io import BytesIO
from elevenlabs import VoiceSettings
from elevenlabs.client import ElevenLabs
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(
api_key=ELEVENLABS_API_KEY,
)
def text_to_speech_stream(text: str) -> IO[bytes]:
# Perform the text-to-speech conversion
response = client.text_to_speech.convert(
voice_id="pNInz6obpgDQGcFmaJgB", # Adam pre-made voice
output_format="mp3_22050_32",
text=text,
model_id="eleven_multilingual_v2",
# Optional voice settings that allow you to customize the output
voice_settings=VoiceSettings(
stability=0.0,
similarity_boost=1.0,
style=0.0,
use_speaker_boost=True,
speed=1.0,
),
)
# Create a BytesIO object to hold the audio data in memory
audio_stream = BytesIO()
# Write each chunk of audio data to the stream
for chunk in response:
if chunk:
audio_stream.write(chunk)
# Reset stream position to the beginning
audio_stream.seek(0)
# Return the stream for further use
return audio_stream
```
```typescript text_to_speech_stream.ts (Typescript)
import * as dotenv from 'dotenv';
import { ElevenLabsClient } from 'elevenlabs';
dotenv.config();
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
if (!ELEVENLABS_API_KEY) {
throw new Error('Missing ELEVENLABS_API_KEY in environment variables');
}
const client = new ElevenLabsClient({
apiKey: ELEVENLABS_API_KEY,
});
export const createAudioStreamFromText = async (text: string): Promise<Buffer> => {
const audioStream = await client.textToSpeech.convertAsStream('JBFqnCBsd6RMkjVDRZzb', {
model_id: 'eleven_multilingual_v2',
text,
output_format: 'mp3_44100_128',
// Optional voice settings that allow you to customize the output
voice_settings: {
stability: 0,
similarity_boost: 1.0,
use_speaker_boost: true,
speed: 1.0,
},
});
const chunks: Buffer[] = [];
for await (const chunk of audioStream) {
chunks.push(chunk);
}
const content = Buffer.concat(chunks);
return content;
};
```
</CodeGroup>
You can then run this function with:
<CodeGroup>
```python Python
text_to_speech_stream("This is James")
```
```typescript TypeScript
await createAudioStreamFromText('This is James');
```
</CodeGroup>
## Bonus - Uploading to AWS S3 and getting a secure sharing link
Once your audio data is created as either a file or a stream you might want to share this with your users. One way to do this is to upload it to an AWS S3 bucket and generate a secure sharing link.
<AccordionGroup>
<Accordion title="Creating your AWS credentials">
To upload the data to S3 you’ll need to add your AWS access key ID, secret access key and AWS region name to your `.env` file. Follow these steps to find the credentials:
1. Log in to your AWS Management Console: Navigate to the AWS home page and sign in with your account.
<Frame caption="AWS Console Login">
<img src="file:13896c7f-471a-4b4e-b8f3-bd334adcb5c9" />
</Frame>
2. Access the IAM (Identity and Access Management) Dashboard: You can find IAM under "Security, Identity, & Compliance" on the services menu. The IAM dashboard manages access to your AWS services securely.
<Frame caption="AWS IAM Dashboard">
<img src="file:a4242a81-a41f-4ab7-82fc-da378caa0cc2" />
</Frame>
3. Create a New User (if necessary): On the IAM dashboard, select "Users" and then "Add user". Enter a user name.
<Frame caption="Add AWS IAM User">
<img src="file:556c3c0d-7e87-4408-af43-f5030d90f0a8" />
</Frame>
4. Set the permissions: attach policies directly to the user according to the access level you wish to grant. For S3 uploads, you can use the AmazonS3FullAccess policy. However, it's best practice to grant least privilege, or the minimal permissions necessary to perform a task. You might want to create a custom policy that specifically allows only the necessary actions on your S3 bucket.
<Frame caption="Set Permission for AWS IAM User">
<img src="file:2d1868b3-70aa-4da4-8f73-6eba268cf0a1" />
</Frame>
5. Review and create the user: Review your settings and create the user. Upon creation, you'll be presented with an access key ID and a secret access key. Be sure to download and securely save these credentials; the secret access key cannot be retrieved again after this step.
<Frame caption="AWS Access Secret Key">
<img src="file:789ea5eb-6d00-4f5a-bee1-4d2cb237c26d" />
</Frame>
6. Get AWS region name: ex. us-east-1
<Frame caption="AWS Region Name">
<img src="file:f65d2511-3d1a-4d88-8192-b4b454a7ceea" />
</Frame>
If you do not have an AWS S3 bucket, you will need to create a new one by following these steps:
1. Access the S3 dashboard: You can find S3 under "Storage" on the services menu.
<Frame caption="AWS S3 Dashboard">
<img src="file:f341b50c-74cb-4adf-be7f-6ede28774e77" />
</Frame>
2. Create a new bucket: On the S3 dashboard, click the "Create bucket" button.
<Frame caption="Click Create Bucket Button">
<img src="file:97f63c5d-39e3-4cc8-8b10-378ec175e149" />
</Frame>
3. Enter a bucket name and click on the "Create bucket" button. You can leave the other bucket options as default. The newly added bucket will appear in the list.
<Frame caption="Enter a New S3 Bucket Name">
<img src="file:74026607-2ea2-4829-860e-495bbbc4c9d5" />
</Frame>
<Frame caption="S3 Bucket List">
<img src="file:54988a9c-99a3-45a8-93f0-ce0def1414cf" />
</Frame>
</Accordion>
<Accordion title="Installing the AWS SDK and adding the credentials">
Install `boto3` for interacting with AWS services using `pip` and `npm`.
<CodeGroup>
```bash Python
pip install boto3
```
```bash TypeScript
npm install @aws-sdk/client-s3
npm install @aws-sdk/s3-request-presigner
```
</CodeGroup>
Then add the environment variables to `.env` file like so:
```
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here
AWS_REGION_NAME=your_aws_region_name_here
AWS_S3_BUCKET_NAME=your_s3_bucket_name_here
```
</Accordion>
<Accordion title="Uploading to AWS S3 and generating the signed URL">
Add the following functions to upload the audio stream to S3 and generate a signed URL.
<CodeGroup>
```python s3_uploader.py (Python)
import os
import boto3
import uuid
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION_NAME = os.getenv("AWS_REGION_NAME")
AWS_S3_BUCKET_NAME = os.getenv("AWS_S3_BUCKET_NAME")
session = boto3.Session(
aws_access_key_id=AWS_ACCESS_KEY_ID,
aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
region_name=AWS_REGION_NAME,
)
s3 = session.client("s3")
def generate_presigned_url(s3_file_name: str) -> str:
signed_url = s3.generate_presigned_url(
"get_object",
Params={"Bucket": AWS_S3_BUCKET_NAME, "Key": s3_file_name},
ExpiresIn=3600,
)  # URL expires in 1 hour
return signed_url
def upload_audiostream_to_s3(audio_stream) -> str:
s3_file_name = f"{uuid.uuid4()}.mp3"  # Generates a unique file name using UUID
s3.upload_fileobj(audio_stream, AWS_S3_BUCKET_NAME, s3_file_name)
return s3_file_name
```
```typescript s3_uploader.ts (TypeScript)
import { S3Client, PutObjectCommand, GetObjectCommand } from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import * as dotenv from 'dotenv';
import { v4 as uuid } from 'uuid';
dotenv.config();
const { AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION_NAME, AWS_S3_BUCKET_NAME } =
process.env;
if (!AWS_ACCESS_KEY_ID || !AWS_SECRET_ACCESS_KEY || !AWS_REGION_NAME || !AWS_S3_BUCKET_NAME) {
throw new Error('One or more environment variables are not set. Please check your .env file.');
}
const s3 = new S3Client({
credentials: {
accessKeyId: AWS_ACCESS_KEY_ID,
secretAccessKey: AWS_SECRET_ACCESS_KEY,
},
region: AWS_REGION_NAME,
});
export const generatePresignedUrl = async (objectKey: string) => {
const getObjectParams = {
Bucket: AWS_S3_BUCKET_NAME,
Key: objectKey,
Expires: 3600,
};
const command = new GetObjectCommand(getObjectParams);
const url = await getSignedUrl(s3, command, { expiresIn: 3600 });
return url;
};
export const uploadAudioStreamToS3 = async (audioStream: Buffer) => {
const remotePath = `${uuid()}.mp3`;
await s3.send(
new PutObjectCommand({
Bucket: AWS_S3_BUCKET_NAME,
Key: remotePath,
Body: audioStream,
ContentType: 'audio/mpeg',
})
);
return remotePath;
};
```
</CodeGroup>
You can then call uploading function with the audio stream from the text.
<CodeGroup>
```python Python
s3_file_name = upload_audiostream_to_s3(audio_stream)
```
```typescript TypeScript
const s3path = await uploadAudioStreamToS3(stream);
```
</CodeGroup>
After uploading the audio file to S3, generate a signed URL to share access to the file. This URL will be time-limited, meaning it will expire after a certain period, making it secure for temporary sharing.
You can now generate a URL from a file with:
<CodeGroup>
```python Python
signed_url = generate_presigned_url(s3_file_name)
print(f"Signed URL to access the file: {signed_url}")
```
```typescript TypeScript
const presignedUrl = await generatePresignedUrl(s3path);
console.log('Presigned URL:', presignedUrl);
```
</CodeGroup>
If you want to use the file multiple times, you should store the s3 file path in your database and then regenerate the signed URL each time you need rather than saving the signed URL directly as it will expire.
</Accordion>
<Accordion title="Putting it all together">
To put it all together, you can use the following script:
<CodeGroup>
```python main.py (Python)
import os
from dotenv import load_dotenv
load_dotenv()
from text_to_speech_stream import text_to_speech_stream
from s3_uploader import upload_audiostream_to_s3, generate_presigned_url
def main():
text = "This is James"
audio_stream = text_to_speech_stream(text)
s3_file_name = upload_audiostream_to_s3(audio_stream)
signed_url = generate_presigned_url(s3_file_name)
print(f"Signed URL to access the file: {signed_url}")
if __name__ == "__main__":
main()
```
```typescript index.ts (Typescript)
import 'dotenv/config';
import { generatePresignedUrl, uploadAudioStreamToS3 } from './s3_uploader';
import { createAudioFileFromText } from './text_to_speech_file';
import { createAudioStreamFromText } from './text_to_speech_stream';
(async () => {
// save the audio file to disk
const fileName = await createAudioFileFromText(
'Today, the sky is exceptionally clear, and the sun shines brightly.'
);
console.log('File name:', fileName);
// OR stream the audio, upload to S3, and get a presigned URL
const stream = await createAudioStreamFromText(
'Today, the sky is exceptionally clear, and the sun shines brightly.'
);
const s3path = await uploadAudioStreamToS3(stream);
const presignedUrl = await generatePresignedUrl(s3path);
console.log('Presigned URL:', presignedUrl);
})();
```
</CodeGroup>
</Accordion>
</AccordionGroup>
## Conclusion
You now know how to convert text into speech and generate a signed URL to share the audio file. This functionality opens up numerous opportunities for creating and sharing content dynamically.
Here are some examples of what you could build with this.
1. **Educational Podcasts**: Create personalized educational content that can be accessed by students on demand. Teachers can convert their lessons into audio format, upload them to S3, and share the links with students for a more engaging learning experience outside the traditional classroom setting.
2. **Accessibility Features for Websites**: Enhance website accessibility by offering text content in audio format. This can make information on websites more accessible to individuals with visual impairments or those who prefer auditory learning.
3. **Automated Customer Support Messages**: Produce automated and personalized audio messages for customer support, such as FAQs or order updates. This can provide a more engaging customer experience compared to traditional text emails.
4. **Audio Books and Narration**: Convert entire books or short stories into audio format, offering a new way for audiences to enjoy literature. Authors and publishers can diversify their content offerings and reach audiences who prefer listening over reading.
5. **Language Learning Tools**: Develop language learning aids that provide learners with audio lessons and exercises. This makes it possible to practice pronunciation and listening skills in a targeted way.
For more details, visit the following to see the full project files which give a clear structure for setting up your application:
For Python: [example repo](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/python)
For TypeScript: [example repo](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/node)
If you have any questions please create an issue on the [elevenlabs-doc Github](https://github.com/elevenlabs/elevenlabs-docs/issues).
# Convert text to speech in real-time
> Learn how to convert text to speech via a WebSocket connection.
Websocket streaming is a method of sending and receiving data over a single, long-lived connection. This method is useful for real-time applications where you need to stream audio data as it becomes available.
If you want to quickly test out the latency (time to first byte) of a websocket connection to the ElevenLabs text-to-speech API, you can install `elevenlabs-latency` via `npm` and follow the instructions [here](https://www.npmjs.com/package/elevenlabs-latency?activeTab=readme).
## Requirements
* An ElevenLabs account with an API key (here’s how to [find your API key](/docs/api-reference/authentication)).
* Python or Node.js/Typescript installed on your machine
## Setup
Install dotenv package to manage your environmental variables:
<CodeGroup>
```bash Python
pip install python-dotenv
pip install websockets
```
```bash TypeScript
npm install dotenv
npm install @types/dotenv --save-dev
npm install ws
```
</CodeGroup>
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```bash .env
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
Last, create a new file to write the code in. You can name it `text-to-speech-websocket.py` for Python or `text-to-speech-websocket.ts` for Typescript.
## Initiate the websocket connection
Pick a voice from the voice library and a text-to-speech model; Then initiate a websocket connection to the text-to-speech API.
<CodeGroup>
```python text-to-speech-websocket.py (Python)
import os
from dotenv import load_dotenv
import websockets
# Load the API key from the .env file
load_dotenv()
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
voice_id = 'kmSVBPu7loj4ayNinwWM'
model_id = 'eleven_flash_v2_5'
async def text_to_speech_ws_streaming(voice_id, model_id):
uri = f"wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input?model_id={model_id}"
async with websockets.connect(uri) as websocket:
...
```
```typescript text-to-speech-websocket.ts (Typescript)
import * as dotenv from 'dotenv';
// @ts-ignore
import WebSocket from 'ws';
// Load the API key from the .env file
dotenv.config();
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const voiceId = 'Xb7hH8MSUJpSbSDYk0k2';
const model = 'eleven_flash_v2_5';
const uri = `wss://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream-input?model_id=${model}`;
const websocket = new WebSocket(uri, {
headers: { 'xi-api-key': `${ELEVENLABS_API_KEY}` },
});
```
</CodeGroup>
For TypeScript, create a write stream ahead for saving the audio into mp3 which can be passed to the websocket listener.
```typescript text-to-speech-websocket.ts (Typescript)
import * as fs from 'node:fs';
const outputDir = './output';
try {
fs.accessSync(outputDir, fs.constants.R_OK | fs.constants.W_OK);
} catch (err) {
fs.mkdirSync(outputDir);
}
const writeStream = fs.createWriteStream(outputDir + '/test.mp3', {
flags: 'a',
});
```
## Send the input text
Once the websocket connection is open, set up voice settings first. Next, send the text message to the API.
<CodeGroup>
```python text-to-speech-websocket.py (Python)
async def text_to_speech_ws_streaming(voice_id, model_id):
async with websockets.connect(uri) as websocket:
await websocket.send(json.dumps({
"text": " ",
"voice_settings": {"stability": 0.5, "similarity_boost": 0.8, "use_speaker_boost": False},
"generation_config": {
"chunk_length_schedule": [120, 160, 250, 290]
},
"xi_api_key": ELEVENLABS_API_KEY,
}))
text = "The twilight sun cast its warm golden hues upon the vast rolling fields, saturating the landscape with an ethereal glow. Silently, the meandering brook continued its ceaseless journey, whispering secrets only the trees seemed privy to."
await websocket.send(json.dumps({"text": text}))
// Send empty string to indicate the end of the text sequence which will close the websocket connection
await websocket.send(json.dumps({"text": ""}))
```
```typescript text-to-speech-websocket.ts (Typescript)
const text =
'The twilight sun cast its warm golden hues upon the vast rolling fields, saturating the landscape with an ethereal glow. ';
websocket.on('open', async () => {
websocket.send(
JSON.stringify({
text: ' ',
voice_settings: {
stability: 0.5,
similarity_boost: 0.8,
use_speaker_boost: false,
},
generation_config: { chunk_length_schedule: [120, 160, 250, 290] },
})
);
websocket.send(JSON.stringify({ text: text }));
// Send empty string to indicate the end of the text sequence which will close the websocket connection
websocket.send(JSON.stringify({ text: '' }));
});
```
</CodeGroup>
## Save the audio to file
Read the incoming message from the websocket connection and write the audio chunks to a local file.
<CodeGroup>
```python text-to-speech-websocket.py (Python)
import asyncio
async def write_to_local(audio_stream):
"""Write the audio encoded in base64 string to a local mp3 file."""
with open(f'./output/test.mp3', "wb") as f:
async for chunk in audio_stream:
if chunk:
f.write(chunk)
async def listen(websocket):
"""Listen to the websocket for audio data and stream it."""
while True:
try:
message = await websocket.recv()
data = json.loads(message)
if data.get("audio"):
yield base64.b64decode(data["audio"])
elif data.get('isFinal'):
break
except websockets.exceptions.ConnectionClosed:
print("Connection closed")
break
async def text_to_speech_ws_streaming(voice_id, model_id):
async with websockets.connect(uri) as websocket:
...
# Add listen task to submit the audio chunks to the write_to_local function
listen_task = asyncio.create_task(write_to_local(listen(websocket)))
await listen_task
asyncio.run(text_to_speech_ws_streaming(voice_id, model_id))
```
```typescript text-to-speech-websocket.ts (Typescript)
// Helper function to write the audio encoded in base64 string into local file
function writeToLocal(base64str: any, writeStream: fs.WriteStream) {
const audioBuffer: Buffer = Buffer.from(base64str, 'base64');
writeStream.write(audioBuffer, (err) => {
if (err) {
console.error('Error writing to file:', err);
}
});
}
// Listen to the incoming message from the websocket connection
websocket.on('message', function incoming(event) {
const data = JSON.parse(event.toString());
if (data['audio']) {
writeToLocal(data['audio'], writeStream);
}
});
// Close the writeStream when the websocket connection closes
websocket.on('close', () => {
writeStream.end();
});
```
</CodeGroup>
## Run the script
You can run the script by executing the following command in your terminal. An mp3 audio file will be saved in the `output` directory.
<CodeGroup>
`python Python python text-to-speech-websocket.py ` `typescript Typescript tsx
text-to-speech-websocket.ts `
</CodeGroup>
## Understanding buffering
A key concept to understand when using websockets is buffering. The API only runs model generations when a certain amount of text above a threshold has been sent. This is to optimize the quality of the generated audio by maximising the amount of context available to the model while balancing latency.
For example, if the threshold is set to 120 characters and you send 'Hello, how are you?', the audio won't be generated immediately. This is because the sent message has only 19 characters which is below the threshold. However, if you keep sending text, the API will generate audio once the total text sent since the last generation has at least 120 characters.
In the case that you want force the immediate return of the audio, you can use `flush=true` to clear out the buffer and force generate any buffered text. This can be useful, for example, when you have reached the end of a document and want to generate audio for the final section.
In addition, closing the websocket will automatically force generate any buffered text.
## Best practice
* We suggest using the default setting for `chunk_length_schedule` in `generation_config`. Avoid using `try_trigger_generation` as it is deprecated.
* When developing a real-time conversational AI application, we advise using `flush=true` along with the text at the end of conversation turn to ensure timely audio generation.
* If the default setting doesn't provide optimal latency for your use case, you can modify the `chunk_length_schedule`. However, be mindful that reducing latency through this adjustment may come at the expense of quality.
## Tips
* The API maintains a internal buffer so that it only runs model generations when a certain amount of text above a threshold has been sent. For short texts with a character length smaller than the value set in `chunk_length_schedule`, you can use `flush=true` to clear out the buffer and force generate any buffered text.
* The websocket connection will automatically close after 20 seconds of inactivity. To keep the connection open, you can send a single space character `" "`. Please note that this string must include a space, as sending a fully empty string, `""`, will close the websocket.
* Send an empty string to close the websocket connection after sending the last text message.
* You can use `alignment` to get the word-level timestamps for each word in the text. This can be useful for aligning the audio with the text in a video or for other applications that require precise timing.
# Stitching multiple requests
> Learn how to maintain voice prosody over multiple chunks/generations.
## What is Request Stitching?
When one has a large text to convert into audio and sends the text in chunks without further context there can be abrupt changes in prosody from one chunk to another.
It would be much better to give the model context on what was already generated and what will be generated in the future, this is exactly what Request Stitching does.
As you can see below the difference between not using Request Stitching and using it is subtle but noticeable:
#### Without Request Stitching:
<video controls src="https://eleven-public-cdn.elevenlabs.io/audio/docs/without_request_stitching.mp3" />
#### With Request Stitching:
<video controls src="https://eleven-public-cdn.elevenlabs.io/audio/docs/with_request_stitching.mp3" />
## Conditioning on text
We will use Pydub for concatenating multiple audios together, you can install it using:
```bash
pip install pydub
```
One of the two ways on how to give the model context is to provide the text before and / or after the current chunk by using the 'previous\_text' and 'next\_text' parameters:
```python
import os
import requests
from pydub import AudioSegment
import io
YOUR_XI_API_KEY = "<insert your xi-api-key here>"
VOICE_ID = "21m00Tcm4TlvDq8ikWAM"  # Rachel
PARAGRAPHS = [
"The advent of technology has transformed countless sectors, with education "
"standing out as one of the most significantly impacted fields.",
"In recent years, educational technology, or EdTech, has revolutionized the way "
"teachers deliver instruction and students absorb information.",
"From interactive whiteboards to individual tablets loaded with educational software, "
"technology has opened up new avenues for learning that were previously unimaginable.",
"One of the primary benefits of technology in education is the accessibility it provides.",
]
segments = []
for i, paragraph in enumerate(PARAGRAPHS):
is_last_paragraph = i == len(PARAGRAPHS) - 1
is_first_paragraph = i == 0
response = requests.post(
f"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream",
json={
"text": paragraph,
"model_id": "eleven_multilingual_v2",
"previous_text": None if is_first_paragraph else " ".join(PARAGRAPHS[:i]),
"next_text": None if is_last_paragraph else " ".join(PARAGRAPHS[i + 1:])
},
headers={"xi-api-key": YOUR_XI_API_KEY},
)
if response.status_code != 200:
print(f"Error encountered, status: {response.status_code}, "
f"content: {response.text}")
quit()
print(f"Successfully converted paragraph {i + 1}/{len(PARAGRAPHS)}")
segments.append(AudioSegment.from_mp3(io.BytesIO(response.content)))
segment = segments[0]
for new_segment in segments[1:]:
segment = segment + new_segment
audio_out_path = os.path.join(os.getcwd(), "with_text_conditioning.wav")
segment.export(audio_out_path, format="wav")
print(f"Success! Wrote audio to {audio_out_path}")
```
## Conditioning on past generations
Text conditioning works well when there has been no previous or next chunks generated yet. If there have been however, it works much better to provide the actual past generations to the model instead of just the text.
This is done by using the previous\_request\_ids and next\_request\_ids parameters.
Every text-to-speech request has an associated request-id which is obtained by reading from the response header. Below is an example on how to use this request\_id in order to condition requests on the previous generations.
```python
import os
import requests
from pydub import AudioSegment
import io
YOUR_XI_API_KEY = "<insert your xi-api-key here>"
VOICE_ID = "21m00Tcm4TlvDq8ikWAM"  # Rachel
PARAGRAPHS = [
"The advent of technology has transformed countless sectors, with education "
"standing out as one of the most significantly impacted fields.",
"In recent years, educational technology, or EdTech, has revolutionized the way "
"teachers deliver instruction and students absorb information.",
"From interactive whiteboards to individual tablets loaded with educational software, "
"technology has opened up new avenues for learning that were previously unimaginable.",
"One of the primary benefits of technology in education is the accessibility it provides.",
]
segments = []
previous_request_ids = []
for i, paragraph in enumerate(PARAGRAPHS):
response = requests.post(
f"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream",
json={
"text": paragraph,
"model_id": "eleven_multilingual_v2",
# A maximum of three next or previous history item ids can be send
"previous_request_ids": previous_request_ids[-3:],
},
headers={"xi-api-key": YOUR_XI_API_KEY},
)
if response.status_code != 200:
print(f"Error encountered, status: {response.status_code}, "
f"content: {response.text}")
quit()
print(f"Successfully converted paragraph {i + 1}/{len(PARAGRAPHS)}")
previous_request_ids.append(response.headers["request-id"])
segments.append(AudioSegment.from_mp3(io.BytesIO(response.content)))
segment = segments[0]
for new_segment in segments[1:]:
segment = segment + new_segment
audio_out_path = os.path.join(os.getcwd(), "with_previous_request_ids_conditioning.wav")
segment.export(audio_out_path, format="wav")
print(f"Success! Wrote audio to {audio_out_path}")
```
<b>Note that the order matters here</b>: When one converts a text split into 5 chunks and has
already converted chunks 1, 2, 4 and 5 and now wants to convert chunk 3 the previous\_request\_ids one
neeeds to send would be \[request\_id\_chunk\_1, request\_id\_chunk\_2] and the next\_request\_ids would be
\[request\_id\_chunk\_4, request\_id\_chunk\_5].
## Conditioning both on text and past generations
The best possible results are achieved when conditioning both on text and past generations so lets combine the two by providing previous\_text, next\_text and previous\_request\_ids in one request:
```python
import os
import requests
from pydub import AudioSegment
import io
YOUR_XI_API_KEY = "<insert your xi-api-key here>"
VOICE_ID = "21m00Tcm4TlvDq8ikWAM"  # Rachel
PARAGRAPHS = [
"The advent of technology has transformed countless sectors, with education "
"standing out as one of the most significantly impacted fields.",
"In recent years, educational technology, or EdTech, has revolutionized the way "
"teachers deliver instruction and students absorb information.",
"From interactive whiteboards to individual tablets loaded with educational software, "
"technology has opened up new avenues for learning that were previously unimaginable.",
"One of the primary benefits of technology in education is the accessibility it provides.",
]
segments = []
previous_request_ids = []
for i, paragraph in enumerate(PARAGRAPHS):
is_first_paragraph = i == 0
is_last_paragraph = i == len(PARAGRAPHS) - 1
response = requests.post(
f"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream",
json={
"text": paragraph,
"model_id": "eleven_multilingual_v2",
# A maximum of three next or previous history item ids can be send
"previous_request_ids": previous_request_ids[-3:],
"previous_text": None if is_first_paragraph else " ".join(PARAGRAPHS[:i]),
"next_text": None if is_last_paragraph else " ".join(PARAGRAPHS[i + 1:])
},
headers={"xi-api-key": YOUR_XI_API_KEY},
)
if response.status_code != 200:
print(f"Error encountered, status: {response.status_code}, "
f"content: {response.text}")
quit()
print(f"Successfully converted paragraph {i + 1}/{len(PARAGRAPHS)}")
previous_request_ids.append(response.headers["request-id"])
segments.append(AudioSegment.from_mp3(io.BytesIO(response.content)))
segment = segments[0]
for new_segment in segments[1:]:
segment = segment + new_segment
audio_out_path = os.path.join(os.getcwd(), "with_full_conditioning.wav")
segment.export(audio_out_path, format="wav")
print(f"Success! Wrote audio to {audio_out_path}")
```
## Things to note
1. Providing wrong previous\_request\_ids and next\_request\_ids will not result in an error.
2. In order to use the request\_id of a request for conditioning it needs to have processed completely. In case of streaming this means the audio has to be read completely from the response body.
3. How well Request Stitching works varies greatly dependent on the model, voice and voice settings used.
4. previous\_request\_ids and next\_request\_ids should contain request\_ids which are not too old. When the request\_ids are older than two hours it will diminish the effect of conditioning.
5. Enterprises with increased privacy requirements will have Request Stitching disabled.
# Using pronunciation dictionaries
> Learn how to manage pronunciation dictionaries programmatically.
In this tutorial, you'll learn how to use a pronunciation dictionary with the ElevenLabs Python SDK. Pronunciation dictionaries are useful for controlling the specific pronunciation of words. We support both [IPA](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) and [CMU](https://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary) alphabets. It is useful for correcting rare or specific pronunciations, such as names or companies. For example, the word `nginx` could be pronounced incorrectly. Instead, we can add our version of pronunciation. Based on IPA, `nginx` is pronounced as `/ˈɛndʒɪnˈɛks/`. Finding IPA or CMU of words manually can be difficult. Instead, LLMs like ChatGPT can help you to make the search easier.
We'll start by adding rules to the pronunciation dictionary from a file and comparing the text-to-speech results that use and do not use the dictionary. After that, we'll discuss how to add and remove specific rules to existing dictionaries.
If you want to jump straight to the finished repo you can find it [here](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/pronunciation-dictionaries/python)
<Info>
Phoneme tags only work with `eleven_flash_v2`, `eleven_turbo_v2` & `eleven_monolingual_v1` models.
If you use phoneme tags with other models, they will silently skip the word.
</Info>
## Requirements
* An ElevenLabs account with an API key (here’s how to [find your API key](/docs/api-reference/text-to-speech#authentication)).
* Python installed on your machine
* FFMPEG to play audio
## Setup
### Installing our SDK
Before you begin, make sure you have installed the necessary SDKs and libraries. You will need the ElevenLabs SDK for the updating pronunciation dictionary and using text-to-speech conversion. You can install it using pip:
```bash
pip install elevenlabs
```
Additionally, install `python-dotenv` to manage your environmental variables:
```bash
pip install python-dotenv
```
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
## Initiate the Client SDK
We'll start by initializing the client SDK.
```python
import os
from elevenlabs.client import ElevenLabs
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(
api_key=ELEVENLABS_API_KEY,
)
```
## Create a Pronunciation Dictionary From a File
To create a pronunciation dictionary from a File, we'll create a `.pls` file for our rules.
This rule will use the "IPA" alphabet and update the pronunciation for `tomato` and `Tomato` with a different pronunciation. PLS files are case sensitive which is why we include it both with and without a capital "T". Save it as `dictionary.pls`.
```xml filename="dictionary.pls"
<?xml version="1.0" encoding="UTF-8"?>
<lexicon version="1.0"
xmlns="http://www.w3.org/2005/01/pronunciation-lexicon"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2005/01/pronunciation-lexicon
http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd"
alphabet="ipa" xml:lang="en-US">
<lexeme>
<grapheme>tomato</grapheme>
<phoneme>/tə'meɪtoʊ/</phoneme>
</lexeme>
<lexeme>
<grapheme>Tomato</grapheme>
<phoneme>/tə'meɪtoʊ/</phoneme>
</lexeme>
</lexicon>
```
In the following snippet, we start by adding rules from a file and get the uploaded result. Finally, we generate and play two different text-to-speech audio to compare the custom pronunciation dictionary.
```python
import requests
from elevenlabs import play, PronunciationDictionaryVersionLocator
with open("dictionary.pls", "rb") as f:
# this dictionary changes how tomato is pronounced
pronunciation_dictionary = client.pronunciation_dictionary.add_from_file(
file=f.read(), name="example"
)
audio_1 = client.generate(
text="Without the dictionary: tomato",
voice="Rachel",
model="eleven_turbo_v2",
)
audio_2 = client.generate(
text="With the dictionary: tomato",
voice="Rachel",
model="eleven_turbo_v2",
pronunciation_dictionary_locators=[
PronunciationDictionaryVersionLocator(
pronunciation_dictionary_id=pronunciation_dictionary.id,
version_id=pronunciation_dictionary.version_id,
)
],
)
# play the audio
play(audio_1)
play(audio_2)
```
## Remove Rules From a Pronunciation Dictionary
To remove rules from a pronunciation dictionary, we can simply call `remove_rules_from_the_pronunciation_dictionary` method in the pronunciation dictionary module. In the following snippet, we start by removing rules based on the rule string and get the updated result. Finally, we generate and play another text-to-speech audio to test the difference. In the example, we take pronunciation dictionary version id from `remove_rules_from_the_pronunciation_dictionary` response because every changes to pronunciation dictionary will create a new version, so we need to use the latest version returned from the response. The old version also still available.
```python
pronunciation_dictionary_rules_removed = (
client.pronunciation_dictionary.remove_rules_from_the_pronunciation_dictionary(
pronunciation_dictionary_id=pronunciation_dictionary.id,
rule_strings=["tomato", "Tomato"],
)
)
audio_3 = client.generate(
text="With the rule removed: tomato",
voice="Rachel",
model="eleven_turbo_v2",
pronunciation_dictionary_locators=[
PronunciationDictionaryVersionLocator(
pronunciation_dictionary_id=pronunciation_dictionary_rules_removed.id,
version_id=pronunciation_dictionary_rules_removed.version_id,
)
],
)
play(audio_3)
```
## Add Rules to Pronunciation Dictionary
We can add rules directly to the pronunciation dictionary with `PronunciationDictionaryRule_Phoneme` class and call `add_rules_to_the_pronunciation_dictionary` from the pronunciation dictionary. The snippet will demonstrate adding rules with the class and get the updated result. Finally, we generate and play another text-to-speech audio to test the difference. This example also use pronunciation dictionary version returned from `add_rules_to_the_pronunciation_dictionary` to ensure we use the latest dictionary version.
```python
from elevenlabs import PronunciationDictionaryRule_Phoneme
pronunciation_dictionary_rules_added = client.pronunciation_dictionary.add_rules_to_the_pronunciation_dictionary(
pronunciation_dictionary_id=pronunciation_dictionary_rules_removed.id,
rules=[
PronunciationDictionaryRule_Phoneme(
type="phoneme",
alphabet="ipa",
string_to_replace="tomato",
phoneme="/tə'meɪtoʊ/",
),
PronunciationDictionaryRule_Phoneme(
type="phoneme",
alphabet="ipa",
string_to_replace="Tomato",
phoneme="/tə'meɪtoʊ/",
),
],
)
audio_4 = client.generate(
text="With the rule added again: tomato",
voice="Rachel",
model="eleven_turbo_v2",
pronunciation_dictionary_locators=[
PronunciationDictionaryVersionLocator(
pronunciation_dictionary_id=pronunciation_dictionary_rules_added.id,
version_id=pronunciation_dictionary_rules_added.version_id,
)
],
)
play(audio_4)
```
## Conclusion
You know how to use a pronunciation dictionary for generating text-to-speech audio. These functionailities open up opportunities to generate text-to-speech audio based on your pronunciation dictionary, making it more flexible for your use case.
For more details, visit our [example repo](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/pronunciation-dictionaries/python) to see the full project files which give a clear structure for setting up your application:
* `env.example`: Template for your environment variables.
* `main.py`: The complete code for snippets above.
* `dictionary.pls`: Custom dictionary example with XML format.
* `requirements.txt`: List of python package used for this example.
If you have any questions please create an issue on the [elevenlabs-doc Github](https://github.com/elevenlabs/elevenlabs-docs/issues).
# Streaming and Caching with Supabase
> Generate and stream speech through Supabase Edge Functions. Store speech in Supabase Storage and cache responses via built-in CDN.
## Introduction
In this tutorial you will learn how to build and edge API to generate, stream, store, and cache speech using Supabase Edge Functions, Supabase Storage, and ElevenLabs.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/4Roog4PAmZ8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Tip title="Prefer to jump straight to the code?" icon="lightbulb">
Find the [example project on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/supabase/stream-and-cache-storage).
</Tip>
## Requirements
* An ElevenLabs account with an [API key](/app/settings/api-keys).
* A [Supabase](https://supabase.com) account (you can sign up for a free account via [database.new](https://database.new)).
* The [Supabase CLI](https://supabase.com/docs/guides/local-development) installed on your machine.
* The [Deno runtime](https://docs.deno.com/runtime/getting_started/installation/) installed on your machine and optionally [setup in your facourite IDE](https://docs.deno.com/runtime/getting_started/setup_your_environment).
## Setup
### Create a Supabase project locally
After installing the [Supabase CLI](https://supabase.com/docs/guides/local-development), run the following command to create a new Supabase project locally:
```bash
supabase init
```
### Configure the storage bucket
You can configure the Supabase CLI to automatically generate a storage bucket by adding this configuration in the `config.toml` file:
```toml ./supabase/config.toml
[storage.buckets.audio]
public = false
file_size_limit = "50MiB"
allowed_mime_types = ["audio/mp3"]
objects_path = "./audio"
```
<Note>
Upon running `supabase start` this will create a new storage bucket in your local Supabase
project. Should you want to push this to your hosted Supabase project, you can run `supabase seed
buckets --linked`.
</Note>
### Configure background tasks for Supabase Edge Functions
To use background tasks in Supabase Edge Functions when developing locally, you need to add the following configuration in the `config.toml` file:
```toml ./supabase/config.toml
[edge_runtime]
policy = "per_worker"
```
<Note>
When running with `per_worker` policy, Function won't auto-reload on edits. You will need to
manually restart it by running `supabase functions serve`.
</Note>
### Create a Supabase Edge Function for Speech generation
Create a new Edge Function by running the following command:
```bash
supabase functions new text-to-speech
```
If you're using VS Code or Cursor, select `y` when the CLI prompts "Generate VS Code settings for Deno? \[y/N]"!
### Set up the environment variables
Within the `supabase/functions` directory, create a new `.env` file and add the following variables:
```env supabase/functions/.env
# Find / create an API key at https://elevenlabs.io/app/settings/api-keys
ELEVENLABS_API_KEY=your_api_key
```
### Dependencies
The project uses a couple of dependencies:
* The [@supabase/supabase-js](https://supabase.com/docs/reference/javascript) library to interact with the Supabase database.
* The ElevenLabs [JavaScript SDK](/docs/quickstart) to interact with the text-to-speech API.
* The open-source [object-hash](https://www.npmjs.com/package/object-hash) to generate a hash from the request parameters.
Since Supabase Edge Function uses the [Deno runtime](https://deno.land/), you don't need to install the dependencies, rather you can [import](https://docs.deno.com/examples/npm/) them via the `npm:` prefix.
## Code the Supabase Edge Function
In your newly created `supabase/functions/text-to-speech/index.ts` file, add the following code:
```ts supabase/functions/text-to-speech/index.ts
// Setup type definitions for built-in Supabase Runtime APIs
import 'jsr:@supabase/functions-js/edge-runtime.d.ts';
import { createClient } from 'jsr:@supabase/supabase-js@2';
import { ElevenLabsClient } from 'npm:elevenlabs';
import * as hash from 'npm:object-hash';
const supabase = createClient(
Deno.env.get('SUPABASE_URL')!,
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
);
const client = new ElevenLabsClient({
apiKey: Deno.env.get('ELEVENLABS_API_KEY'),
});
// Upload audio to Supabase Storage in a background task
async function uploadAudioToStorage(stream: ReadableStream, requestHash: string) {
const { data, error } = await supabase.storage
.from('audio')
.upload(`${requestHash}.mp3`, stream, {
contentType: 'audio/mp3',
});
console.log('Storage upload result', { data, error });
}
Deno.serve(async (req) => {
// To secure your function for production, you can for example validate the request origin,
// or append a user access token and validate it with Supabase Auth.
console.log('Request origin', req.headers.get('host'));
const url = new URL(req.url);
const params = new URLSearchParams(url.search);
const text = params.get('text');
const voiceId = params.get('voiceId') ?? 'JBFqnCBsd6RMkjVDRZzb';
const requestHash = hash.MD5({ text, voiceId });
console.log('Request hash', requestHash);
// Check storage for existing audio file
const { data } = await supabase.storage.from('audio').createSignedUrl(`${requestHash}.mp3`, 60);
if (data) {
console.log('Audio file found in storage', data);
const storageRes = await fetch(data.signedUrl);
if (storageRes.ok) return storageRes;
}
if (!text) {
return new Response(JSON.stringify({ error: 'Text parameter is required' }), {
status: 400,
headers: { 'Content-Type': 'application/json' },
});
}
try {
console.log('ElevenLabs API call');
const response = await client.textToSpeech.convertAsStream(voiceId, {
output_format: 'mp3_44100_128',
model_id: 'eleven_multilingual_v2',
text,
});
const stream = new ReadableStream({
async start(controller) {
for await (const chunk of response) {
controller.enqueue(chunk);
}
controller.close();
},
});
// Branch stream to Supabase Storage
const [browserStream, storageStream] = stream.tee();
// Upload to Supabase Storage in the background
EdgeRuntime.waitUntil(uploadAudioToStorage(storageStream, requestHash));
// Return the streaming response immediately
return new Response(browserStream, {
headers: {
'Content-Type': 'audio/mpeg',
},
});
} catch (error) {
console.log('error', { error });
return new Response(JSON.stringify({ error: error.message }), {
status: 500,
headers: { 'Content-Type': 'application/json' },
});
}
});
```
### Code deep dive
There's a couple of things worth noting about the code. Let's step through it step by step.
<Steps>
<Step title="Handle the incoming request">
To handle the incoming request, use the `Deno.serve` handler. In the demo we don't validate the request origin, but you can for example validate the request origin, or append a user access token and validate it with [Supabase Auth](https://supabase.com/docs/guides/functions/auth).
From the incoming request, the function extracts the `text` and `voiceId` parameters. The `voiceId` parameter is optional and defaults to the ElevenLabs ID for the "Allison" voice.
Using the `object-hash` library, the function generates a hash from the request parameters. This hash is used to check for existing audio files in Supabase Storage.
```ts {1,5-8}
Deno.serve(async (req) => {
// To secure your function for production, you can for example validate the request origin,
// or append a user access token and validate it with Supabase Auth.
console.log("Request origin", req.headers.get("host"));
const url = new URL(req.url);
const params = new URLSearchParams(url.search);
const text = params.get("text");
const voiceId = params.get("voiceId") ?? "JBFqnCBsd6RMkjVDRZzb";
const requestHash = hash.MD5({ text, voiceId });
console.log("Request hash", requestHash);
// ...
})
```
</Step>
<Step title="Check for existing audio file in Supabase Storage">
Supabase Storage comes with a [smart CDN built-in](https://supabase.com/docs/guides/storage/cdn/smart-cdn) allowing you to easily cache and serve your files.
Here, the function checks for an existing audio file in Supabase Storage. If the file exists, the function returns the file from Supabase Storage.
```ts {4,9}
const { data } = await supabase
.storage
.from("audio")
.createSignedUrl(`${requestHash}.mp3`, 60);
if (data) {
console.log("Audio file found in storage", data);
const storageRes = await fetch(data.signedUrl);
if (storageRes.ok) return storageRes;
}
```
</Step>
<Step title="Generate Speech as a stream and split into two branches">
Using the streaming capabilities of the ElevenLabs API, the function generates a stream. The benefit here is that even for larger text, you can start streaming the audio back to your user immediately, and then upload the stream to Supabase Storage in the background.
This allows for the best possible user experience, making even large text blocks feel magically quick. The magic here happens on line 17, where the `stream.tee()` method branches the readablestream into two branches: one for the browser and one for Supabase Storage.
```ts {1,17,20,22-27}
try {
const response = await client.textToSpeech.convertAsStream(voiceId, {
output_format: "mp3_44100_128",
model_id: "eleven_multilingual_v2",
text,
});
const stream = new ReadableStream({
async start(controller) {
for await (const chunk of response) {
controller.enqueue(chunk);
}
controller.close();
},
});
// Branch stream to Supabase Storage
const [browserStream, storageStream] = stream.tee();
// Upload to Supabase Storage in the background
EdgeRuntime.waitUntil(uploadAudioToStorage(storageStream, requestHash));
// Return the streaming response immediately
return new Response(browserStream, {
headers: {
"Content-Type": "audio/mpeg",
},
});
} catch (error) {
console.log("error", { error });
return new Response(JSON.stringify({ error: error.message }), {
status: 500,
headers: { "Content-Type": "application/json" },
});
}
```
</Step>
<Step title="Upload the audio stream to Supabase Storage in the background">
The `EdgeRuntime.waitUntil` method on line 20 in the previous step is used to upload the audio stream to Supabase Storage in the background using the `uploadAudioToStorage` function. This allows the function to return the streaming response immediately to the browser, while the audio is being uploaded to Supabase Storage.
Once the storage object has been created, the next time your users makes a request with the same parameters, the function will return the audio file from the Supabase Storage CDN.
```ts {2,8-10}
// Upload audio to Supabase Storage in a background task
async function uploadAudioToStorage(
stream: ReadableStream,
requestHash: string,
) {
const { data, error } = await supabase.storage
.from("audio")
.upload(`${requestHash}.mp3`, stream, {
contentType: "audio/mp3",
});
console.log("Storage upload result", { data, error });
}
```
</Step>
</Steps>
## Run locally
To run the function locally, run the following commands:
```bash
supabase start
```
Once the local Supabase stack is up and running, run the following command to start the function and observe the logs:
```bash
supabase functions serve
```
### Try it out
Navigate to `http://127.0.0.1:54321/functions/v1/text-to-speech?text=hello%20world` to hear the function in action.
Afterwards, navigate to `http://127.0.0.1:54323/project/default/storage/buckets/audio` to see the audio file in your local Supabase Storage bucket.
## Deploy to Supabase
If you haven't already, create a new Supabase account at [database.new](https://database.new) and link the local project to your Supabase account:
```bash
supabase link
```
Once done, run the following command to deploy the function:
```bash
supabase functions deploy
```
### Set the function secrets
Now that you have all your secrets set locally, you can run the following command to set the secrets in your Supabase project:
```bash
supabase secrets set --env-file supabase/functions/.env
```
## Test the function
The function is designed in a way that it can be used directly as a source for an `<audio>` element.
```html
<audio
src="https://${SUPABASE_PROJECT_REF}.supabase.co/functions/v1/text-to-speech?text=Hello%2C%20world!&voiceId=JBFqnCBsd6RMkjVDRZzb"
controls
/>
```
You can find an example frontend implementation in the complete code example on [GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-speech/supabase/stream-and-cache-storage/src/pages/Index.tsx).
# Sending generated audio through Twilio
> Learn how to integrate generated speech into phone calls with Twilio.
In this guide, you’ll learn how to send an AI generated message through a phone call using Twilio and ElevenLabs. This process allows you to send high-quality voice messages directly to your callers.
## Create accounts with Twilio and ngrok
We’ll be using Twilio and ngrok for this guide, so go ahead and create accounts with them.
* [twilio.com](https://www.twilio.com)
* [ngrok.com](https://ngrok.com)
## Get the code
If you want to get started quickly, you can get the entire code for this guide on [GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/twilio/call)
## Create the server with Express
### Initialize your project
Create a new folder for your project
```
mkdir elevenlabs-twilio
cd elevenlabs-twilio
npm init -y
```
### Install dependencies
```
npm install elevenlabs express express-ws twilio
```
### Install dev dependencies
```
npm i @types/node @types/express @types/express-ws @types/ws dotenv tsx typescript
```
### Create your files
```ts
// src/app.ts
import 'dotenv/config';
import { ElevenLabsClient } from 'elevenlabs';
import express, { Response } from 'express';
import ExpressWs from 'express-ws';
import { Readable } from 'stream';
import VoiceResponse from 'twilio/lib/twiml/VoiceResponse';
import { type WebSocket } from 'ws';
const app = ExpressWs(express()).app;
const PORT: number = parseInt(process.env.PORT || '5000');
const elevenlabs = new ElevenLabsClient();
const voiceId = '21m00Tcm4TlvDq8ikWAM';
const outputFormat = 'ulaw_8000';
const text = 'This is a test. You can now hang up. Thank you.';
function startApp() {
app.post('/call/incoming', (_, res: Response) => {
const twiml = new VoiceResponse();
twiml.connect().stream({
url: `wss://${process.env.SERVER_DOMAIN}/call/connection`,
});
res.writeHead(200, { 'Content-Type': 'text/xml' });
res.end(twiml.toString());
});
app.ws('/call/connection', (ws: WebSocket) => {
ws.on('message', async (data: string) => {
const message: {
event: string;
start?: { streamSid: string; callSid: string };
} = JSON.parse(data);
if (message.event === 'start' && message.start) {
const streamSid = message.start.streamSid;
const response = await elevenlabs.textToSpeech.convert(voiceId, {
model_id: 'eleven_flash_v2_5',
output_format: outputFormat,
text,
});
const readableStream = Readable.from(response);
const audioArrayBuffer = await streamToArrayBuffer(readableStream);
ws.send(
JSON.stringify({
streamSid,
event: 'media',
media: {
payload: Buffer.from(audioArrayBuffer as any).toString('base64'),
},
})
);
}
});
ws.on('error', console.error);
});
app.listen(PORT, () => {
console.log(`Local: http://localhost:${PORT}`);
console.log(`Remote: https://${process.env.SERVER_DOMAIN}`);
});
}
function streamToArrayBuffer(readableStream: Readable) {
return new Promise((resolve, reject) => {
const chunks: Buffer[] = [];
readableStream.on('data', (chunk) => {
chunks.push(chunk);
});
readableStream.on('end', () => {
resolve(Buffer.concat(chunks).buffer);
});
readableStream.on('error', reject);
});
}
startApp();
```
```env
# .env
SERVER_DOMAIN=
ELEVENLABS_API_KEY=
```
## Understanding the code
### Handling the incoming call
When you call your number, Twilio makes a POST request to your endpoint at `/call/incoming`.
We then use twiml.connect to tell Twilio that we want to handle the call via our websocket by setting the url to our `/call/connection` endpoint.
```ts
function startApp() {
app.post('/call/incoming', (_, res: Response) => {
const twiml = new VoiceResponse();
twiml.connect().stream({
url: `wss://${process.env.SERVER_DOMAIN}/call/connection`,
});
res.writeHead(200, { 'Content-Type': 'text/xml' });
res.end(twiml.toString());
});
```
### Creating the text to speech
Here we listen for messages that Twilio sends to our websocket endpoint. When we receive a `start` message event, we generate audio using the ElevenLabs [TypeScript SDK](https://github.com/elevenlabs/elevenlabs-js).
```ts
app.ws('/call/connection', (ws: WebSocket) => {
ws.on('message', async (data: string) => {
const message: {
event: string;
start?: { streamSid: string; callSid: string };
} = JSON.parse(data);
if (message.event === 'start' && message.start) {
const streamSid = message.start.streamSid;
const response = await elevenlabs.textToSpeech.convert(voiceId, {
model_id: 'eleven_flash_v2_5',
output_format: outputFormat,
text,
});
```
### Sending the message
Upon receiving the audio back from ElevenLabs, we convert it to an array buffer and send the audio to Twilio via the websocket.
```ts
const readableStream = Readable.from(response);
const audioArrayBuffer = await streamToArrayBuffer(readableStream);
ws.send(
JSON.stringify({
streamSid,
event: 'media',
media: {
payload: Buffer.from(audioArrayBuffer as any).toString('base64'),
},
})
);
```
## Point ngrok to your application
Twilio requires a publicly accessible URL. We’ll use ngrok to forward the local port of our application and expose it as a public URL.
Run the following command in your terminal:
```
ngrok http 5000
```
Copy the ngrok domain (without https\://) to use in your environment variables.
<img src="file:5939f749-89b4-4514-a6ac-4d34c65622bc" />
## Update your environment variables
Update the `.env` file with your ngrok domain and ElevenLabs API key.
```
# .env
SERVER_DOMAIN=*******.ngrok.app
ELEVENLABS_API_KEY=*************************
```
## Start the application
Run the following command to start the app:
```
npm run dev
```
## Set up Twilio
Follow Twilio’s guides to create a new number. Once you’ve created your number, navigate to the “Configure” tab in Phone Numbers -> Manage -> Active numbers
In the “A call comes in” section, enter the full URL to your application (make sure to add the`/call/incoming` path):
E.g. https\://**\*\*\***&#x6E;grok.app/call/incoming
<img src="file:5b3b0392-2290-4a27-bbfe-31725bd9692e" />
## Make a phone call
Make a call to your number. You should hear a message using the ElevenLabs voice.
## Tips for deploying to production
When running the application in production, make sure to set the `SERVER_DOMAIN` environment variable to that of your server. Be sure to also update the URL in Twilio to point to your production server.
## Conclusion
You should now have a basic understanding of integrating Twilio with ElevenLabs voices. If you have any further questions, or suggestions on how to improve this blog post, please feel free to select the “Suggest edits” or “Raise issue” button below.
# Synchronous Speech to Text
> Learn how to transcribe audio with ElevenLabs synchronously
In this tutorial, you'll learn how to transcribe audio with the ElevenLabs SDK synchronously.
## Requirements
* An ElevenLabs account with an [API key](/docs/developer-guides/quickstart#authentication).
* Python or Node installed on your machine
## Setup
### Installing the SDK
Before you begin, make sure you have installed the ElevenLabs SDK.
<CodeBlocks>
```python title="Python"
pip install elevenlabs
```
```javascript title="JavaScript"
npm install elevenlabs
```
</CodeBlocks>
Additionally, install necessary packages to manage your environmental variables:
<CodeBlocks>
```python title="Python"
pip install python-dotenv
```
```javascript title="JavaScript"
npm install dotenv
```
</CodeBlocks>
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```python .env
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
To convert the audio of a file to text, we'll use the `convert` method of the ElevenLabs SDK.
## Convert speech to text
<CodeGroup>
```python title="speech_to_text.py" maxLines=0
from dotenv import load_dotenv
from io import BytesIO
import requests
from elevenlabs.client import ElevenLabs
import os
load_dotenv()
client = ElevenLabs(
api_key=os.getenv("ELEVENLABS_API_KEY"),
)
audio_url = (
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
)
response = requests.get(audio_url)
audio_data = BytesIO(response.content)
transcription = client.speech_to_text.convert(
file=audio_data,
model_id="scribe_v1", # Model to use, for now only "scribe_v1" is supported
tag_audio_events=True, # Tag audio events like laughter, applause, etc.
language_code="eng", # Language of the audio file. If set to None, the model will detect the language automatically.
diarize=True, # Whether to annotate who is speaking
)
print(transcription.text)
```
```javascript title="speechToText.mjs" maxLines=0
import "dotenv/config";
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient();
const response = await fetch(
"https://storage.googleapis.com/eleven-public-cdn/audio/marketing/nicole.mp3"
);
const audioBlob = new Blob([await response.arrayBuffer()], { type: "audio/mp3" });
const transcription = await client.speechToText.convert({
file: audioBlob,
model_id: "scribe_v1", // Model to use, for now only "scribe_v1" is support.
tag_audio_events: true, // Tag audio events like laughter, applause, etc.
language_code: "eng", // Language of the audio file. If set to null, the model will detect the language automatically.
diarize: true, // Whether to annotate who is speaking
});
console.log(transcription.text);
```
</CodeGroup>
Run the script with:
<CodeBlocks>
```python
python speech_to_text.py
```
```node
node speechToText.mjs
```
</CodeBlocks>
# Transcription Telegram Bot
> Build a Telegram bot that transcribes audio and video messages in 99 languages using TypeScript with Deno in Supabase Edge Functions.
## Introduction
In this tutorial you will learn how to build a Telegram bot that transcribes audio and video messages in 99 languages using TypeScript and the ElevenLabs Scribe model via the speech-to-text API.
To check out what the end result will look like, you can test out the [t.me/ElevenLabsScribeBot](https://t.me/ElevenLabsScribeBot)
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/CE4iPp7kd7Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Tip title="Prefer to jump straight to the code?" icon="lightbulb">
Find the [example project on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/speech-to-text/telegram-transcription-bot).
</Tip>
## Requirements
* An ElevenLabs account with an [API key](/app/settings/api-keys).
* A [Supabase](https://supabase.com) account (you can sign up for a free account via [database.new](https://database.new)).
* The [Supabase CLI](https://supabase.com/docs/guides/local-development) installed on your machine.
* The [Deno runtime](https://docs.deno.com/runtime/getting_started/installation/) installed on your machine and optionally [setup in your facourite IDE](https://docs.deno.com/runtime/getting_started/setup_your_environment).
* A [Telegram](https://telegram.org) account.
## Setup
### Register a Telegram bot
Use the [BotFather](https://t.me/BotFather) to create a new Telegram bot. Run the `/newbot` command and follow the instructions to create a new bot. At the end, you will receive your secret bot token. Note it down securely for the next step.
![BotFather](file:f15e70c4-0cf8-44fe-9858-859a6b5b242f)
### Create a Supabase project locally
After installing the [Supabase CLI](https://supabase.com/docs/guides/local-development), run the following command to create a new Supabase project locally:
```bash
supabase init
```
### Create a database table to log the transcription results
Next, create a new database table to log the transcription results:
```bash
supabase migrations new init
```
This will create a new migration file in the `supabase/migrations` directory. Open the file and add the following SQL:
```sql supabase/migrations/init.sql
CREATE TABLE IF NOT EXISTS transcription_logs (
id BIGSERIAL PRIMARY KEY,
file_type VARCHAR NOT NULL,
duration INTEGER NOT NULL,
chat_id BIGINT NOT NULL,
message_id BIGINT NOT NULL,
username VARCHAR,
transcript TEXT,
language_code VARCHAR,
created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
error TEXT
);
ALTER TABLE transcription_logs ENABLE ROW LEVEL SECURITY;
```
### Create a Supabase Edge Function to handle Telegram webhook requests
Next, create a new Edge Function to handle Telegram webhook requests:
```bash
supabase functions new scribe-bot
```
If you're using VS Code or Cursor, select `y` when the CLI prompts "Generate VS Code settings for Deno? \[y/N]"!
### Set up the environment variables
Within the `supabase/functions` directory, create a new `.env` file and add the following variables:
```env supabase/functions/.env
# Find / create an API key at https://elevenlabs.io/app/settings/api-keys
ELEVENLABS_API_KEY=your_api_key
# The bot token you received from the BotFather.
TELEGRAM_BOT_TOKEN=your_bot_token
# A random secret chosen by you to secure the function.
FUNCTION_SECRET=random_secret
```
### Dependencies
The project uses a couple of dependencies:
* The open-source [grammY Framework](https://grammy.dev/) to handle the Telegram webhook requests.
* The [@supabase/supabase-js](https://supabase.com/docs/reference/javascript) library to interact with the Supabase database.
* The ElevenLabs [JavaScript SDK](/docs/quickstart) to interact with the speech-to-text API.
Since Supabase Edge Function uses the [Deno runtime](https://deno.land/), you don't need to install the dependencies, rather you can [import](https://docs.deno.com/examples/npm/) them via the `npm:` prefix.
## Code the Telegram Bot
In your newly created `scribe-bot/index.ts` file, add the following code:
```ts supabase/functions/scribe-bot/index.ts
import { Bot, webhookCallback } from 'https://deno.land/x/grammy@v1.34.0/mod.ts';
import 'jsr:@supabase/functions-js/edge-runtime.d.ts';
import { createClient } from 'jsr:@supabase/supabase-js@2';
import { ElevenLabsClient } from 'npm:elevenlabs@1.50.5';
console.log(`Function "elevenlabs-scribe-bot" up and running!`);
const elevenLabsClient = new ElevenLabsClient({
apiKey: Deno.env.get('ELEVENLABS_API_KEY') || '',
});
const supabase = createClient(
Deno.env.get('SUPABASE_URL') || '',
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') || ''
);
async function scribe({
fileURL,
fileType,
duration,
chatId,
messageId,
username,
}: {
fileURL: string;
fileType: string;
duration: number;
chatId: number;
messageId: number;
username: string;
}) {
let transcript: string | null = null;
let languageCode: string | null = null;
let errorMsg: string | null = null;
try {
const sourceFileArrayBuffer = await fetch(fileURL).then((res) => res.arrayBuffer());
const sourceBlob = new Blob([sourceFileArrayBuffer], {
type: fileType,
});
const scribeResult = await elevenLabsClient.speechToText.convert({
file: sourceBlob,
model_id: 'scribe_v1',
tag_audio_events: false,
});
transcript = scribeResult.text;
languageCode = scribeResult.language_code;
// Reply to the user with the transcript
await bot.api.sendMessage(chatId, transcript, {
reply_parameters: { message_id: messageId },
});
} catch (error) {
errorMsg = error.message;
console.log(errorMsg);
await bot.api.sendMessage(chatId, 'Sorry, there was an error. Please try again.', {
reply_parameters: { message_id: messageId },
});
}
// Write log to Supabase.
const logLine = {
file_type: fileType,
duration,
chat_id: chatId,
message_id: messageId,
username,
language_code: languageCode,
error: errorMsg,
};
console.log({ logLine });
await supabase.from('transcription_logs').insert({ ...logLine, transcript });
}
const telegramBotToken = Deno.env.get('TELEGRAM_BOT_TOKEN');
const bot = new Bot(telegramBotToken || '');
const startMessage = `Welcome to the ElevenLabs Scribe Bot\\! I can transcribe speech in 99 languages with super high accuracy\\!
\nTry it out by sending or forwarding me a voice message, video, or audio file\\!
\n[Learn more about Scribe](https://elevenlabs.io/speech-to-text) or [build your own bot](https://elevenlabs.io/docs/cookbooks/speech-to-text/telegram-bot)\\!
`;
bot.command('start', (ctx) => ctx.reply(startMessage.trim(), { parse_mode: 'MarkdownV2' }));
bot.on([':voice', ':audio', ':video'], async (ctx) => {
try {
const file = await ctx.getFile();
const fileURL = `https://api.telegram.org/file/bot${telegramBotToken}/${file.file_path}`;
const fileMeta = ctx.message?.video ?? ctx.message?.voice ?? ctx.message?.audio;
if (!fileMeta) {
return ctx.reply('No video|audio|voice metadata found. Please try again.');
}
// Run the transcription in the background.
EdgeRuntime.waitUntil(
scribe({
fileURL,
fileType: fileMeta.mime_type!,
duration: fileMeta.duration,
chatId: ctx.chat.id,
messageId: ctx.message?.message_id!,
username: ctx.from?.username || '',
})
);
// Reply to the user immediately to let them know we received their file.
return ctx.reply('Received. Scribing...');
} catch (error) {
console.error(error);
return ctx.reply(
'Sorry, there was an error getting the file. Please try again with a smaller file!'
);
}
});
const handleUpdate = webhookCallback(bot, 'std/http');
Deno.serve(async (req) => {
try {
const url = new URL(req.url);
if (url.searchParams.get('secret') !== Deno.env.get('FUNCTION_SECRET')) {
return new Response('not allowed', { status: 405 });
}
return await handleUpdate(req);
} catch (err) {
console.error(err);
}
});
```
### Code deep dive
There's a couple of things worth noting about the code. Let's step through it step by step.
<Steps>
<Step title="Handling the incoming request">
To handle the incoming request, use the `Deno.serve` handler. The handler checks whether the request has the correct secret and then passes the request to the `handleUpdate` function.
```ts {1,6,10}
const handleUpdate = webhookCallback(bot, 'std/http');
Deno.serve(async (req) => {
try {
const url = new URL(req.url);
if (url.searchParams.get('secret') !== Deno.env.get('FUNCTION_SECRET')) {
return new Response('not allowed', { status: 405 });
}
return await handleUpdate(req);
} catch (err) {
console.error(err);
}
});
```
</Step>
<Step title="Handle voice, audio, and video messages">
The grammY frameworks provides a convenient way to [filter](https://grammy.dev/guide/filter-queries#combining-multiple-queries) for specific message types. In this case, the bot is listening for voice, audio, and video messages.
Using the request context, the bot extracts the file metadata and then uses [Supabase Background Tasks](https://supabase.com/docs/guides/functions/background-tasks) `EdgeRuntime.waitUntil` to run the transcription in the background.
This way you can provide an immediate response to the user and handle the transcription of the file in the background.
```ts {1,3,12,24}
bot.on([':voice', ':audio', ':video'], async (ctx) => {
try {
const file = await ctx.getFile();
const fileURL = `https://api.telegram.org/file/bot${telegramBotToken}/${file.file_path}`;
const fileMeta = ctx.message?.video ?? ctx.message?.voice ?? ctx.message?.audio;
if (!fileMeta) {
return ctx.reply('No video|audio|voice metadata found. Please try again.');
}
// Run the transcription in the background.
EdgeRuntime.waitUntil(
scribe({
fileURL,
fileType: fileMeta.mime_type!,
duration: fileMeta.duration,
chatId: ctx.chat.id,
messageId: ctx.message?.message_id!,
username: ctx.from?.username || '',
})
);
// Reply to the user immediately to let them know we received their file.
return ctx.reply('Received. Scribing...');
} catch (error) {
console.error(error);
return ctx.reply(
'Sorry, there was an error getting the file. Please try again with a smaller file!'
);
}
});
```
</Step>
<Step title="Transcription with the ElevenLabs API">
Finally, in the background worker, the bot uses the ElevenLabs JavaScript SDK to transcribe the file. Once the transcription is complete, the bot replies to the user with the transcript and writes a log entry to the Supabase database using [supabase-js](https://supabase.com/docs/reference/javascript).
```ts {29-38,43-46,54-65}
const elevenLabsClient = new ElevenLabsClient({
apiKey: Deno.env.get('ELEVENLABS_API_KEY') || '',
});
const supabase = createClient(
Deno.env.get('SUPABASE_URL') || '',
Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') || ''
);
async function scribe({
fileURL,
fileType,
duration,
chatId,
messageId,
username,
}: {
fileURL: string;
fileType: string;
duration: number;
chatId: number;
messageId: number;
username: string;
}) {
let transcript: string | null = null;
let languageCode: string | null = null;
let errorMsg: string | null = null;
try {
const sourceFileArrayBuffer = await fetch(fileURL).then((res) => res.arrayBuffer());
const sourceBlob = new Blob([sourceFileArrayBuffer], {
type: fileType,
});
const scribeResult = await elevenLabsClient.speechToText.convert({
file: sourceBlob,
model_id: 'scribe_v1',
tag_audio_events: false,
});
transcript = scribeResult.text;
languageCode = scribeResult.language_code;
// Reply to the user with the transcript
await bot.api.sendMessage(chatId, transcript, {
reply_parameters: { message_id: messageId },
});
} catch (error) {
errorMsg = error.message;
console.log(errorMsg);
await bot.api.sendMessage(chatId, 'Sorry, there was an error. Please try again.', {
reply_parameters: { message_id: messageId },
});
}
// Write log to Supabase.
const logLine = {
file_type: fileType,
duration,
chat_id: chatId,
message_id: messageId,
username,
language_code: languageCode,
error: errorMsg,
};
console.log({ logLine });
await supabase.from('transcription_logs').insert({ ...logLine, transcript });
}
```
</Step>
</Steps>
## Deploy to Supabase
If you haven't already, create a new Supabase account at [database.new](https://database.new) and link the local project to your Supabase account:
```bash
supabase link
```
### Apply the database migrations
Run the following command to apply the database migrations from the `supabase/migrations` directory:
```bash
supabase db push
```
Navigate to the [table editor](https://supabase.com/dashboard/project/_/editor) in your Supabase dashboard and you should see and empty `transcription_logs` table.
![Empty table](file:baaa0ccb-471f-41e2-b273-a9bd00e7f727)
Lastly, run the following command to deploy the Edge Function:
```bash
supabase functions deploy --no-verify-jwt scribe-bot
```
Navigate to the [Edge Functions view](https://supabase.com/dashboard/project/_/functions) in your Supabase dashboard and you should see the `scribe-bot` function deployed. Make a note of the function URL as you'll need it later, it should look something like `https://<project-ref>.functions.supabase.co/scribe-bot`.
![Edge Function deployed](file:d3aa3e01-853e-4140-a8aa-a18ecc9189c1)
### Set up the webhook
Set your bot's webhook url to `https://<PROJECT_REFERENCE>.functions.supabase.co/telegram-bot` (Replacing `<...>` with respective values). In order to do that, simply run a GET request to the following url (in your browser, for example):
```
https://api.telegram.org/bot<TELEGRAM_BOT_TOKEN>/setWebhook?url=https://<PROJECT_REFERENCE>.supabase.co/functions/v1/scribe-bot?secret=<FUNCTION_SECRET>
```
Note that the `FUNCTION_SECRET` is the secret you set in your `.env` file.
![Set webhook](file:4ba295c2-a77d-46e4-8e80-9f5eaf0b6965)
### Set the function secrets
Now that you have all your secrets set locally, you can run the following command to set the secrets in your Supabase project:
```bash
supabase secrets set --env-file supabase/functions/.env
```
## Test the bot
Finally you can test the bot by sending it a voice message, audio or video file.
![Test the bot](file:f1998a6c-659f-4198-abdd-6d9cff31b969)
After you see the transcript as a reply, navigate back to your table editor in the Supabase dashboard and you should see a new row in your `transcription_logs` table.
![New row in table](file:3d1b218c-cc3a-4710-8e79-c64032898a41)
# Create sound effects from text
> Learn how to use the text to sound effects API to generate cinematic sound effects from text.
## Introduction
Our [text to sound effects](https://elevenlabs.io/sound-effects) model enables you to create high-quality sound effects from a short description. These sound effects could be used in a variety of applications, including game development and building apps for music production.
In this tutorial, we will use the text to sound effects API to generate a sound effect from a short description using the Python SDK. We'll then save this sound effect to a file.
<Tip>
For general tips on prompting, see the [sound effects product
docs](/docs/product/sound-effects/overview). And for information on the API configuration visit
[the API reference](/docs/api-reference/sound-generation).
</Tip>
## How to generate a sound effect with the API
### Requirements
Before proceeding, please ensure that you have the following:
* An ElevenLabs account with an API key (here’s how to [find your API key](/docs/api-reference/authentication))
* Python installed on your machine
Then, install the ElevenLabs SDK as shown below
<CodeGroup>
```bash Python
pip install elevenlabs
```
</CodeGroup>
Install the necessary packages to manage your environmental variables:
<CodeGroup>
```bash Python
pip install python-dotenv
```
</CodeGroup>
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```bash .env
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
### Using the sound effects SDK
Now we can use the SDK to generate a sound effect from a short description and save it to a file as shown below.
```python
import os
from elevenlabs.client import ElevenLabs
from dotenv import load_dotenv
load_dotenv()
elevenlabs = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
def generate_sound_effect(text: str, output_path: str):
print("Generating sound effects...")
result = elevenlabs.text_to_sound_effects.convert(
text=text,
duration_seconds=10,  # Optional, if not provided will automatically determine the correct length
prompt_influence=0.3,  # Optional, if not provided will use the default value of 0.3
)
with open(output_path, "wb") as f:
for chunk in result:
f.write(chunk)
print(f"Audio saved to {output_path}")
if __name__ == "__main__":
generate_sound_effect("Dog barking", "output.mp3")
```
## Configuration
* `duration_seconds`: The duration of the sound effect in seconds. If not provided, the API will automatically determine the correct length. The maximum value is 22
* `prompt_influence`: The amount of influence the prompt has on the generated sound effect. If not provided, the API will use the default value of 0.3
### API pricing
The API is charged at 100 characters per generation with automatic duration or 25 characters per second with a set duration.
### Next steps
We're excited to see what you build with the API. Here are some ideas of what you might want to use it for:
* Adding sound effect generation to a video editing application
* Enabling users to create on-demand samples for their music production
* A new type of video game where every sound is generated dynamically
For higher rate limits of volume based discounts please [contact sales](https://elevenlabs.io/contact-sales).
# Dubbing audio
> Learn how to dub audio and video files across languages.
## Introduction
Dubbing videos and audio files from one language to another can be a great way to reach a wider audience. The ElevenLabs API provides a convenient way to automatically dub media files using state-of-the-art technology. In this guide, we will walk you through how to upload a video or audio file, dub it, and download the translated video. We'll also discuss how to directly dub a link such as a YouTube, TikTok, or Twitter video.
If you're looking to jump straight into the action, the complete code is available on the following repos:
* [Python example repo](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/dubbing/python).
<Tip>
On the 8th of May 2024 we launched the Dubbing API for all ElevenLabs tiers
</Tip>
## How to upload and dub a video or audio file
### Requirements
Before proceeding, please ensure that you have the following:
* An ElevenLabs account with an API key (here’s how to [find your API key](/docs/api-reference/authentication)).
* Python or Node.js installed on your machine
Then, install the ElevenLabs SDK as shown below
<CodeGroup>
```bash Python
pip install elevenlabs
```
</CodeGroup>
Install the necessary packages to manage your environmental variables:
<CodeGroup>
```bash Python
pip install python-dotenv
```
</CodeGroup>
Next, create a `.env` file in your project directory and fill it with your credentials like so:
```bash .env
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
```
### Start the dubbing
First we want to send the file to the ElevenLabs dubbing service
<CodeGroup>
```python Python
def create_dub_from_file(
input_file_path: str,
file_format: str,
source_language: str,
target_language: str,
) -> Optional[str]:
"""
Dubs an audio or video file from one language to another and saves the output.
Args:
input_file_path (str): The file path of the audio or video to dub.
file_format (str): The file format of the input file.
source_language (str): The language of the input file.
target_language (str): The target language to dub into.
Returns:
Optional[str]: The file path of the dubbed file or None if operation failed.
"""
if not os.path.isfile(input_file_path):
raise FileNotFoundError(f"The input file does not exist: {input_file_path}")
with open(input_file_path, "rb") as audio_file:
response = client.dubbing.dub_a_video_or_an_audio_file(
file=(os.path.basename(input_file_path), audio_file, file_format), # Optional file
target_lang=target_language, # The target language to dub the content into. Can be none if dubbing studio editor is enabled and running manual mode
source_lang=source_language, # Source language
num_speakers=1, # Number of speakers to use for the dubbing.
watermark=False,  # Whether to apply watermark to the output video.
)
# rest of the code
```
</CodeGroup>
### Check for completion
The `wait_for_dubbing_completion()` function within the `dubbing_utils.py` file polls the API to check whether the dubbing process is complete. If completed, it proceeds to the next step; otherwise, it reports the status or failure.
<CodeGroup>
```python Python
def wait_for_dubbing_completion(dubbing_id: str) -> bool:
"""
Waits for the dubbing process to complete by periodically checking the status.
Args:
dubbing_id (str): The dubbing project id.
Returns:
bool: True if the dubbing is successful, False otherwise.
"""
MAX_ATTEMPTS = 120
CHECK_INTERVAL = 10  # In seconds
for _ in range(MAX_ATTEMPTS):
metadata = client.dubbing.get_dubbing_project_metadata(dubbing_id)
if metadata.status == "dubbed":
return True
elif metadata.status == "dubbing":
print(
"Dubbing in progress... Will check status again in",
CHECK_INTERVAL,
"seconds.",
)
time.sleep(CHECK_INTERVAL)
else:
print("Dubbing failed:", metadata.error_message)
return False
print("Dubbing timed out")
return False
```
</CodeGroup>
### Save the video locally
Upon completion of dubbing, the `download_dubbed_file()` function in `dubbing_utils.py` will save the dubbed file to a local directory, typically under the `data/{dubbing_id}/{language_code}.mp4`.
<CodeGroup>
```python Python
def download_dubbed_file(dubbing_id: str, language_code: str) -> str:
"""
Downloads the dubbed file for a given dubbing ID and language code.
Args:
dubbing_id: The ID of the dubbing project.
language_code: The language code for the dubbing.
Returns:
The file path to the downloaded dubbed file.
"""
dir_path = f"data/{dubbing_id}"
os.makedirs(dir_path, exist_ok=True)
file_path = f"{dir_path}/{language_code}.mp4"
with open(file_path, "wb") as file:
for chunk in client.dubbing.get_dubbed_file(dubbing_id, language_code):
file.write(chunk)
return file_path
```
</CodeGroup>
### Putting it together
We add the `wait_for_dubbing_completion`(`waitForDubbingCompletion`) function and the `download_dubbed_file`(`downloadDubbedFile`) function together to create the final function.
<CodeGroup>
```python Python
def create_dub_from_file(
input_file_path: str,
file_format: str,
source_language: str,
target_language: str,
) -> Optional[str]:
"""
Dubs an audio or video file from one language to another and saves the output.
Args:
input_file_path (str): The file path of the audio or video to dub.
file_format (str): The file format of the input file.
source_language (str): The language of the input file.
target_language (str): The target language to dub into.
Returns:
Optional[str]: The file path of the dubbed file or None if operation failed.
"""
if not os.path.isfile(input_file_path):
raise FileNotFoundError(f"The input file does not exist: {input_file_path}")
with open(input_file_path, "rb") as audio_file:
response = client.dubbing.dub_a_video_or_an_audio_file(
file=(os.path.basename(input_file_path), audio_file, file_format),
target_lang=target_language,
source_lang=source_language,
num_speakers=1,
watermark=False,  # reduces the characters used if enabled, only works for videos not audio
)
dubbing_id = response.dubbing_id
if wait_for_dubbing_completion(dubbing_id):
output_file_path = download_dubbed_file(dubbing_id, target_language)
return output_file_path
else:
return None
```
</CodeGroup>
We then use the final the function as shown below.
<CodeGroup>
```python create_a_dub_from_file.py (Python)
if __name__ == "__main__":
result = create_dub_from_file(
"../example_speech.mp3",  # Input file path
"audio/mpeg",  # File format
"en",  # Source language
"es",  # Target language
)
if result:
print("Dubbing was successful! File saved at:", result)
else:
print("Dubbing failed or timed out.")
```
</CodeGroup>
## How to dub a video from YouTube, TikTok, Twitter or Vimeo
For dubbing web-based content, instead of uploading a file you can pass in a URL. This supports popular platforms like YouTube, TikTok, Twitter, and Vimeo.
<CodeGroup>
```python Python
def create_dub_from_url(
source_url: str,
source_language: str,
target_language: str,
) -> Optional[str]:
"""
Downloads a video from a URL, and creates a dubbed version in the target language.
Args:
source_url (str): The URL of the source video to dub. Can be a YouTube link, TikTok, X (Twitter) or a Vimeo link.
source_language (str): The language of the source video.
target_language (str): The target language to dub into.
Returns:
Optional[str]: The file path of the dubbed file or None if operation failed.
"""
response = client.dubbing.dub_a_video_or_an_audio_file(
source_url=source_url, # URL of the source video/audio file.
target_lang=target_language, # The Target language to dub the content into. Can be none if dubbing studio editor is enabled and running manual mode
source_lang=source_language, # Source language.
num_speakers=1, # Number of speakers to use for the dubbing.
watermark=True,  # Whether to apply watermark to the output video.
)
dubbing_id = response.dubbing_id
if wait_for_dubbing_completion(dubbing_id):
output_file_path = download_dubbed_file(dubbing_id, target_language)
return output_file_path
else:
return None
```
</CodeGroup>
You can then call the function as shown below.
<CodeGroup>
```python Python
if __name__ == "__main__":
source_url = "https://www.youtube.com/watch?v=0EqSXDwTq6U"  # Charlie bit my finger
source_language = "en"
target_language = "fr"
result = create_dub_from_url(source_url, source_language, target_language)
if result:
print("Dubbing was successful! File saved at:", result)
else:
print("Dubbing failed or timed out.")
```
</CodeGroup>
## Conclusion
With this guide and the accompanying code structure, you now have a basic setup for dubbing audio and video content using the ElevenLabs API. Whether you're working with local files or content from URLs, you can create multilingual versions of your media to cater to diverse audiences.
Remember to always follow the best practices when dealing with API keys and sensitive data, and consult the ElevenLabs API documentation for more advanced features and options. Happy dubbing!
For additional information on dubbing capabilities, translation services, and available languages, please refer to the [ElevenLabs API documentation](/docs/api-reference/dubbing/dub-a-video-or-an-audio-file).
Should you encounter any issues or have questions, our [GitHub Issues page](https://github.com/elevenlabs/elevenlabs-docs/issues) is open for your queries and feedback.
## List of supported languages for dubbing
| No | Language Name | Language Code |
| -- | ------------- | ------------- |
| 1  | English       | en            |
| 2  | Hindi         | hi            |
| 3  | Portuguese    | pt            |
| 4  | Chinese       | zh            |
| 5  | Spanish       | es            |
| 6  | French        | fr            |
| 7  | German        | de            |
| 8  | Japanese      | ja            |
| 9  | Arabic        | ar            |
| 10 | Russian       | ru            |
| 11 | Korean        | ko            |
| 12 | Indonesian    | id            |
| 13 | Italian       | it            |
| 14 | Dutch         | nl            |
| 15 | Turkish       | tr            |
| 16 | Polish        | pl            |
| 17 | Swedish       | sv            |
| 18 | Filipino      | fil           |
| 19 | Malay         | ms            |
| 20 | Romanian      | ro            |
| 21 | Ukrainian     | uk            |
| 22 | Greek         | el            |
| 23 | Czech         | cs            |
| 24 | Danish        | da            |
| 25 | Finnish       | fi            |
| 26 | Bulgarian     | bg            |
| 27 | Croatian      | hr            |
| 28 | Slovak        | sk            |
| 29 | Tamil         | ta            |
# Cross-platform Voice Agents with Expo React Native
> Build conversational AI agents that work across iOS, Android, and web using Expo React Native and the ElevenLabs Conversational AI SDK.
## Introduction
In this tutorial you will learn how to build a voice agent that works across iOS, Android, and web using [Expo React Native](https://expo.dev/) and the ElevenLabs Conversational AI SDK.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/ADb9wziKgoU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Tip title="Prefer to jump straight to the code?" icon="lightbulb">
Find the [example project on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/react-native/elevenlabs-conversational-ai-expo-react-native).
</Tip>
## Requirements
* An ElevenLabs account with an [API key](/app/settings/api-keys).
* Node.js v18 or higher installed on your machine.
## Setup
### Create a new Expo project
Using `create-expo-app`, create a new blank Expo project:
```bash
npx create-expo-app@latest --template blank-typescript
```
### Enable microphone permissions
In the `app.json` file, add the following permissions:
```json app.json
{
"expo": {
"scheme": "elevenlabs",
// ...
"ios": {
"infoPlist": {
"NSMicrophoneUsageDescription": "This app uses the microphone to record audio."
},
"supportsTablet": true,
"bundleIdentifier": "com.anonymous.elevenlabs-conversational-ai-expo-react-native"
}
// ...
}
}
```
This will allow the React Native web view to prompt for microphone permissions when the conversation is started.
### Install dependencies
This approach relies on [Expo DOM components](https://docs.expo.dev/guides/dom-components/) to make the conversational AI agent work across platforms. There is a couple of dependencies you need to install to make this work.
```bash
npx expo install @11labs/react
npx expo install expo-dev-client # tunnel support
npx expo install react-native-webview # DOM components support
npx expo install react-dom react-native-web @expo/metro-runtime # RN web support
# Cool client tools
npx expo install expo-battery
npx expo install expo-brightness
```
## Expo DOM components
Expo offers a [novel approach](https://docs.expo.dev/guides/dom-components/) to work with modern web code directly in a native app via the `use dom` directive. This approach means that you can use our [Conversational AI React SDK](https://elevenlabs.io/docs/conversational-ai/libraries/react) across all platforms using the same code.
Under the hood, Expo uses `react-native-webview` to render the web code in a native component. To allow the webview to access the microphone, you need to make sure to use `npx expo start --tunnel` to start the Expo development server locally so that the webview is served over https.
### Create the conversational AI DOM component
Create a new file in the components folder: `./components/ConvAI.tsx` and add the following code:
```tsx /components/ConvAI.tsx {10-19,33-40,51-65}
'use dom';
import { useConversation } from '@11labs/react';
import { Mic } from 'lucide-react-native';
import { useCallback } from 'react';
import { View, Pressable, StyleSheet } from 'react-native';
import tools from '../utils/tools';
async function requestMicrophonePermission() {
try {
await navigator.mediaDevices.getUserMedia({ audio: true });
return true;
} catch (error) {
console.log(error);
console.error('Microphone permission denied');
return false;
}
}
export default function ConvAiDOMComponent({
platform,
get_battery_level,
change_brightness,
flash_screen,
}: {
dom?: import('expo/dom').DOMProps;
platform: string;
get_battery_level: typeof tools.get_battery_level;
change_brightness: typeof tools.change_brightness;
flash_screen: typeof tools.flash_screen;
}) {
const conversation = useConversation({
onConnect: () => console.log('Connected'),
onDisconnect: () => console.log('Disconnected'),
onMessage: (message) => {
console.log(message);
},
onError: (error) => console.error('Error:', error),
});
const startConversation = useCallback(async () => {
try {
// Request microphone permission
const hasPermission = await requestMicrophonePermission();
if (!hasPermission) {
alert('No permission');
return;
}
// Start the conversation with your agent
await conversation.startSession({
agentId: 'YOUR_AGENT_ID', // Replace with your agent ID
dynamicVariables: {
platform,
},
clientTools: {
get_battery_level,
change_brightness,
flash_screen,
},
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}, [conversation]);
const stopConversation = useCallback(async () => {
await conversation.endSession();
}, [conversation]);
return (
<Pressable
style={[styles.callButton, conversation.status === 'connected' && styles.callButtonActive]}
onPress={conversation.status === 'disconnected' ? startConversation : stopConversation}
>
<View
style={[
styles.buttonInner,
conversation.status === 'connected' && styles.buttonInnerActive,
]}
>
<Mic size={32} color="#E2E8F0" strokeWidth={1.5} style={styles.buttonIcon} />
</View>
</Pressable>
);
}
const styles = StyleSheet.create({
callButton: {
width: 120,
height: 120,
borderRadius: 60,
backgroundColor: 'rgba(255, 255, 255, 0.1)',
alignItems: 'center',
justifyContent: 'center',
marginBottom: 24,
},
callButtonActive: {
backgroundColor: 'rgba(239, 68, 68, 0.2)',
},
buttonInner: {
width: 80,
height: 80,
borderRadius: 40,
backgroundColor: '#3B82F6',
alignItems: 'center',
justifyContent: 'center',
shadowColor: '#3B82F6',
shadowOffset: {
width: 0,
height: 0,
},
shadowOpacity: 0.5,
shadowRadius: 20,
elevation: 5,
},
buttonInnerActive: {
backgroundColor: '#EF4444',
shadowColor: '#EF4444',
},
buttonIcon: {
transform: [{ translateY: 2 }],
},
});
```
### Native client tools
A big part of building conversational AI agents is allowing the agent access and execute functionality dynamically. This can be done via [client tools](https://elevenlabs.io/docs/conversational-ai/customization/tools-events/client-tools).
In order for DOM components to exectute native actions, you can send type-safe native functions to DOM components by passing asynchronous functions as top-level props to the DOM component.
Create a new file to hold your client tools: `./utils/tools.ts` and add the following code:
```ts ./utils/tools.ts
import * as Battery from 'expo-battery';
import * as Brightness from 'expo-brightness';
const get_battery_level = async () => {
const batteryLevel = await Battery.getBatteryLevelAsync();
console.log('batteryLevel', batteryLevel);
if (batteryLevel === -1) {
return 'Error: Device does not support retrieving the battery level.';
}
return batteryLevel;
};
const change_brightness = ({ brightness }: { brightness: number }) => {
console.log('change_brightness', brightness);
Brightness.setSystemBrightnessAsync(brightness);
return brightness;
};
const flash_screen = () => {
Brightness.setSystemBrightnessAsync(1);
setTimeout(() => {
Brightness.setSystemBrightnessAsync(0);
}, 200);
return 'Successfully flashed the screen.';
};
const tools = {
get_battery_level,
change_brightness,
flash_screen,
};
export default tools;
```
### Dynamic variables
In addition to the client tools, we're also injecting the platform (web, iOS, Android) as a [dynamic variable](https://elevenlabs.io/docs/conversational-ai/customization/personalization/dynamic-variables) both into the first message, and the prompt. To do this, we pass the platform as a top-level prop to the DOM component, and then in our DOM component pass it to the `startConversation` configuration:
```tsx ./components/ConvAI.tsx {3,34-36}
// ...
export default function ConvAiDOMComponent({
platform,
get_battery_level,
change_brightness,
flash_screen,
}: {
dom?: import('expo/dom').DOMProps;
platform: string;
get_battery_level: typeof tools.get_battery_level;
change_brightness: typeof tools.change_brightness;
flash_screen: typeof tools.flash_screen;
}) {
const conversation = useConversation({
onConnect: () => console.log('Connected'),
onDisconnect: () => console.log('Disconnected'),
onMessage: (message) => {
console.log(message);
},
onError: (error) => console.error('Error:', error),
});
const startConversation = useCallback(async () => {
try {
// Request microphone permission
const hasPermission = await requestMicrophonePermission();
if (!hasPermission) {
alert('No permission');
return;
}
// Start the conversation with your agent
await conversation.startSession({
agentId: 'YOUR_AGENT_ID', // Replace with your agent ID
dynamicVariables: {
platform,
},
clientTools: {
get_battery_level,
change_brightness,
flash_screen,
},
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}, [conversation]);
//...
}
// ...
```
### Add the component to your app
Add the component to your app by adding the following code to your `./App.tsx` file:
```tsx ./App.tsx {44-52}
import { LinearGradient } from 'expo-linear-gradient';
import { StatusBar } from 'expo-status-bar';
import { View, Text, StyleSheet, SafeAreaView } from 'react-native';
import { Platform } from 'react-native';
import ConvAiDOMComponent from './components/ConvAI';
import tools from './utils/tools';
export default function App() {
return (
<SafeAreaView style={styles.container}>
<LinearGradient colors={['#0F172A', '#1E293B']} style={StyleSheet.absoluteFill} />
<View style={styles.topContent}>
<Text style={styles.description}>
Cross-platform conversational AI agents with ElevenLabs and Expo React Native.
</Text>
<View style={styles.toolsList}>
<Text style={styles.toolsTitle}>Available Client Tools:</Text>
<View style={styles.toolItem}>
<Text style={styles.toolText}>Get battery level</Text>
<View style={styles.platformTags}>
<Text style={styles.platformTag}>web</Text>
<Text style={styles.platformTag}>ios</Text>
<Text style={styles.platformTag}>android</Text>
</View>
</View>
<View style={styles.toolItem}>
<Text style={styles.toolText}>Change screen brightness</Text>
<View style={styles.platformTags}>
<Text style={styles.platformTag}>ios</Text>
<Text style={styles.platformTag}>android</Text>
</View>
</View>
<View style={styles.toolItem}>
<Text style={styles.toolText}>Flash screen</Text>
<View style={styles.platformTags}>
<Text style={styles.platformTag}>ios</Text>
<Text style={styles.platformTag}>android</Text>
</View>
</View>
</View>
<View style={styles.domComponentContainer}>
<ConvAiDOMComponent
dom={{ style: styles.domComponent }}
platform={Platform.OS}
get_battery_level={tools.get_battery_level}
change_brightness={tools.change_brightness}
flash_screen={tools.flash_screen}
/>
</View>
</View>
<StatusBar style="light" />
</SafeAreaView>
);
}
const styles = StyleSheet.create({
container: {
flex: 1,
},
topContent: {
paddingTop: 40,
paddingHorizontal: 24,
alignItems: 'center',
},
description: {
fontFamily: 'Inter-Regular',
fontSize: 16,
color: '#E2E8F0',
textAlign: 'center',
maxWidth: 300,
lineHeight: 24,
marginBottom: 24,
},
toolsList: {
backgroundColor: 'rgba(255, 255, 255, 0.05)',
borderRadius: 16,
padding: 20,
width: '100%',
maxWidth: 400,
marginBottom: 24,
},
toolsTitle: {
fontFamily: 'Inter-Bold',
fontSize: 18,
color: '#E2E8F0',
marginBottom: 16,
},
toolItem: {
flexDirection: 'row',
justifyContent: 'space-between',
alignItems: 'center',
paddingVertical: 12,
borderBottomWidth: 1,
borderBottomColor: 'rgba(255, 255, 255, 0.1)',
},
toolText: {
fontFamily: 'Inter-Regular',
fontSize: 14,
color: '#E2E8F0',
},
platformTags: {
flexDirection: 'row',
gap: 8,
},
platformTag: {
fontSize: 12,
color: '#94A3B8',
backgroundColor: 'rgba(148, 163, 184, 0.1)',
paddingHorizontal: 8,
paddingVertical: 4,
borderRadius: 6,
overflow: 'hidden',
fontFamily: 'Inter-Regular',
},
domComponentContainer: {
width: 120,
height: 120,
alignItems: 'center',
justifyContent: 'center',
marginBottom: 24,
},
domComponent: {
width: 120,
height: 120,
},
});
```
## Agent configuration
<Steps>
<Step title="Sign in to ElevenLabs">
Go to [elevenlabs.io](https://elevenlabs.io/sign-up) and sign in to your account.
</Step>
<Step title="Create a new agent">
Navigate to [Conversational AI > Agents](https://elevenlabs.io/app/conversational-ai/agents) and
create a new agent from the blank template.
</Step>
<Step title="Set the first message">
Set the first message and specify the dynamic variable for the platform.
```txt
Hi there, woah, so cool that I'm running on {{platform}}. What can I help you with?
```
</Step>
<Step title="Set the system prompt">
Set the system prompt. You can also include dynamic variables here.
```txt
You are a helpful assistant running on {{platform}}. You have access to certain tools that allow you to check the user device battery level and change the display brightness. Use these tools if the user asks about them. Otherwise, just answer the question.
```
</Step>
<Step title="Set up the client tools">
Set up the following client tools:
* Name: `get_battery_level`
* Description: Gets the device battery level as decimal point percentage.
* Wait for response: `true`
* Response timeout (seconds): 3
* Name: `change_brightness`
* Description: Changes the brightness of the device screen.
* Wait for response: `true`
* Response timeout (seconds): 3
* Parameters:
* Data Type: `number`
* Identifier: `brightness`
* Required: `true`
* Value Type: `LLM Prompt`
* Description: A number between 0 and 1, inclusive, representing the desired screen brightness.
* Name: `flash_screen`
* Description: Quickly flashes the screen on and off.
* Wait for response: `true`
* Response timeout (seconds): 3
</Step>
</Steps>
## Run the app
Modyfing the brightness is not supported within Expo Go, therefore you will need to prebuild the app and then run it on a native device.
* Terminal 1:
* Run `npx expo prebuild --clean`
```bash
npx expo prebuild --clean
```
* Run `npx expo start --tunnel` to start the Expo development server over https.
```bash
npx expo start --tunnel
```
* Terminal 2:
* Run `npx expo run:ios --device` to run the app on your iOS device.
```bash
npx expo run:ios --device
```
# Controls
> Learn how to control delivery, pronunciation & emotion of text to speech.
<Info>
We are actively working on *Director's Mode* to give you even greater control over outputs.
</Info>
This guide provides techniques to enhance text-to-speech outputs using ElevenLabs models. Experiment with these methods to discover what works best for your needs. These techniques provide a practical way to achieve nuanced results until advanced features like *Director's Mode* are rolled out.
## Pauses
Use `<break time="x.xs" />` for natural pauses up to 3 seconds.
<Note>
Using too many break tags in a single generation can cause instability. The AI might speed up, or
introduce additional noises or audio artifacts. We are working on resolving this.
</Note>
```text Example
"Hold on, let me think." <break time="1.5s" /> "Alright, I’ve got it."
```
* **Consistency:** Use `<break>` tags consistently to maintain natural speech flow. Excessive use can lead to instability.
* **Voice-Specific Behavior:** Different voices may handle pauses differently, especially those trained with filler sounds like "uh" or "ah."
Alternatives to `<break>` include dashes (- or --) for short pauses or ellipses (...) for hesitant tones. However, these are less consistent.
```text Example
"It… well, it might work." "Wait — what’s that noise?"
```
## Pronunciation
### Phoneme Tags
Specify pronunciation using [SSML phoneme tags](https://en.wikipedia.org/wiki/Speech_Synthesis_Markup_Language). Supported alphabets include [CMU](https://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary) Arpabet and the [International Phonetic Alphabet (IPA)](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet).
<Note>
Phoneme tags are only compatible with "Eleven Flash v2", "Eleven Turbo v2" and "Eleven English v1"
[models](/docs/models).
</Note>
<CodeBlocks>
```xml CMU Arpabet Example
<phoneme alphabet="cmu-arpabet" ph="M AE1 D IH0 S AH0 N">
Madison
</phoneme>
```
```xml IPA Example
<phoneme alphabet="ipa" ph="ˈæktʃuəli">
actually
</phoneme>
```
</CodeBlocks>
We recommend using CMU Arpabet for consistent and predictable results with current AI models. While IPA can be effective, CMU Arpabet generally offers more reliable performance.
Phoneme tags only work for individual words. If for example you have a name with a first and last name that you want to be pronounced a certain way, you will need to create a phoneme tag for each word.
Ensure correct stress marking for multi-syllable words to maintain accurate pronunciation. For example:
<CodeBlocks>
```xml Correct usage
<phoneme alphabet="cmu-arpabet" ph="P R AH0 N AH0 N S IY EY1 SH AH0 N">
pronunciation
</phoneme>
```
```xml Incorrect usage
<phoneme alphabet="cmu-arpabet" ph="P R AH N AH N S IY EY SH AH N">
pronunciation
</phoneme>
```
</CodeBlocks>
### Alias Tags
For models that don't support phoneme tags, you can try writing words more phonetically. You can also employ various tricks such as capital letters, dashes, apostrophes, or even single quotation marks around a single letter or letters.
As an example, a word like “trapezii” could be spelt “trapezIi” to put more emphasis on the “ii” of the word.
You can either replace the word directly in your text, or if you want to specify pronunciation using other words or phrases when using a pronunciation dictionary, you can use alias tags for this. This can be useful if you're generating using Multilingual v2 or Turbo v2.5, which don't support phoneme tags. You can use pronunciation dictionaries with Studio, Dubbing Studio and Speech Synthesis via the API.
For example, if your text includes a name that has an unusual pronunciation that the AI might struggle with, you could use an alias tag to specify how you would like it to be pronounced:
```
<lexeme>
<grapheme>Claughton</grapheme>
<alias>Cloffton</alias>
</lexeme>
```
If you want to make sure that an acronym is always delivered in a certain way whenever it is incountered in your text, you can use an alias tag to specify this:
```
<lexeme>
<grapheme>UN</grapheme>
<alias>United Nations</alias>
</lexeme>
```
### Pronunciation Dictionaries
Some of our tools, such as Studio and Dubbing Studio, allow you to create and upload a pronunciation dictionary. These allow you to specify the pronunciation of certain words, such as character or brand names, or to specify how acronyms should be read.
Pronunciation dictionaries allow this functionality by enabling you to upload a lexicon or dictionary file that specifies pairs of words and how they should be pronounced, either using a phonetic alphabet or word substitutions.
Whenever one of these words is encountered in a project, the AI model will pronounce the word using the specified replacement.
To provide a pronunciation dictionary file, open the settings for a project and upload a file in either TXT or the [.PLS format](https://www.w3.org/TR/pronunciation-lexicon/). When a dictionary is added to a project it will automatically recalculate which pieces of the project will need to be re-converted using the new dictionary file and mark these as unconverted.
Currently we only support pronunciation dictionaries that specify replacements using phoneme or alias tags.
Both phonemes and aliases are sets of rules that specify a word or phrase they are looking for, referred to as a grapheme, and what it will be replaced with. Please note that searches are case sensitive. When checking for a replacement word in a pronunciation dictionary, the dictionary is checked from start to end and only the very first replacement is used.
### Pronunciation Dictionary Example
Here is an example pronunciation dictionary that specifies in IPA the pronunciation of "Apple" with IPA of "ˈæpl̩" and "UN" with an alias of "United Nations":
```
<?xml version="1.0" encoding="UTF-8"?>
<lexicon version="1.0"
xmlns="http://www.w3.org/2005/01/pronunciation-lexicon"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2005/01/pronunciation-lexicon
http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd"
alphabet="ipa" xml:lang="en-GB">
<lexeme>
<grapheme>Apple</grapheme>
<phoneme>ˈæpl̩</phoneme>
</lexeme>
<lexeme>
<grapheme>UN</grapheme>
<alias>United Nations</alias>
</lexeme>
</lexicon>
```
To generate a pronunciation dictionary `.pls` file, there are a few open source tools available:
* [Sequitur G2P](https://github.com/sequitur-g2p/sequitur-g2p) - Open-source tool that learns pronunciation rules from data and can generate phonetic transcriptions.
* [Phonetisaurus](https://github.com/AdolfVonKleist/Phonetisaurus) - Open-source G2P system trained on existing dictionaries like CMUdict.
* [eSpeak](https://github.com/espeak-ng/espeak-ng) - Speech synthesizer that can generate phoneme transcriptions from text.
* [CMU Pronouncing Dictionary](https://github.com/cmusphinx/cmudict) - A pre-built English dictionary with phonetic transcriptions.
## Emotion
Convey emotions through narrative context or explicit dialogue tags. This approach helps the AI understand the tone and emotion to emulate.
```text Example
You’re leaving?" she asked, her voice trembling with sadness. "That’s it!" he exclaimed triumphantly.
```
Explicit dialogue tags yield more predictable results than relying solely on context, however the model will still speak out the emotional delivery guides. These can be removed in post-production using an audio editor if unwanted.
## Pace
Pacing can be controlled by writing in a natural, narrative style. For voice cloning, longer, continuous samples are recommended to avoid pacing issues like unnaturally fast speech.
```text Example
"I… I thought you’d understand," he said, his voice slowing with disappointment.
```
Sample Length: Use longer, continuous samples for voice cloning to avoid pacing issues.
Narrative Style: Write in a narrative style to naturally control pacing and emotion, similar to scriptwriting.
## Tips
<AccordionGroup>
<Accordion title="Common Issues">
<ul>
<li>
Inconsistent pauses: Ensure <code>\<break time="x.xs" /></code> syntax is used for
pauses.
</li>
<li>
Pronunciation errors: Use CMU Arpabet or IPA phoneme tags for precise pronunciation.
</li>
<li>
Emotion mismatch: Add narrative context or explicit tags to guide emotion.{' '}
<strong>Remember to remove any emotional guidance text in post-production.</strong>
</li>
</ul>
</Accordion>
<Accordion title="Tips for Improving Output">
Experiment with alternative phrasing to achieve desired pacing or emotion. For complex sound
effects, break prompts into smaller, sequential elements and combine results manually.
</Accordion>
</AccordionGroup>
## Creative control
While we are actively developing a "Director's Mode" to give users even greater control over outputs, here are some interim techniques to maximize creativity and precision:
<Steps>
### Narrative styling
Write prompts in a narrative style, similar to scriptwriting, to guide tone and pacing effectively.
### Layered outputs
Generate sound effects or speech in segments and layer them together using audio editing software for more complex compositions.
### Phonetic experimentation
If pronunciation isn't perfect, experiment with alternate spellings or phonetic approximations to achieve desired results.
### Manual adjustments
Combine individual sound effects manually in post-production for sequences that require precise timing.
### Feedback iteration
Iterate on results by tweaking descriptions, tags, or emotional cues.
</Steps>
# Normalization
> Learn how to normalize text for Text to Speech.
When using Text to Speech with complex items like phone numbers, zip codes and emails they might be mispronounced. This is often due to the specific items not being in the training set and smaller models failing to generalize how they should be pronounced. This guide will clarify when those discrepancies happen and how to have them pronounced correctly.
## Why do models read out inputs differently?
Certain models are trained to read out numbers and phrases in a more human way. For instance, the phrase "\$1,000,000" is correctly read out as "one million dollars" by the Eleven Multilingual v2 model. However, the same phrase is read out as "one thousand thousand dollars" by the Eleven Flash v2.5 model.
The reason for this is that the Multilingual v2 model is a larger model and can better generalize the reading out of numbers in a way that is more natural for human listeners, whereas the Flash v2.5 model is a much smaller model and so cannot.
### Common examples
Text to Speech models can struggle with the following:
* Phone numbers ("123-456-7890")
* Currencies ("\$47,345.67")
* Calendar events ("2024-01-01")
* Time ("9:23 AM")
* Addresses ("123 Main St, Anytown, USA")
* URLs ("example.com/link/to/resource")
* Abbreviations for units ("TB" instead of "Terabyte")
* Shortcuts ("Ctrl + Z")
## Mitigation
### Use trained models
The simplest way to mitigate this is to use a TTS model that is trained to read out numbers and phrases in a more human way, such as the Eleven Multilingual v2 model. This however might not always be possible, for instance if you have a use case where low latency is critical (e.g. Conversational AI).
### Apply normalization in LLM prompts
In the case of using an LLM to generate the text for TTS, you can add normalization instructions to the prompt.
<Steps>
<Step title="Use clear and explicit prompts">
LLMs respond best to structured and explicit instructions. Your prompt should clearly specify that you want text converted into a readable format for speech.
</Step>
<Step title="Handle different number formats">
Not all numbers are read out in the same way. Consider how different number types should be spoken:
* Cardinal numbers: 123 → "one hundred twenty-three"
* Ordinal numbers: 2nd → "second"
* Monetary values: \$45.67 → "forty-five dollars and sixty-seven cents"
* Phone numbers: "123-456-7890" → "one two three, four five six, seven eight nine zero"
* Decimals & Fractions: "3.5" → "three point five", "⅔" → "two-thirds"
* Roman numerals: "XIV" → "fourteen" (or "the fourteenth" if a title)
</Step>
<Step title="Remove or expand abbreviations">
Common abbreviations should be expanded for clarity:
* "Dr." → "Doctor"
* "Ave." → "Avenue"
* "St." → "Street" (but "St. Patrick" should remain)
You can request explicit expansion in your prompt:
> Expand all abbreviations to their full spoken forms.
</Step>
<Step title="Alphanumeric normalization">
Not all normalization is about numbers, certain alphanumeric phrases should also be normalized for clarity:
* Shortcuts: "Ctrl + Z" → "control z"
* Abbreviations for units: "100km" → "one hundred kilometers"
* Symbols: "100%" → "one hundred percent"
* URLs: "elevenlabs.io/docs" → "eleven labs dot io slash docs"
* Calendar events: "2024-01-01" → "January first, two-thousand twenty-four"
</Step>
<Step title="Consider edge cases">
Different contexts might require different conversions:
* Dates: "01/02/2023" → "January second, twenty twenty-three" or "the first of February, twenty twenty-three" (depending on locale)
* Time: "14:30" → "two thirty PM"
If you need a specific format, explicitly state it in the prompt.
</Step>
</Steps>
#### Putting it all together
This prompt will act as a good starting point for most use cases:
```text maxLines=0
Convert the output text into a format suitable for text-to-speech. Ensure that numbers, symbols, and abbreviations are expanded for clarity when read aloud. Expand all abbreviations to their full spoken forms.
Example input and output:
"$42.50" → "forty-two dollars and fifty cents"
"£1,001.32" → "one thousand and one pounds and thirty-two pence"
"1234" → "one thousand two hundred thirty-four"
"3.14" → "three point one four"
"555-555-5555" → "five five five, five five five, five five five five"
"2nd" → "second"
"XIV" → "fourteen" - unless it's a title, then it's "the fourteenth"
"3.5" → "three point five"
"⅔" → "two-thirds"
"Dr." → "Doctor"
"Ave." → "Avenue"
"St." → "Street" (but saints like "St. Patrick" should remain)
"Ctrl + Z" → "control z"
"100km" → "one hundred kilometers"
"100%" → "one hundred percent"
"elevenlabs.io/docs" → "eleven labs dot io slash docs"
"2024-01-01" → "January first, two-thousand twenty-four"
"123 Main St, Anytown, USA" → "one two three Main Street, Anytown, United States of America"
"14:30" → "two thirty PM"
"01/02/2023" → "January second, two-thousand twenty-three" or "the first of February, two-thousand twenty-three", depending on locale of the user
```
### Use Regular Expressions for preprocessing
If using code to prompt an LLM, you can use regular expressions to normalize the text before providing it to the model. This is a more advanced technique and requires some knowledge of regular expressions. Here are some simple examples:
<CodeBlocks>
```python title="normalize_text.py" maxLines=0
# Be sure to install the inflect library before running this code
import inflect
import re
# Initialize inflect engine for number-to-word conversion
p = inflect.engine()
def normalize_text(text: str) -> str:
# Convert monetary values
def money_replacer(match):
currency_map = {"$": "dollars", "£": "pounds", "€": "euros", "¥": "yen"}
currency_symbol, num = match.groups()
# Remove commas before parsing
num_without_commas = num.replace(',', '')
# Check for decimal points to handle cents
if '.' in num_without_commas:
dollars, cents = num_without_commas.split('.')
dollars_in_words = p.number_to_words(int(dollars))
cents_in_words = p.number_to_words(int(cents))
return f"{dollars_in_words} {currency_map.get(currency_symbol, 'currency')} and {cents_in_words} cents"
else:
# Handle whole numbers
num_in_words = p.number_to_words(int(num_without_commas))
return f"{num_in_words} {currency_map.get(currency_symbol, 'currency')}"
# Regex to handle commas and decimals
text = re.sub(r"([$£€¥])(\d+(?:,\d{3})*(?:\.\d{2})?)", money_replacer, text)
# Convert phone numbers
def phone_replacer(match):
return ", ".join(" ".join(p.number_to_words(int(digit)) for digit in group) for group in match.groups())
text = re.sub(r"(\d{3})-(\d{3})-(\d{4})", phone_replacer, text)
return text
# Example usage
print(normalize_text("$1,000"))   # "one thousand dollars"
print(normalize_text("£1000"))   # "one thousand pounds"
print(normalize_text("€1000"))   # "one thousand euros"
print(normalize_text("¥1000"))   # "one thousand yen"
print(normalize_text("$1,234.56"))   # "one thousand two hundred thirty-four dollars and fifty-six cents"
print(normalize_text("555-555-5555"))  # "five five five, five five five, five five five five"
```
```typescript title="normalizeText.ts" maxLines=0
// Be sure to install the number-to-words library before running this code
import { toWords } from 'number-to-words';
function normalizeText(text: string): string {
return (
text
// Convert monetary values (e.g., "$1000" → "one thousand dollars", "£1000" → "one thousand pounds")
.replace(/([$£€¥])(\d+(?:,\d{3})*(?:\.\d{2})?)/g, (_, currency, num) => {
// Remove commas before parsing
const numWithoutCommas = num.replace(/,/g, '');
const currencyMap: { [key: string]: string } = {
$: 'dollars',
'£': 'pounds',
'€': 'euros',
'¥': 'yen',
};
// Check for decimal points to handle cents
if (numWithoutCommas.includes('.')) {
const [dollars, cents] = numWithoutCommas.split('.');
return `${toWords(Number.parseInt(dollars))} ${currencyMap[currency] || 'currency'}${cents ? ` and ${toWords(Number.parseInt(cents))} cents` : ''}`;
}
// Handle whole numbers
return `${toWords(Number.parseInt(numWithoutCommas))} ${currencyMap[currency] || 'currency'}`;
})
// Convert phone numbers (e.g., "555-555-5555" → "five five five, five five five, five five five five")
.replace(/(\d{3})-(\d{3})-(\d{4})/g, (_, p1, p2, p3) => {
return `${spellOutDigits(p1)}, ${spellOutDigits(p2)}, ${spellOutDigits(p3)}`;
})
);
}
// Helper function to spell out individual digits as words (for phone numbers)
function spellOutDigits(num: string): string {
return num
.split('')
.map((digit) => toWords(Number.parseInt(digit)))
.join(' ');
}
// Example usage
console.log(normalizeText('$1,000')); // "one thousand dollars"
console.log(normalizeText('£1000')); // "one thousand pounds"
console.log(normalizeText('€1000')); // "one thousand euros"
console.log(normalizeText('¥1000')); // "one thousand yen"
console.log(normalizeText('$1,234.56')); // "one thousand two hundred thirty-four dollars and fifty-six cents"
console.log(normalizeText('555-555-5555')); // "five five five, five five five, five five five five"
```
</CodeBlocks>
# Latency optimization
> Learn how to optimize text-to-speech latency.
This guide covers the core principles for improving text-to-speech latency.
While there are many individual techniques, we'll group them into **four principles**.
<h4>
Four principles
</h4>
1. [Use Flash models](#use-flash-models)
2. [Leverage streaming](#leverage-streaming)
3. [Consider geographic proximity](#consider-geographic-proximity)
4. [Choose appropriate voices](#choose-appropriate-voices)
<Success>
Enterprise customers benefit from increased concurrency limits and priority access to our rendering queue. [Contact sales](https://elevenlabs.io/contact-sales) to learn more about our enterprise
plans.
</Success>
## Use Flash models
[Flash models](/docs/models#flash-v25) deliver \~75ms inference speeds, making them ideal for real-time applications. The trade-off is a slight reduction in audio quality compared to [Multilingual v2](/docs/models#multilingual-v2).
<Info>
75ms refers to model inference time only. Actual end-to-end latency will vary with factors such as
your location & endpoint type used.
</Info>
## Leverage streaming
There are three types of text-to-speech endpoints available in our [API Reference](/docs/api-reference):
* **Regular endpoint**: Returns a complete audio file in a single response.
* **Streaming endpoint**: Returns audio chunks progressively using [Server-sent events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events).
* **Websockets endpoint**: Enables bidirectional streaming for real-time audio generation.
### Streaming
Streaming endpoints progressively return audio as it is being generated in real-time, reducing the time-to-first-byte. This endpoint is recommended for cases where the input text is available up-front.
<Info>
Streaming is supported for the [Text to
Speech](/docs/api-reference/text-to-speech/convert-as-stream) API, [Voice
Changer](/docs/api-reference/speech-to-speech/convert-as-stream) API & [Audio
Isolation](/docs/api-reference/audio-isolation/audio-isolation-stream) API.
</Info>
### Websockets
The [text-to-speech websocket endpoint](/docs/api-reference#text-to-speech-websocket) supports bidirectional streaming making it perfect for applications with real-time text input (e.g. LLM outputs).
<Tip>
Setting `auto_mode` to true automatically handles generation triggers, removing the need to
manually manage chunk strategies.
</Tip>
If `auto_mode` is disabled, the model will wait for enough text to match the chunk schedule before starting to generate audio.
For instance, if you set a chunk schedule of 125 characters but only 50 arrive, the model stalls until additional characters come in—potentially increasing latency.
For implementation details, see the [text-to-speech websocket guide](/docs/api-reference#text-to-speech-websocket).
## Consider geographic proximity
Because our models are served in the US, your geographic location will affect the network latency you experience.
For example, using Flash models with Websockets, you can expect the following TTFB latencies:
| Region          | TTFB      |
| --------------- | --------- |
| US              | 150-200ms |
| EU              | \~230ms   |
| North East Asia | 250-350ms |
| South Asia      | 380-440ms |
<Note>
We are actively working on deploying our models in EU and Asia. These deployments will bring
speeds closer to those experienced by US customers.
</Note>
## Choose appropriate voices
We have observed that in some cases, voice selection can impact latency. Here's the order from fastest to slowest:
1. Default voices (formerly premade), Synthetic voices, and Instant Voice Clones (IVC)
2. Professional Voice Clones (PVC)
Higher audio quality output formats can increase latency. Be sure to balance your latency requirements with audio fidelity needs.
<Info>
We are actively working on optimizing PVC latency for Flash v2.5.
</Info>
# Overview
> Step by step worflow guides.
<img src="file:289408bc-cb55-4320-be0a-6717d3e9448b" alt="Product guides overview" />
This section covers everything from account creation to advanced voice cloning, speech synthesis techniques, dubbing, and expert voiceover.
## Product guides
<CardGroup cols={2}>
<Card title="Create speech from text" icon="duotone comment-dots" href="/docs/product-guides/playground/text-to-speech" iconPosition="left">
Discover how to create speech from text with text to speech
</Card>
<Card title="Voice changer" icon="duotone microphone-lines" href="/docs/product-guides/playground/voice-changer" iconPosition="left">
Discover how to transform your voice with voice changer
</Card>
<Card title="Sound effects" icon="duotone explosion" href="/docs/product-guides/playground/sound-effects" iconPosition="left">
Discover how to create cinematic sound effects from text
</Card>
<Card title="Studio" icon="duotone rectangle-vertical-history" href="/docs/product-guides/products/studio" iconPosition="left">
Manage long-form content with Studio
</Card>
<Card title="Dubbing" icon="duotone language" href="/docs/product-guides/products/dubbing" iconPosition="left">
Discover how to dub your videos in multiple languages
</Card>
<Card title="Conversational AI" icon="duotone comments" href="/docs/conversational-ai/overview" iconPosition="left">
Discover how to create conversational AI agents
</Card>
<Card title="Voice cloning" icon="duotone microphone" href="/docs/product-guides/voices/voice-cloning" iconPosition="left">
Discover how to create instant & professional voice clones
</Card>
<Card title="Voice library" icon="duotone microphone" href="/docs/product-guides/voices/voice-library" iconPosition="left">
Discover our voice library with over 5,000 community voices
</Card>
<Card title="Voice design" icon="duotone paintbrush" href="/docs/product-guides/voices/voice-design" iconPosition="left">
Discover how to craft voices from a single prompt
</Card>
<Card title="Payouts" icon="duotone money-bill-wave" href="/docs/product-guides/voices/payouts" iconPosition="left">
Discover how to get paid when your voice is used
</Card>
<Card title="Audio native" icon="duotone headphones" href="/docs/product-guides/audio-tools/audio-native" iconPosition="left">
Discover how to get paid when your voice is used
</Card>
<Card title="Voiceover studio" icon="duotone list-timeline" href="/docs/product-guides/audio-tools/voiceover-studio" iconPosition="left">
Manage long-form audio generation with voiceover studio
</Card>
<Card title="Voice isolator" icon="duotone microphone-stand" href="/docs/product-guides/audio-tools/voice-isolator" iconPosition="left">
Isolate voices from background noise
</Card>
<Card title="AI speech classifier" icon="duotone computer-classic" href="/docs/product-guides/audio-tools/ai-speech-classifier" iconPosition="left">
Classify AI-generated speech
</Card>
</CardGroup>
## Administration
<CardGroup cols={2}>
<Card title="Account" icon="duotone user-circle" href="/docs/product-guides/administration/account" iconPosition="left">
Learn how to manage your account settings
</Card>
<Card title="Billing" icon="duotone file-invoice-dollar" href="/docs/product-guides/administration/billing" iconPosition="left">
Learn how to manage your billing information
</Card>
<Card title="Workspaces" icon="duotone users" href="/docs/product-guides/administration/workspaces" iconPosition="left">
Learn how to manage your enterprise workspaces
</Card>
<Card title="SSO" icon="duotone key" href="/docs/product-guides/administration/workspaces/sso" iconPosition="left">
Learn how to enable single sign-on for your enterprise
</Card>
</CardGroup>
***
## Troubleshooting
1. Explore our troubleshooting section for common issues and solutions.
2. Get help from the Conversational AI widget in the bottom right corner.
3. Ask for help in our [Discord community](https://discord.gg/elevenlabs).
4. Contact our [support team](https://help.elevenlabs.io/hc/en-us/requests/new?ticket_form_id=13145996177937).
# Text to Speech
> A guide on how to turn text to speech with ElevenLabs
<img src="file:7a486ce1-fc2d-4f6a-a9a7-61d889864660" alt="Text to Speech product feature" />
## Overview
ElevenLabs' Text to Speech technology is integral to our offerings, powering high-quality AI-generated speech across various applications worldwide. It's likely you've already encountered our voices in action, delivering lifelike audio experiences.
## Guide
<Frame background="subtle">
![Text to Speech demo](file:b6adf046-4e87-42c6-b71a-02aeab7640b7)
</Frame>
<Steps>
<Step title="Text input">
Type or paste your text into the input box on the Text to Speech page.
</Step>
<Step title="Voice selection">
Select the voice you wish to use from your Voices at the bottom left of the screen.
</Step>
<Step title="Adjust settings (optional)">
Modify the voice settings for the desired output.
</Step>
<Step title="Generate">
Click the 'Generate' button to create your audio file.
</Step>
</Steps>
## Settings
Get familiar with the voices, models & settings for creating high-quality speech.
<AccordionGroup>
<Accordion title="Voices">
### Voices
<Frame background="subtle">
![Text to Speech voice
selection](file:06f55225-0e21-4f51-ae39-74d6f7582960)
</Frame>
We offer many types of voices, including the curated Default Voices library; completely synthetic voices created using our Voice Design tool; you can create your own collection of cloned voices using our two technologies: Instant Voice Cloning and Professional Voice Cloning. Browse through our voice library to find the perfect voice for your production.
Not all voices are equal, and a lot depends on the source audio used to create that voice. Some voices will perform better than others, while some will be more stable than others. Additionally, certain voices will be more easily cloned by the AI than others, and some voices may work better with one model and one language compared to another. All of these factors are important to consider when selecting your voice.
[Learn more about voices](/docs/capabilities/voices)
</Accordion>
<Accordion title="Models">
### Models
<Frame background="subtle">
![Text to Speech model
selection](file:f83ff542-6c04-4704-bea1-b82c043f24df)
</Frame>
ElevenLabs offers two families of models: standard (high-quality) models and Flash models, which are optimized for low latency. Each family includes both English-only and multilingual models, tailored for specific use cases with strengths in either speed, accuracy, or language diversity.
<CardGroup cols={2} rows={2}>
<Card title="Eleven Multilingual v2" href="/docs/models#multilingual-v2">
Our most lifelike, emotionally rich speech synthesis model
<div>
<div>
Most natural-sounding output
</div>
<div>
29 languages supported
</div>
<div>
10,000 character limit
</div>
<div>
Rich emotional expression
</div>
</div>
</Card>
<Card title="Eleven Flash v2.5" href="/docs/models#flash-v25">
Our fast, affordable speech synthesis model
<div>
<div>
Ultra-low latency (~75ms†)
</div>
<div>
32 languages supported
</div>
<div>
40,000 character limit
</div>
<div>
Faster model, 50% lower price per character
</div>
</div>
</Card>
</CardGroup>
[Learn more about our models](/docs/models)
</Accordion>
<Accordion title="Voice settings">
### Voice settings
<Frame background="subtle">
![Text to Speech voice
settings](file:9d5f991b-36c9-4245-80b5-3b21257fcc3a)
</Frame>
Our users have found different workflows that work for them. The most common setting is stability around 50 and similarity near 75, with minimal changes thereafter. Of course, this all depends on the original voice and the style of performance you're aiming for.
It's important to note that the AI is non-deterministic; setting the sliders to specific values won't guarantee the same results every time. Instead, the sliders function more as a range, determining how wide the randomization can be between each generation.
#### Stability
The stability slider determines how stable the voice is and the randomness between each generation. Lowering this slider introduces a broader emotional range for the voice. As mentioned before, this is also influenced heavily by the original voice. Setting the slider too low may result in odd performances that are overly random and cause the character to speak too quickly. On the other hand, setting it too high can lead to a monotonous voice with limited emotion.
For a more lively and dramatic performance, it is recommended to set the stability slider lower and generate a few times until you find a performance you like.
On the other hand, if you want a more serious performance, even bordering on monotone at very high values, it is recommended to set the stability slider higher. Since it is more consistent and stable, you usually don't need to generate as many samples to achieve the desired result. Experiment to find what works best for you!
#### Similarity
The similarity slider dictates how closely the AI should adhere to the original voice when attempting to replicate it. If the original audio is of poor quality and the similarity slider is set too high, the AI may reproduce artifacts or background noise when trying to mimic the voice if those were present in the original recording.
#### Style exaggeration
With the introduction of the newer models, we also added a style exaggeration setting. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0. It's important to note that using this setting has shown to make the model slightly less stable, as it strives to emphasize and imitate the style of the original voice.
In general, we recommend keeping this setting at 0 at all times.
#### Speaker Boost
This setting boosts the similarity to the original speaker. However, using this setting requires a slightly higher computational load, which in turn increases latency. The differences introduced by this setting are generally rather subtle.
</Accordion>
</AccordionGroup>
## FAQ
<AccordionGroup>
<Accordion title="Good input equals good output">
The first factor, and one of the most important, is that good, high-quality, and consistent input will result in good, high-quality, and consistent output.
If you provide the AI with audio that is less than ideal—for example, audio with a lot of noise, reverb on clear speech, multiple speakers, or inconsistency in volume or performance and delivery—the AI will become more unstable, and the output will be more unpredictable.
If you plan on cloning your own voice, we strongly recommend that you go through our guidelines in the documentation for creating proper voice clones, as this will provide you with the best possible foundation to start from. Even if you intend to use only Instant Voice Clones, it is advisable to read the Professional Voice Cloning section as well. This section contains valuable information about creating voice clones, even though the requirements for these two technologies are slightly different.
</Accordion>
<Accordion title="Use the right voice">
The second factor to consider is that the voice you select will have a tremendous effect on the output. Not only, as mentioned in the first factor, is the quality and consistency of the samples used to create that specific clone extremely important, but also the language and tonality of the voice.
If you want a voice that sounds happy and cheerful, you should use a voice that has been cloned using happy and cheerful samples. Conversely, if you desire a voice that sounds introspective and brooding, you should select a voice with those characteristics.
However, it is also crucial to use a voice that has been trained in the correct language. For example, all of the professional voice clones we offer as default voices are English voices and have been trained on English samples. Therefore, if you have them speak other languages, their performance in those languages can be unpredictable. It is essential to use a voice that has been cloned from samples where the voice was speaking the language you want the AI to then speak.
</Accordion>
<Accordion title="Use proper formatting">
This may seem slightly trivial, but it can make a big difference. The AI tries to understand how to read something based on the context of the text itself, which means not only the words used but also how they are put together, how punctuation is applied, the grammar, and the general formatting of the text.
This can have a small but impactful influence on the AI's delivery. If you were to misspell a word, the AI won't correct it and will try to read it as written.
</Accordion>
<Accordion title="Nondeterministic">
The settings of the AI are nondeterministic, meaning that even with the same initial conditions (voice, settings, model), it will give you slightly different output, similar to how a voice actor will deliver a slightly different performance each time.
This variability can be due to various factors, such as the options mentioned earlier: voice, settings, model. Generally, the breadth of that variability can be controlled by the stability slider. A lower stability setting means a wider range of variability between generations, but it also introduces inter-generational variability, where the AI can be a bit more performative.
A wider variability can often be desirable, as setting the stability too high can make certain voices sound monotone as it does give the AI the same leeway to generate more variable content. However, setting the stability too low can also introduce other issues where the generations become unstable, especially with certain voices that might have used less-than-ideal audio for the cloning process.
The default setting of 50 is generally a great starting point for most applications.
</Accordion>
</AccordionGroup>
# Voice changer
> A guide on how to transform audio between voices while preserving emotion and delivery.
<img src="file:268ebfa8-2d15-42cf-9f22-8822dc68bae7" alt="Voice changer product feature" />
## Overview
Voice changer (previously Speech-to-Speech) allows you to convert one voice (source voice) into another (cloned voice) while preserving the tone and delivery of the original voice.
Voice changer can be used to complement Text-to-Speech (TTS) by fixing pronunciation errors or infusing that special performance you've been wanting to exude. Voice changer is especially useful for emulating those subtle, idiosyncratic characteristics of the voice that give a more emotive and human feel. Some key features include:
* Greater accuracy with whispering
* The ability to create audible sighs, laughs, or cries
* Greatly improved detection of tone and emotion
* Accurately follows the input speaking cadence
* Language/accent retention
<AccordionGroup>
<Accordion title="Watch a video of voice changer in action">
<iframe width="100%" height="400" src="https://www.youtube.com/embed/GBdOQClluIA" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
</Accordion>
</AccordionGroup>
## Guide
<Frame background="subtle">
![Voice changer demo](file:ab8058da-29e2-44ff-b3b6-0bf7e44e0b8e)
</Frame>
Audio can be uploaded either directly with an audio file, or spoken live through a microphone. The audio file must be less than **50mb in size**, and either the audio file or your live recording cannot exceed **5 minutes in length**.
If you have material longer than 5 minutes, we recommend breaking it up into smaller sections and generating them separately. Additionally, if your file size is too large, you may need to compress/convert it to an mp3.
### Existing audio file
To upload an existing audio file, either click the audio box, or drag and drop your audio file directly onto it.
### Record live
Press the **Record Audio** button in the audio box, and then once you are ready to begin recording, press the **Microphone** button to start. After you're finished recording, press the **Stop** button.
You will then see the audio file of this recording, which you can then playback to listen to - this is helpful to determine if you are happy with your performance/recording. The character cost will be displayed on the bottom-left corner, and you will not be charged this quota for recording anything - only when you press "Generate".
**The cost for a voice changer generation is solely duration-based at 1000 characters per minute.**
## Settings
<Frame background="subtle">
![Voice changer settings](file:73d882d0-1ee7-4490-a68a-19d9ee65f535)
</Frame>
Learn more about the different voice settings [here](/docs/product-guides/playground/text-to-speech#settings).
<Info>
Voice changer adds an additional setting to automaticaly remove background noise from your
recording.
</Info>
## Support languages
`eleven_english_sts_v2`
Our v2 models support 29 languages:
*English (USA, UK, Australia, Canada), Japanese, Chinese, German, Hindi, French (France, Canada), Korean, Portuguese (Brazil, Portugal), Italian, Spanish (Spain, Mexico), Indonesian, Dutch, Turkish, Filipino, Polish, Swedish, Bulgarian, Romanian, Arabic (Saudi Arabia, UAE), Czech, Greek, Finnish, Croatian, Malay, Slovak, Danish, Tamil, Ukrainian & Russian.*
The `eleven_english_sts_v2` model only supports English.
[Learn more about models](/docs/models)
## Best practices
Voice changer excels at **preserving accents** and **natural speech cadences** across various output voices. For instance, if you upload an audio sample with a Portuguese accent, the output will retain that language and accent. The input sample is crucial, as it determines the output characteristics. If you select a British voice like "George" but record with an American accent, the result will be George's voice with an American accent.
* **Expression**: Be expressive in your recordings. Whether shouting, crying, or laughing, the voice changer will accurately replicate your performance. This tool is designed to enhance AI realism, allowing for creative expression.
* **Microphone gain**: Ensure the input gain is appropriate. A quiet recording may hinder AI recognition, while a loud one could cause audio clipping.
* **Background Noise**: Turn on the **Remove Background Noise** option to automatically remove background noise from your recording.
# Sound effects
> A guide on how to create high-quality sound effects from text with ElevenLabs.
<img src="file:39083aa7-4ffb-4d13-8916-e0eb2d1ec7ba" alt="Sound effects product feature" />
## Overview
**Sound effects** enhance the realism and immersion of your audio projects. ElevenLabs offers a variety of sound effects that can be easily integrated into your voiceovers and projects.
## Guide
<Frame background="subtle">
![Sound effects demo](file:c6a91fc3-5674-4025-83f6-99ebfd85a724)
</Frame>
<Steps>
<Step title="Navigate to Sound Effects">
Head over to the Sound Effects tab in the dashboard.
</Step>
<Step title="Describe the sound effect">
In the text box, type a description of the sound effect you want (e.g., “person walking on
grass”).
</Step>
<Step title="Adjust settings">
<Frame background="subtle">
![Sound effects settings](file:92084824-f7e4-45d1-a5e5-e25f881c0cd1)
</Frame>
<>
1. Set the duration for the generated sound (or let it automatically pick the best length).
2. Use the prompt influence slider to control how closely the output should matchthe prompt.
</>
</Step>
<Step title="Generate Sound">
Click the "Generate" button to start generating.
</Step>
<Step title="Review and regenerate">
You should have four different sounds generated. If you like none of them, adjust the prompt or
settings as needed and regenerate.
</Step>
</Steps>
<Success>
**Exercise**: Create a Sound Effect using the following prompt: old-school funky brass stabs from
an old vinyl sample, stem, 88bpm in F# minor.
</Success>
## Explore the library
<Frame background="subtle">
![Sound effects explore](file:7584185d-85d7-4cc1-a2b6-349779c133c0)
</Frame>
Check out some of our community-made sound effects in the **Explore** tab.
For more information on prompting & how sound effects work visit our [overview page](/docs/capabilities/sound-effects).
# Speech to Text
> A guide on how to transcribe audio with ElevenLabs
<img src="file:b04a3af3-3510-492d-bf69-37b4c7820ae4" alt="Text to Speech product feature" />
## Overview
With speech to text, you can transcribe spoken audio into text with state of the art accuracy. With automatic language detection, you can transcribe audio in a multitude of languages.
## Creating a transcript
<Steps>
<Step title="Upload audio">
In the ElevenLabs dashboard, navigate to the Speech to Text page and click the "Transcribe files" button. From the modal, you can upload an audio or video file to transcribe.
<Frame background="subtle">
![Speech to Text upload](file:d6720483-e560-413a-8aa1-b9fd91ab7cd6)
</Frame>
</Step>
<Step title="Select options">
Select the primary language of the audio and the maximum number of speakers. If you don't know either, you can leave the defaults which will attempt to detect the language and number of speakers automatically.
Finally choose whether you wish to tag audio events like laughter or applause, then click the "Transcribe" button.
</Step>
<Step title="View results">
Click on the name of the audio file you uploaded in the center pane to view the results. You can click on a word to start a playback of the audio at that point.
Click the "Export" button in the top right to download the results in a variety of formats.
</Step>
</Steps>
## Transcript Editor
<Steps>
<Step title="Open transcript">
In the ElevenLabs dashboard, navigate to the Speech to Text page and click any transcript to open the Transcript Editor.
<Frame background="subtle">
![Open transcript](file:37863a3e-10b0-45ec-809f-dc8bca42c816)
</Frame>
</Step>
<Step title="Edit basic details">
You can rename your transcript by clicking the name and typing a new one.
<Frame background="subtle">
![Rename transcript](file:1d82261f-30d1-45db-8a17-fc852c3dc441)
</Frame>
</Step>
<Step title="Follow along with the audio">
Click the play button in the bottom of the screen to start playing the audio. Our editor will automatically highlight the text to show you where you are.
<Frame background="subtle">
![Follow along](file:0215d7af-1122-496c-b6dc-743857e8f5d0)
</Frame>
</Step>
<Step title="Select edit mode">
Select Edit mode using the tabs in the top left. This reveals the editing features.
<Frame background="subtle">
![Edit mode](file:32c09a30-c4f4-4c67-a0fb-9372e7682217)
</Frame>
</Step>
<Step title="Edit Transcript">
Click the pencil icon next to a transcribed segment to edit the text. When you click enter, our system will automatically update the timecodes for the segment under the hood.
<Frame background="subtle">
![Edit transcript](file:f6ece3dc-f899-4c93-ba9a-8432531d032d)
</Frame>
</Step>
<Step title="Manage Speakers">
Our transcript editor comes with powerful features for managing speaker allocation.
Click the 'Manage Speakers' button, and you'll see a list of speakers in the left pane. You can rename speakers, add new ones, and transfer lines attributed to one speaker to another.
<Frame background="subtle">
![Manage speakers](file:32606f8c-18f2-4856-923e-ea736ca6b9b7)
</Frame>
</Step>
<Step title="Split and merge segments">
Select 'adjust segments' in the toolbar to switch to the segment editing mode.
This mode allows you to split and merge segments. This is useful if you want to edit the transcription only for a certain part of a segment, or assign a certain part of a segment to a different speaker.
<Frame background="subtle">
![Split and merge](file:5f80e0b6-8a62-4914-a162-131913a750ca)
</Frame>
</Step>
</Steps>
## FAQ
<AccordionGroup>
<Accordion title="What languages are supported?">
### Supported languages
The Scribe v1 model supports 99 languages, including:
*Afrikaans (afr), Amharic (amh), Arabic (ara), Armenian (hye), Assamese (asm), Asturian (ast), Azerbaijani (aze), Belarusian (bel), Bengali (ben), Bosnian (bos), Bulgarian (bul), Burmese (mya), Cantonese (yue), Catalan (cat), Cebuano (ceb), Chichewa (nya), Croatian (hrv), Czech (ces), Danish (dan), Dutch (nld), English (eng), Estonian (est), Filipino (fil), Finnish (fin), French (fra), Fulah (ful), Galician (glg), Ganda (lug), Georgian (kat), German (deu), Greek (ell), Gujarati (guj), Hausa (hau), Hebrew (heb), Hindi (hin), Hungarian (hun), Icelandic (isl), Igbo (ibo), Indonesian (ind), Irish (gle), Italian (ita), Japanese (jpn), Javanese (jav), Kabuverdianu (kea), Kannada (kan), Kazakh (kaz), Khmer (khm), Korean (kor), Kurdish (kur), Kyrgyz (kir), Lao (lao), Latvian (lav), Lingala (lin), Lithuanian (lit), Luo (luo), Luxembourgish (ltz), Macedonian (mkd), Malay (msa), Malayalam (mal), Maltese (mlt), Mandarin Chinese (cmn), Māori (mri), Marathi (mar), Mongolian (mon), Nepali (nep), Northern Sotho (nso), Norwegian (nor), Occitan (oci), Odia (ori), Pashto (pus), Persian (fas), Polish (pol), Portuguese (por), Punjabi (pan), Romanian (ron), Russian (rus), Serbian (srp), Shona (sna), Sindhi (snd), Slovak (slk), Slovenian (slv), Somali (som), Spanish (spa), Swahili (swa), Swedish (swe), Tamil (tam), Tajik (tgk), Telugu (tel), Thai (tha), Turkish (tur), Ukrainian (ukr), Umbundu (umb), Urdu (urd), Uzbek (uzb), Vietnamese (vie), Welsh (cym), Wolof (wol), Xhosa (xho) and Zulu (zul).*
</Accordion>
<Accordion title="Can I upload video files?">
Yes, the tool supports uploading both audio and video files. The maximum file size for either is 1GB.
</Accordion>
<Accordion title="Can I rename speakers?">
### Renaming speakers
Yes, you can rename speakers by clicking the "edit" button next to the "Speakers" label.
</Accordion>
</AccordionGroup>
# Studio
> Studio overview
<img src="file:387c421e-728e-47c3-bd09-36fb9c686a61" alt="Studio product feature" />
## Overview
Studio is an end-to-end workflow for creating long-form content. With this tool you can upload an entire book, document or webpage and generate a voiceover narration for it. The result can then be downloaded as a single MP3 file or as individual MP3 files for each chapter.
## Guide
<Frame background="subtle">
![Studio create](file:8b722820-3faf-4903-9664-321e3e098d67)
</Frame>
<Steps>
<Step title="Create a new project">
Select one of the start options at the top of the studio page.
</Step>
<Step title="Select settings">
Follow the instructions in the popup and click "Create".
</Step>
<Step title="Edit text">
Make changes in the text editor and adjust voice settings as needed.
</Step>
<Step title="Download audio files">
Click the "Convert" button to compile and download the entire project or specific chapters as a
single audio file. Use the "Download" button for various download options, including
project-wide or chapter-specific files.
</Step>
</Steps>
<Note>
You can use our [Audio Native](/docs/product/audio-native/overview) feature to easily and
effortlessly embed any narration project onto your website.
</Note>
## Settings
<AccordionGroup>
<Accordion title="Voices">
### Voices
We offer many types of voices, including the curated Default Voices library; completely synthetic voices created using our Voice Design tool; you can create your own collection of cloned voices using our two technologies: Instant Voice Cloning and Professional Voice Cloning. Browse through our voice library to find the perfect voice for your production.
Not all voices are equal, and a lot depends on the source audio used to create that voice. Some voices will perform better than others, while some will be more stable than others. Additionally, certain voices will be more easily cloned by the AI than others, and some voices may work better with one model and one language compared to another. All of these factors are important to consider when selecting your voice.
[Learn more about voices](/docs/capabilities/voices)
</Accordion>
<Accordion title="Voice settings">
### Voice settings
<Frame background="subtle">
![Studio voice settings](file:f864808e-fced-4d32-8e13-c185d9115310)
</Frame>
Our users have found different workflows that work for them. The most common setting is stability around 50 and similarity near 75, with minimal changes thereafter. Of course, this all depends on the original voice and the style of performance you're aiming for.
It's important to note that the AI is non-deterministic; setting the sliders to specific values won't guarantee the same results every time. Instead, the sliders function more as a range, determining how wide the randomization can be between each generation.
#### Stability
The stability slider determines how stable the voice is and the randomness between each generation. Lowering this slider introduces a broader emotional range for the voice. As mentioned before, this is also influenced heavily by the original voice. Setting the slider too low may result in odd performances that are overly random and cause the character to speak too quickly. On the other hand, setting it too high can lead to a monotonous voice with limited emotion.
For a more lively and dramatic performance, it is recommended to set the stability slider lower and generate a few times until you find a performance you like.
On the other hand, if you want a more serious performance, even bordering on monotone at very high values, it is recommended to set the stability slider higher. Since it is more consistent and stable, you usually don't need to generate as many samples to achieve the desired result. Experiment to find what works best for you!
#### Similarity
The similarity slider dictates how closely the AI should adhere to the original voice when attempting to replicate it. If the original audio is of poor quality and the similarity slider is set too high, the AI may reproduce artifacts or background noise when trying to mimic the voice if those were present in the original recording.
#### Style exaggeration
With the introduction of the newer models, we also added a style exaggeration setting. This setting attempts to amplify the style of the original speaker. It does consume additional computational resources and might increase latency if set to anything other than 0. It's important to note that using this setting has shown to make the model slightly less stable, as it strives to emphasize and imitate the style of the original voice.
In general, we recommend keeping this setting at 0 at all times.
#### Speaker boost
This setting boosts the similarity to the original speaker. However, using this setting requires a slightly higher computational load, which in turn increases latency. The differences introduced by this setting are generally rather subtle.
</Accordion>
<Accordion title="Pronunciation dictionaries">
### Pronunciation dictionaries
Sometimes you may want to specify the pronunciation of certain words, such as character or brand names, or specify how acronyms should be read. Pronunciation dictionaries allow this functionality by enabling you to upload a lexicon or dictionary file that includes rules about how specified words should be pronounced, either using a phonetic alphabet (phoneme tags) or word substitutions (alias tags).
Whenever one of these words is encountered in a project, the AI will pronounce the word using the specified replacement. When checking for a replacement word in a pronunciation dictionary, the dictionary is checked from start to end and only the first replacement is used.
You can add a pronunciation dictionary to your project from the General tab in Project settings.
For more information on pronunciation dictionaries, please see our [prompting best practices guide](/docs/best-practices/prompting#pronunciation-dictionaries).
</Accordion>
<Accordion title="Exporting">
### Exporting
Within the "Export" tab under General settings you can add additional metadata such as Title, Author, ISBN and a Description to your project. This information will automatically be added to the downloaded audio files.
</Accordion>
</AccordionGroup>
## FAQ
<AccordionGroup>
<Accordion title="Free regenerations">
<Frame background="subtle">
![Studio free regenerations](file:cb085463-2fa8-466d-beb4-44b6c9ca5cad)
</Frame>
In Studio, provided you don't change the text, you can regenerate a selected paragraph or section of text twice for free.
If free regenerations are available for the selected paragraph or text, you will see "Regenerate". If you hover over the "Regenerate" button, the number of free regenerations remaining will be displayed.
Once your free regenerations have been used, the button will display "Generate", and you will be charged for subsequent generations.
</Accordion>
<Accordion title="Auto-regeneration for bulk conversions">
When converting a full chapter or project, auto-regeneration automatically checks the output for volume issues, voice similarity, and mispronunciations. If ElevenLabs detects any issues, the tool will automatically regenerate the audio up to twice, at no extra cost.
This feature may increase the processing time but helps ensure higher quality output for your bulk conversions.
</Accordion>
</AccordionGroup>
# Dubbing
> Translate audio and video files with ElevenLabs dubbing and dubbing studio.
<img src="file:879220de-4f42-4a87-8e0f-12d87171ce57" alt="Dubbing studio product feature" />
**Dubbing** allows you to translate content across 29 languages in seconds with voice translation, speaker detection, and audio dubbing.
Automated Dubbing or Video Translation is a process for translating and replacing the original audio of a video with a new language, while preserving the unique characteristics of the original speakers' voices.
We offer two different types of Dubbing: Automatic and Studio.
**Automatic Dubbing** is the default, so let’s see the step by step for this type of dubbing.
<Frame background="subtle">
![Dubbing new project](file:c07de852-6f76-4108-9e30-c8d9aeaf33a0)
</Frame>
### Step by step for Automatic Dubbing
1. Go to the Dubbing Studio in your Navigation Menu.
2. Enter the dub name and select the original and target languages.
3. Upload a video/audio file or import one via URL (YouTube, TikTok, etc.).
4. Opt for watermarking if needed.
5. Leave the Create a Dubbing Studio project box unchecked.
6. Click on the **Advanced Settings** option:
* Choose the number of speakers and video resolution.
* Select the specific range for dubbing if needed.
7. Click on **Create** and sit back while ElevenLabs does its magic.
**Exercise**: Dub the video found [here](https://www.youtube.com/watch?v=WnNFZt0qjD0) from English to Spanish (or a language of your choosing). Select 6 speakers and keep the watermark.
<CardGroup>
<Card title="API reference" href="/docs/api-reference/text-to-voice">
See the API reference for dubbing.
</Card>
<Card title="Example app" href="https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/dubbing">
A Python flask example app for dubbing.
</Card>
</CardGroup>
### Dubbing Studio Project
* This is the advanced Dubbing version, which you can access by checking the **Create a Dubbing Studio project** box. Read more about it in the [Dubbing Studio guide](/docs/product-guides/products/dubbing/dubbing-studio).
# Dubbing studio
> Fine grained control over your dubs.
<iframe width="100%" height="400" src="https://www.youtube.com/embed/DwMcfofG0js" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
### Step by step for for using Dubbing Studio:
1. Follow the same steps as you had with Automatic Dubbing, this time checking the **Create a Dubbing Studio project** box.
2. Click on **Create**.
3. The system will auto-generate a transcription of the original audio (or for more advanced users, you can manually input the transcription using the Manual upload option during the upload stage).
4. Review the transcription in the speaker cards and edit if necessary.
5. If needed, re-assign clips to the appropriate speaker(s) by dragging and dropping the audio clips from the track to the speaker timeline.
6. Click on the language where you dubbed the video in at the bottom of the screen.
7. You will see a new set of speaker cards appearing next to your transcription, as well as a new set of audio files that are highlighted in sync with the audio timeline.
* (Optional) If you have made any edits to the transcription, you can re-translate the text by clicking the arrow between the two speaker cards.
* (Optional) You can assign different voices and/or edit the voice settings for an audio track by clicking the cog icon available next to the speaker's name within the audio track.
8. Use the timeline to view and adjust the placement of voice clips.
9. **You can edit clips**:
* By dragging the clip edges to speed up or slow down speech within in select mode.
* Merge clips by selecting the merge button between clips in the original audio tracks.
* Split clips by selecting the split button in the clip panel with the split icon to save time.
10. You can export the final output in various formats and synchronize any video or audio you wish by selecting "Export".
11. Preview the dubbed video, export when ready.
12. This allows video clips to be generated. Choose the video format and size from available options.
13. Select the dubbed file to be generated.
## Additional Features
* **Manual Import**: Allows for manual uploading of video, background audio, and speaker audio files, along with CSV files specifying details for each clip.
* **Timing Adjustments**: Choose between fixed durations to maintain video timing or dynamic durations for more natural speech flow.
* **Voiceover Tracks:** Voiceover tracks create new Speakers. You can click and add clips on the timeline wherever you like. After creating a clip, start writing your desired text on the speaker cards above. You'll first need to translate that text, then you can press "Generate". You can also use our voice changer tool by clicking on the microphone icon on the right side of the screen to use your own voice and then change it into the selected voice.
* **SFX Tracks:** Add a SFX track, then click anywhere on that track to create a SFX clip. Similar to our independent SFX feature, simply start writing your prompt in the Speaker card above and click “Generate” to create your new SFX audio. You can lengthen or shorten SFX clips and move them freely around your timeline to fit your project - make sure to press the “stale” button if you do so.
* **Upload Audio:** This option allows you to upload a non voiced track such as sfx, music or background track. Please keep in mind that if voices are present in this track, they won't be detected so it will not be possible to translate or correct them.
**Exercise**: Dub the video found [here](https://www.youtube.com/watch?v=WnNFZt0qjD0) using Dubbing Studio from English to Spanish (or a language of your choosing). Select 6 speakers and keep the watermark.
<Frame background="subtle">
![Dubbing project](file:de345301-8af1-4fa7-ae25-80a62ef16445)
</Frame>
## "Dynamic" vs. "Fixed" Generation
In Dubbing Studio, all regenerations made to the text are "Fixed" generations by default. This means that no matter how much text is in a Speaker card, that respective clip will not change its length. This is helpful to keep the timing of the video with the speech. However, this can be problematic if there are too many or too few words within the speaker card, as this can result in sped up or slowed down speech.
This is where "Dynamic" generation can help. You can access this by right clicking on a clip and selecting "Generate Audio (Dynamic Duration). You'll notice now that the length of the clip will more appropriately match the text spoken for that section. For example, the phrase **"I'm doing well!"** should only occupy a small clip - if the clip was very long, the speech would be slurred and drawn out. This is where Dynamic generation can be helpful.
Just note, though, that this could affect the syncing and timing of your video. Additionally, if you choose "Dynamic Duration" for a clip that has many words, the clip will need to lengthen - if there is a clip directly in front of it, it will not have enough room to generate properly, so make sure you leave some space between your clips!
# Voice library
> A guide on how to use voices from the Voice Library.
<img src="file:b35282ed-bce3-488a-9e5b-d5947c04afe9" alt="Voice library" />
## Overview
The [Voice Library](https://elevenlabs.io/voice-library) (VL) is a marketplace where our community can share voices and earn rewards when they're used. At the moment, only Professional Voice Clones (PVCs) can be shared in the library. Instant Voice Clones (IVCs) cannot be shared for safety reasons.
## Using voices from the Voice Library
You can play a sample for any voice in the Voice Library by clicking it.
To use a voice from the Voice Library, you first need to add it to My Voices. To do this, click "Add". This will save it to My Voices using the default name for the voice. You can use it directly from the Voice Library by clicking "Use", which will open Speech Synthesis with the voice selected.
Once the voice has been added to My Voices, it will appear in the voice selection menu across all features.
## Details view
You can find out more information about a voice by clicking "View". This opens up a pane on the right which contains more information. Here you can see all the tags associated with the voice, including:
* the language it was trained on
* the age and gender of the voice
* the category, for example, "Conversational"
* how long the notice period is, if the voice has one
* if the voice has been labelled as High Quality
* what type of voice it is, for example, Professional Voice Clone
You can also see how many users have saved the voice to My Voices, and how many characters of audio have been generated with the voice.
Finally, you can also see suggestions of similar voices, and can play samples and add these to My Voices if you want.
### Category
Some labels tell you about the type of voice:
<Info>
Voice Design voices are no longer shareable in the Voice Library; however, the legacy shared
voices will remain accessible.
</Info>
<Card
title="Voice Design"
icon={
<svg
xmlns="http://www.w3.org/2000/svg"
viewBox="0 0 24 24"
fill="gray"
class="h-6 w-6"
display="inline-block"
>
<path
fill-rule="evenodd"
d="M10.5 3.798v5.02a3 3 0 0 1-.879 2.121l-2.377 2.377a9.845 9.845 0 0 1 5.091 1.013 8.315 8.315 0 0 0 5.713.636l.285-.071-3.954-3.955a3 3 0 0 1-.879-2.121v-5.02a23.614 23.614 0 0 0-3 0Zm4.5.138a.75.75 0 0 0 .093-1.495A24.837 24.837 0 0 0 12 2.25a25.048 25.048 0 0 0-3.093.191A.75.75 0 0 0 9 3.936v4.882a1.5 1.5 0 0 1-.44 1.06l-6.293 6.294c-1.62 1.621-.903 4.475 1.471 4.88 2.686.46 5.447.698 8.262.698 2.816 0 5.576-.239 8.262-.697 2.373-.406 3.092-3.26 1.47-4.881L15.44 9.879A1.5 1.5 0 0 1 15 8.818V3.936Z"
clip-rule="evenodd"
/>
</svg>
}
>
Generated voices made using **[Voice Design](/docs/product/voices/voice-lab/voice-design)**
</Card>
<Card
title="Professional Voice Clone"
icon={
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="#fbbf24" class="h-6 w-6">
<path
fill-rule="evenodd"
d="M8.603 3.799A4.49 4.49 0 0 1 12 2.25c1.357 0 2.573.6 3.397 1.549a4.49 4.49 0 0 1 3.498 1.307 4.491 4.491 0 0 1 1.307 3.497A4.49 4.49 0 0 1 21.75 12a4.49 4.49 0 0 1-1.549 3.397 4.491 4.491 0 0 1-1.307 3.497 4.491 4.491 0 0 1-3.497 1.307A4.49 4.49 0 0 1 12 21.75a4.49 4.49 0 0 1-3.397-1.549 4.49 4.49 0 0 1-3.498-1.306 4.491 4.491 0 0 1-1.307-3.498A4.49 4.49 0 0 1 2.25 12c0-1.357.6-2.573 1.549-3.397a4.49 4.49 0 0 1 1.307-3.497 4.49 4.49 0 0 1 3.497-1.307Zm7.007 6.387a.75.75 0 1 0-1.22-.872l-3.236 4.53L9.53 12.22a.75.75 0 0 0-1.06 1.06l2.25 2.25a.75.75 0 0 0 1.14-.094l3.75-5.25Z"
clip-rule="evenodd"
/>
</svg>
}
>
Voices made using **[Professional Voice
Cloning](/docs/product/voices/voice-lab/professional-voice-cloning)**
</Card>
<Card title="HQ">
The HQ label stands for High Quality, and indicates that this Professional Voice Clone has been
trained on audio which follows our **[Professional Recording
Guidelines](/docs/product/voices/voice-lab/professional-voice-cloning)** and has passed a quality
control check on input texts of various lengths.
</Card>
### Sharing Options
Other labels tell you about options the voice owner set when sharing the voice. Please see the **[Sharing](/docs/product/voices/voice-library/sharing)** page for more details.
<Card
title="Notice Period"
icon={
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" class="h-3.5 w-3.5">
<path
stroke="currentColor"
stroke-linecap="round"
stroke-linejoin="round"
d="M12 6v6h4.5m4.5 0a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z"
stroke-width="1.5"
></path>
</svg>
}
>
<p>
A label with a clock icon indicates that the voice has a Notice Period in place. The Notice
Period lets you now how long you'll continue to have access to the voice if the voice owner
decides to remove it from the Voice Library.
</p>
</Card>
<Card title="Credit Multiplier">
Some voices have a credit multiplier in place. This is shown by a label displaying, for example,
x2 multiplier or x3 multiplier. This means that the voice owner has set a custom rate for use of
their voice. Please pay close attention, as credit multipliers mean your account will be deducted
\>1x the number of credits when you generate using a voice that has a credit multiplier.
</Card>
<Card
title="Live Moderation"
icon={
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" class="h-3.5 w-3.5">
<path
d="M11.302 21.6149C11.5234 21.744 11.6341 21.8086 11.7903 21.8421C11.9116 21.8681 12.0884 21.8681 12.2097 21.8421C12.3659 21.8086 12.4766 21.744 12.698 21.6149C14.646 20.4784 20 16.9084 20 12V7.21759C20 6.41808 20 6.01833 19.8692 5.6747C19.7537 5.37113 19.566 5.10027 19.3223 4.88552C19.0465 4.64243 18.6722 4.50207 17.9236 4.22134L12.5618 2.21067C12.3539 2.13271 12.25 2.09373 12.143 2.07827C12.0482 2.06457 11.9518 2.06457 11.857 2.07827C11.75 2.09373 11.6461 2.13271 11.4382 2.21067L6.0764 4.22134C5.3278 4.50207 4.9535 4.64243 4.67766 4.88552C4.43398 5.10027 4.24627 5.37113 4.13076 5.6747C4 6.01833 4 6.41808 4 7.21759V12C4 16.9084 9.35396 20.4784 11.302 21.6149Z"
stroke="currentColor"
stroke-width="1.5"
stroke-linecap="round"
stroke-linejoin="round"
></path>
</svg>
}
>
Some voices have "Live Moderation" enabled. This is indicated with a label with a shield icon.
When you generate using a voice with Live Moderation enabled, we use tools to check whether the
text being generated belongs to a number of prohibited categories. This may introduce extra
latency when using the voice, and voices with Live Moderation enabled cannot be used in Projects.
</Card>
## Filters, Sorting, and Search
To help you find the perfect voice for you, the Voice Library is searchable and filterable.
### Search box
You can use the search box to search by name, keyword and voice ID. You can also search by dragging and dropping an audio file, or uploading a file by clicking the upload icon. This will return the voice used, if it can be found, along with similar voices.
### Sort by
You have a number of options for sorting voices in the Voice Library:
* Trending: voices are ranked by our trending algorithm
* Latest: newest voices are shown first
* Most users
* Most characters generated
### Language filter
The language filter allows you to return only voices that have been trained on audio in a specific language. While all voices are compatible with our multilingual models and can therefore be used with all 32 languages we support, voices labelled with a specific language should perform well for content in that language
### Accent filter
If you select a specific language, the Accent filter will also become available. This allows you to look for voices with specific accents.
### More filters
Click the "More filters" button to access additional filters.
#### Category
* Voice Design
* Professional
* High-Quality
#### Gender
* Male
* Female
* Neutral
#### Age
* Young
* Middle Aged
* Old
#### Use case
You can click the use case of your choice to show only voices that have been labelled with this use case.
#### Voice Notice Periods
When voice creators remove voices from the library, users who have added these voices to their "My Voices" collection receive advance notice through email and in-app notifications. These notifications:
Specify when the voice will become unavailable
Recommend similar alternative voices from the library
This notice period, determined by the voice creator, ensures users have time to transition to new voices and maintain continuity in their projects.
## Sharing voices
<Frame background="subtle">
![Voice sharing](file:ef9a9777-369b-4d17-8f41-6dec61e4a48a)
</Frame>
<Frame background="subtle">
![Voice sharing overview](file:0deec9ac-cad5-45cd-9ea8-68cde9be8b7e)
</Frame>
<Frame background="subtle">
![Voice sharing options](file:3885f1e3-9a37-4156-b732-973acb2b875f)
</Frame>
## How to share a voice model in the Voice Library:
**1. Share Button:** To get started with sharing a voice model, find the voice model you want to share in <a href="/docs/product/voices/voice-lab/overview">My Voices</a> and click the share icon:
**2. Sharing Toggle:** Next, activate sharing by enabling the "Sharing" toggle. Note that this doesn’t make your voice model automatically discoverable in the Voice Library.
**3. Sharing Link/Email Whitelist:** Once the "Sharing" toggle is enabled, you have a few ways to share your Voice Model:
* **Sharing Link:** share this link with your audience, your friends, or anyone else that you want to be able to make a copy of your voice model in My Voices.
* **Email Whitelist:** you can specify specific emails to restrict who can make copies of your voice model in My Voices using your Sharing Link. If you leave the whitelist blank, all emails will be enabled by default.
* **Discovery in Voice Library:** this makes your voice model discoverable in the Voice Library and takes you to the sharing dialog detailed in Step 4 below.
**4. Library Sharing Options:** if you enable "Discovery in Voice Library", you’ll be brought to a dialog screen where you can configure a few options for sharing your voice model in the Voice Library:
Please see the [Voice Library Addendum](https://elevenlabs.io/vla) to our Terms of Service for full descriptions of these options.
**5. Naming Guidelines:** Please ensure the name you give your voice model adheres to the guidelines shown in the sharing dialog:
* The naming pattern should be a one-word name followed by a 2-4 word description, separated by a hyphen (-).
* Your name should NOT include the following:
* Names of public individuals or entities (company names, band names, influencers or famous people, etc).
* Social handles (Twitter, Instagram, you name it, etc).
* ALL CAPS WORDS.
* Emojis and any other non-letter characters.
* Explicit or harmful words.
* The word “voice”.
* Some examples of names following our guidelines:
* Anna - calm and kind
* Robert - friendly grandpa
* Steve - wise teacher
* Harmony - soothing serenader
* Jasper - jovial storyteller
* Maya - confident narrator
**6. Scroll and accept terms:** Before sharing your voice model in the Voice Library, you’ll be asked to scroll and accept the [Voice Library Addendum](https://elevenlabs.io/terms#VLA) to our [Terms of Service](https://elevenlabs.io/terms) and provide additional consents and confirmations. Please do this carefully and ensure you fully understand our service before sharing. If you have any questions at this stage, you can reach out to us at [legal@elevenlabs.io](mailto:legal@elevenlabs.io).
Before you share your voice to the Voice Library, we have a few guidelines that need to be followed. These guidelines are in place to ensure better discoverability and to maintain a clean and organized appearance for everyone using the platform. Please take the time to read through the guidelines below. They will help you understand how you should name, categorize, and tag your voice to enhance the overall experience for users.
### Review
Once you’ve created, named, and shared your voice, it will be set for pending review. This means that someone from the ElevenLabs team will go through your voice to ensure that it adheres to the guidelines outlined above. If there are significant issues, your request to share the voice model will be declined. If only small changes are required, the team might make these adjustments for you and approve the voice model for sharing.
As part of the review process, our team may add labels to your voice model to make it discoverable using the filters for the Voice Library:
* Gender
* Accent
* Language (the language of the source audio used to create your PVC)
* Age
* Use case
* Descriptive
Consistently uploading voices that do not adhere to the guidelines or are highly explicit in nature might result in being barred from uploading and sharing voices altogether. Therefore, please adhere to the guidelines.
Currently, we do not have an estimate of how long the review process will take, as it is highly dependent on the length of the queue.
# Voice Cloning
> Learn how to clone your voice to using our best-in-class models.
<img src="file:5e657922-3b52-45d3-84c7-46f090036f8b" alt="Voice cloning product feature" />
## Overview
When cloning a voice, there are two main options: Instant Voice Cloning (IVC) and Professional Voice Cloning (PVC). IVC is a quick and easy way to clone your voice, while PVC is a more accurate and customizable option.
## Instant Voice Cloning
<Frame background="subtle">
![Instant voice
cloning](file:53f2527a-7018-4ec4-9726-291a87ff6b31)
</Frame>
IVC allows you to create voice clones from shorter samples near instantaneously. Creating an instant voice clone does not train or create a custom AI model. Instead, it relies on prior knowledge from training data to make an educated guess rather than training on the exact voice. This works extremely well for a lot of voices.
However, the biggest limitation of IVC is if you are trying to clone a very unique voice with a very unique accent where the AI might not have heard a similar voices before during training. In such cases, creating a custom model with explicit training using PVC might be the best option.
## Professional Voice Cloning
<Frame background="subtle">
![Professional voice
cloning](file:3525f1b0-a355-49ec-9f8b-64d8c97eb951)
</Frame>
A PVC is a special feature that is available to our Creator+ plans. PVC allows you to train a hyper-realistic model of a voice. This is achieved by training a dedicated model on a large set of voice data to produce a model that’s indistinguishable from the original voice.
Since the custom models require fine-tuning and training, it will take a bit longer to train these PVCs compared to an IVC. Giving an estimate is challenging as it depends on the number of people in the queue before you and a few other factors.
Here are the current estimates for PVC:
* **English:** \~3 hours
* **Multilingual:** \~6 hours
## Beginner's guide to audio recording
If you're new to audio recording, here are some tips to help you get started.
### Recording location
When recording audio, choose a suitable location and set up to minimize room echo/reverb.
So, we want to "deaden" the room as much as possible. This is precisely what a vocal booth that is acoustically treated made for, and if you do not have a vocal booth readily available, you can experiment with some ideas for a DIY vocal booth, “blanket fort”, or closet.
Here are a few YouTube examples of DIY acoustics ideas:
* [I made a vocal booth for \$0.00!](https://www.youtube.com/watch?v=j4wJMDUuHSM)
* [How to Record GOOD Vocals in a BAD Room](https://www.youtube.com/watch?v=TsxdHtu-OpU)
* [The 5 BEST Vocal Home Recording TIPS!](https://www.youtube.com/watch?v=K96mw2QBz34)
### Microphone, pop-filter, and audio interface
A good microphone is crucial. Microphones can range from \$100 to \$10,000, but a professional XLR microphone costing \$150 to \$300 is sufficient for most voiceover work.
For an affordable yet high-quality setup for voiceover work, consider a **Focusrite** interface paired with an **Audio-Technica AT2020** or **Rode NT1 microphone**. This setup, costing between \$300 to \$500, offers high-quality recording suitable for professional use, with minimal self-noise for clean results.
Please ensure that you have a proper **pop-filter** in front of the microphone when recording to avoid plosives as well as breaths and air hitting the diaphragm/microphone directly, as it will sound poor and will also cause issues with the cloning process.
### Digital Audio Workstation (DAW)
There are many different recording solutions out there that all accomplish the same thing: recording audio. However, they are not all created equally. As long as they can record WAV files at 44.1kHz or 48kHz with a bitrate of at least 24 bits, they should be fine. You don't need any fancy post-processing, plugins, denoisers, or anything because we want to keep audio recording simple.
If you want a recommendation, we would suggest something like **REAPER**, which is a fantastic DAW with a tremendous amount of flexibility. It is the industry standard for a lot of audio work. Another good free option is **Audacity**.
Maintain optimal recording levels (not too loud or too quiet) to avoid digital distortion and excessive noise. Aim for peaks of -6 dB to -3 dB and an average loudness of -18 dB for voiceover work, ensuring clarity while minimizing the noise floor. Monitor closely and adjust levels as needed for the best results based on the project and recording environment.
### Positioning
One helpful guideline to follow is to maintain a distance of about two fists away from the microphone, which is approximately 20cm (7-8 in), with a pop filter placed between you and the microphone. Some people prefer to position the pop filter all the way back so that they can press it up right against it. This helps them maintain a consistent distance from the microphone more easily.
Another common technique to avoid directly breathing into the microphone or causing plosive sounds is to speak at an angle. Speaking at an angle ensures that exhaled air is less likely to hit the microphone directly and, instead, passes by it.
### Performance
The performance you give is one of the most crucial aspects of this entire recording session. The AI will try to clone everything about your voice to the best of its ability, which is very high. This means that it will attempt to replicate your cadence, tonality, performance style, the length of your pauses, whether you stutter, take deep breaths, sound breathy, or use a lot of "uhms" and "ahs" – it can even replicate those. Therefore, what we want in the audio file is precisely the performance and voice that we want to clone, nothing less and nothing more. That is also why it's quite important to find a script that you can read that fits the tonality we are aiming for.
When recording for AI, it is very important to be consistent. if you are recording a voice either keep it very animated throughout or keep it very subdued throughout you can't mix and match or the AI can become unstable because it doesn't know what part of the voice to clone. same if you're doing an accent keep the same accent throughout the recording. Consistency is key to a proper clone!
# Instant Voice Cloning
> Learn how to clone your voice instantly using our best-in-class models.
<img src="file:5e657922-3b52-45d3-84c7-46f090036f8b" alt="Voice cloning product feature" />
## Creating an Instant Voice Clone
When cloning a voice, it's important to consider what the AI has been trained on: which languages and what type of dataset. You can find more information about which languages each model has been trained on in our [help center](https://help.elevenlabs.io/hc/en-us/articles/17883183930129-What-models-do-you-offer-and-what-is-the-difference-between-them).
<Info>
Read more about each individual model and their strengths in the [Models page](/docs/models)).
</Info>
## Guide
<Warning>
If you are unsure about what is permissible from a legal standpoint, please consult the [Terms of
Service](https://elevenlabs.io/terms-of-use) and our [AI Safety
information](https://elevenlabs.io/safety) for more information.
</Warning>
<Steps>
### Navigate to the Instant Voice Cloning page
In the ElevenLabs dashboard, select the "Voices" section on the left, then click "Add a new voice".
From the modal, select "Instant Voice Clone".
### Upload or record your audio
Follow the on-screen instructions to upload or record your audio.
### Confirm voice details
<img src="file:e6d6a256-0cc8-42ad-a40d-ecddd9d4da1e" alt="Voice cloning IVC modal" />
Name and label your voice clone, confirm that you have the right and consent to clone the voice, then click "Save voice".
### Use your voice clone
Under the "Voices" section in the dashboard, select the "Personal" tab, then click on your voice clone to begin using it.
</Steps>
## Best practices
<AccordionGroup>
<Accordion title="Record at least 1 minute of audio">
#### Record at least 1 minute of audio
Avoid recording more than 3 minutes, this will yield little improvement and can, in some cases, even be detrimental to the clone.
How the audio was recorded is more important than the total length (total runtime) of the samples. The number of samples you use doesn't matter; it is the total combined length (total runtime) that is the important part.
Approximately 1-2 minutes of clear audio without any reverb, artifacts, or background noise of any kind is recommended. When we speak of "audio or recording quality," we do not mean the codec, such as MP3 or WAV; we mean how the audio was captured. However, regarding audio codecs, using MP3 at 128 kbps and above is advised. Higher bitrates don't have a significant impact on the quality of the clone.
</Accordion>
<Accordion title="Keep the audio consistent">
#### Keep the audio consistent
The AI will attempt to mimic everything it hears in the audio. This includes the speed of the person talking, the inflections, the accent, tonality, breathing pattern and strength, as well as noise and mouth clicks. Even noise and artefacts which can confuse it are factored in.
Ensure that the voice maintains a consistent tone throughout, with a consistent performance. Also, make sure that the audio quality of the voice remains consistent across all the samples. Even if you only use a single sample, ensure that it remains consistent throughout the full sample. Feeding the AI audio that is very dynamic, meaning wide fluctuations in pitch and volume, will yield less predictable results.
</Accordion>
<Accordion title="Replicate your performance">
#### Replicate your performance
Another important thing to keep in mind is that the AI will try to replicate the performance of the voice you provide. If you talk in a slow, monotone voice without much emotion, that is what the AI will mimic. On the other hand, if you talk quickly with much emotion, that is what the AI will try to replicate.
It is crucial that the voice remains consistent throughout all the samples, not only in tone but also in performance. If there is too much variance, it might confuse the AI, leading to more varied output between generations.
</Accordion>
<Accordion title="Find a good balance for the volume">
#### Find a good balance for the volume
Find a good balance for the volume so the audio is neither too quiet nor too loud. The ideal would be between -23 dB and -18 dB RMS with a true peak of -3 dB.
</Accordion>
</AccordionGroup>
# Professional Voice Cloning
> Learn how to clone your voice professionally using our best-in-class models.
## Creating a Professional Voice Clone
When cloning a voice, it's important to consider what the AI has been trained on: which languages and what type of dataset. You can find more information about which languages each model has been trained on in our [help center](https://help.elevenlabs.io/hc/en-us/articles/17883183930129-What-models-do-you-offer-and-what-is-the-difference-between-them).
<Info>
Read more about each individual model and their strengths in the [Models page](/docs/models)).
</Info>
## Guide
<Warning>
If you are unsure about what is permissible from a legal standpoint, please consult the [Terms of
Service](https://elevenlabs.io/terms-of-use) and our [AI Safety
information](https://elevenlabs.io/safety) for more information.
</Warning>
<Steps>
### Navigate to the Professional Voice Cloning page
In the ElevenLabs dashboard, select the "Voices" section on the left, then click "Add a new voice".
From the modal, select "Professional Voice Clone".
### Upload your audio
<img src="file:3525f1b0-a355-49ec-9f8b-64d8c97eb951" alt="Voice cloning IVC modal" />
Follow the on-screen instructions to label your voice clone and upload audio samples.
### Verify your voice
Once everything is recorded and uploaded, you will be asked to verify your voice. To ensure a smooth experience, please try to verify your voice using the same or similar equipment used to record the samples and in a tone and delivery that is similar to what was present in the samples. If you do not have access to the same equipment, try verifying the best you can. If it fails, you will have to reach out to support.
### Wait for your voice to complete fine tuning
Before you can use your voice, it needs to complete the fine tuning process. In My Voices, you can check the status of your voice while it's processing, and you'll be notified when it's ready to use.
### Use your voice clone
Under the "Voices" section in the dashboard, select the "Personal" tab, then click on your voice clone to begin using it.
</Steps>
There are a few things to be mindful of before you start uploading your samples, and some steps that you need to take to ensure the best possible results.
<Steps>
### Record high quality audio
Professional Voice Cloning is highly accurate in cloning the samples used for its training. It will create a near-perfect clone of what it hears, including all the intricacies and characteristics of that voice, but also including any artifacts and unwanted audio present in the samples. This means that if you upload low-quality samples with background noise, room reverb/echo, or any other type of unwanted sounds like music or multiple people speaking, the AI will try to replicate all of these elements in the clone as well.
### Ensure there's only a single speaking voice
Make sure there's only a single speaking voice throughout the audio, as more than one speaker or excessive noise or anything of the above can confuse the AI. This confusion can result in the AI being unable to discern which voice to clone or misinterpreting what the voice actually sounds like because it is being masked by other sounds, leading to a less-than-optimal clone.
### Provide enough material
Make sure you have enough material to clone the voice properly. The bare minimum we recommend is 30 minutes of audio, but for the optimal result and the most accurate clone, we recommend closer to 2+ hours of audio. You might be able to get away with less, but at that point, we can’t vouch for the quality of the resulting clone.
### Keep the style consistent
The speaking style in the samples you provide will be replicated in the output, so depending on what delivery you are looking for, the training data should correspond to that style (e.g. if you are looking to voice an audiobook with a clone of your voice, the audio you submit for training should be a recording of you reading a book in the tone of voice you want to use). It is better to just include one style in the uploaded samples for consistencies sake.
### Use samples speaking the language you want the PVC to be used for
It is best to use samples speaking where you are speaking the language that the PVC will mainly be used for. Of course, the AI can speak any language that we currently support. However, it is worth noting that if the voice itself is not native to the language you want the AI to speak - meaning you cloned a voice speaking a different language - it might have an accent from the original language and might mispronounce words and inflections. For instance, if you clone a voice speaking English and then want it to speak Spanish, it will very likely have an English accent when speaking Spanish. We only support cloning samples recorded in one of our supported languages, and the application will reject your sample if it is recorded in an unsupported language.
</Steps>
See the examples below for what to expect from a good and bad recording.
<iframe width="100%" height={90} frameBorder="no" scrolling="no" src={`https://elevenlabs.io/player/index.html?title=Good%20example&small=true&preview=true&audioSrc=https%3A%2F%2Fstorage.googleapis.com%2Feleven-public-cdn%2Faudio%2Fdocs%2Fgood_example.wav`} />
<iframe width="100%" height={90} frameBorder="no" scrolling="no" src={`https://elevenlabs.io/player/index.html?title=Bad%20example&small=true&preview=true&audioSrc=https%3A%2F%2Fstorage.googleapis.com%2Feleven-public-cdn%2Faudio%2Fdocs%2Fbad_example.wav`} />
For now, we only allow you to clone your own voice. You will be asked to go through a verification process before submitting your fine-tuning request.
## Tips and suggestions
<AccordionGroup>
<Accordion title="Professional Recording Equipment">
#### Professional Recording Equipment
Use high-quality recording equipment for optimal results as the AI will clone everything about the audio. High-quality input = high-quality output. Any microphone will work, but an XLR mic going into a dedicated audio interface would be our recommendation. A few general recommendations on low-end would be something like an Audio Technica AT2020 or a Rode NT1 going into a Focusrite interface or similar.
</Accordion>
<Accordion title="Use a Pop-Filter">
#### Use a Pop-Filter
Use a Pop-Filter when recording. This will minimize plosives when recording.
</Accordion>
<Accordion title="Microphone Distance">
#### Microphone Distance
Position yourself at the right distance from the microphone - approximately two fists away from the mic is recommended, but it also depends on what type of recording you want.
</Accordion>
<Accordion title="Noise-Free Recording">
#### Noise-Free Recording
Ensure that the audio input doesn't have any interference, like background music or noise. The AI cloning works best with clean, uncluttered audio.
</Accordion>
<Accordion title="Room Acoustics">
#### Room Acoustics
Preferably, record in an acoustically-treated room. This reduces unwanted echoes and background noises, leading to clearer audio input for the AI. You can make something temporary using a thick duvet or quilt to dampen the recording space.
</Accordion>
<Accordion title="Audio Pre-processing">
#### Audio Pre-processing
Consider editing your audio beforehand if you're aiming for a specific sound you want the AI to output. For instance, if you want a polished podcast-like output, pre-process your audio to match that quality, or if you have long pauses or many "uhm"s and "ahm"s between words as the AI will mimic those as well.
</Accordion>
<Accordion title="Volume Control">
#### Volume Control
Maintain a consistent volume that's loud enough to be clear but not so loud that it causes distortion. The goal is to achieve a balanced and steady audio level. The ideal would be between -23dB and -18dB RMS with a true peak of -3dB.
</Accordion>
<Accordion title="Sufficient Audio Length">
#### Sufficient Audio Length
Provide at least 30 minutes of high-quality audio that follows the above guidelines for best results - preferably closer to 2+ hours of audio. The more quality data you can feed into the AI, the better the voice clone will be. The number of samples is irrelevant; the total runtime is what matters. However, if you plan to upload multiple hours of audio, it is better to split it into multiple \~30-minute samples. This makes it easier to upload.
</Accordion>
</AccordionGroup>
# Voice design
> A guide on how to craft voices from a text prompt.
<img src="file:91266b2c-503f-414f-b465-9608161b51d0" alt="Voice design" />
## Overview
Voice Design helps creators fill the gaps when the exact voice they are looking for isn’t available in the [Voice Library](/app/voice-library). If you can’t find a suitable voice for your project, you can create one. Note that Voice Design is highly experimental and [Professional Voice Clones (PVC)](/docs/product-guides/voices/voice-cloning) are currently the highest quality voices on our platform. If there is a PVC available in our library that fits your needs, we recommend using it instead.
You can find Voice Design by heading to Voices -> My Voices -> Add a new voice -> Voice Design in the [ElevenLabs app](/app/voice-lab?create=true\&creationType=voiceDesign) or via the [API](/docs/api-reference/text-to-voice).
When you hit generate, we'll generate three voice options for you. The only charge for using voice design is the number of credits to generate your preview text, which you are only charged once even though we are generating three samples for you. You can see the number of characters that will be deducated in the "Text to preview" text box.
After generating, you'll have the option to select and save one of the generations, which will take up one of your voice slots.
<CardGroup>
<Card title="API reference" href="/docs/api-reference/text-to-voice">
See the API reference for Voice Design
</Card>
<Card title="Example app" href="https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/text-to-voice/x-to-voice">
A Next.js example app for Voice Design
</Card>
</CardGroup>
## Prompting guide
### Voice design types
| Type                   | Description                                                                                                                     | Example Prompts                                                                                                                                                                                                                                                                                                                                                                     |
| :--------------------- | :------------------------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Realistic Voice Design | Create an original, realistic voice by specifying age, accent/nationality, gender, tone, pitch, intonation, speed, and emotion. | - "An Indian woman with a soft, high voice. Conversational, slow and calm."<br /> - "An old British male with a raspy, deep voice. Professional, relaxed and assertive."<br /> - "A middle-aged Australian female with a warm, low voice. Corporate, fast and happy."                                                                                                               |
| Character Voice Design | Generate unique voices for creative characters using simpler prompts.                                                           | - "A massive evil ogre, troll"<br />- "A cute little squeaky mouse"<br />- "An angry old pirate, shouting" <br /><br /> Some other characters we've had success with include Goblin, Vampire, Elf, Troll, Werewolf, Ghost, Alien, Giant, Witch, Wizard, Zombie, Demon, Devil, Pirate, Genie, Ogre, Orc, Knight, Samurai, Banshee, Yeti, Druid, Robot, Elf, Monkey, Monster, Dracula |
<Warning>
Generating child or child-like voices violates our [Prohibited Use
Policy](https://elevenlabs.io/use-policy).
</Warning>
### Voice attributes
| Attribute          | Importance      | Options                                                             |
| :----------------- | :-------------- | :------------------------------------------------------------------ |
| Age                | High Importance | Adult, Middle-Aged, Old, etc...                                     |
| Accent/Nationality | High Importance | British, Indian, Polish, American, etc...                           |
| Gender             | High Importance | Male, Female, Gender Neutral                                        |
| Tone               | Not Needed      | Gruff, Soft, Warm, Raspy, etc...                                    |
| Pitch              | Not Needed      | Deep, Low, High, Squeaky, etc...                                    |
| Intonation         | Not Needed      | Conversational, Professional, Corporate, Urban, Posh, etc...        |
| Speed              | Not Needed      | Fast, Quick, Slow, Relaxed, etc...                                  |
| Emotion/Delivery   | Not Needed      | Angry, Calm, Scared, Happy, Assertive, Whispering, Shouting, etc... |
# Payouts
> Earn rewards by sharing your voice in the Voice Library.
<img src="file:b0e3592c-d02d-4224-9ffe-bfa6ffacf734" alt="Payouts" />
## Overview
The [Payouts](https://elevenlabs.io/payouts) (VL) system allows you to earn rewards for sharing voices in the Voice Library. ElevenLabs uses <a href="https://stripe.com/connect">Stripe Connect</a> to process reward payouts.
## Account setup
To set up your Payouts account:
* Click on your account in the bottom left and select ["Payouts"](/app/payouts).
<Frame background="subtle">
![Payouts overview](file:62503e60-099b-497a-872c-dae2d9f4cfca)
</Frame>
* Follow the prompts from Stripe Connect to complete the account setup.
## Tracking usage and earnings
* You can track the usage of your voices by going to ["My Voices"](/app/voice-lab), clicking "View" to open the detailed view for your voice, then clicking the sharing icon at the bottom. Once you have the Sharing Options open, click "View Metrics".
* The rewards you earn are based on the options you selected when [sharing your voice in the Voice Library](/docs/product-guides/voices/voice-library#sharing-voices).
* You can also see your all-time earnings and past payouts by going back to your Payouts page.
## Reader app rewards
* If your voice is marked as **[High-Quality](/docs/product-guides/voices/voice-library#category)** and you have activated the "Available in ElevenReader" toggle, your voice will made be available in the [ElevenReader app](/text-reader). Rewards for ElevenReader are reported separately – to view your Reader App rewards, check the "ElevenReader" box on your "View Metrics" screen.
## Things to know
* Rewards accumulate frequently throughout the day, but payouts typically happen once a week as long as you have more than \$10 in accrued payouts. You can see your past payouts by going to your [Payouts](/app/payouts) page in the sidebar.
## Supported countries
* Currently, Stripe Connect is not supported in all countries. We are constantly working to expand our reach for Payouts and plan to add availability in more countries when possible.
<Accordion title="Supported countries">
Argentina, Australia, Austria, Belgium, Bulgaria, Canada, Chile, Colombia, Croatia, Cyprus, Czech
Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hong Kong SAR China, Hungary,
Iceland, India, Indonesia, Ireland, Israel, Italy, Japan, Latvia, Liechtenstein, Lithuania,
Luxembourg, Malaysia, Malta, Mexico, Monaco, Netherlands, New Zealand, Nigeria, Norway, Peru,
Philippines, Poland, Portugal, Qatar, Romania, Saudi Arabia, Singapore, Slovakia, Slovenia, South
Africa, South Korea, Spain, Sweden, Switzerland, Thailand, Taiwan, Turkey, United Arab Emirates,
United Kingdom, United States, Uruguay & Vietnam
</Accordion>
# Audio Native
> Easily embed ElevenLabs on any web page.
<img src="file:437e7986-abe8-47cd-8e5b-7bfce1c233e4" alt="Audio Native" />
## Overview
Audio Native is an embedded audio player that automatically voices content of a web page using ElevenLab’s [Text to Speech](/docs/product-guides/playground/text-to-speech) service. It can also be used to embed pre-generated content from a project into a web page. All it takes to embed on your site is a small HTML snippet. In addition, Audio Native provides built-in metrics allowing you to precisely track audience engagement via a listener dashboard.
The end result will be a Audio Native player that can narrate the content of a page, or, like in the case below, embed pre-generated content from a project:
<iframe width="100%" height="90" seamless src="https://elevenlabs.io/player/index.html?publicUserId=4d7f6f3d38ae27705f5b516ffd3e413a09baa48667073d385e5be1be773eaf69&projectId=gLj1spzTwuTgKuOtyfnX&small=true&textColor=rgba(0,%200,%200,%201)&backgroundColor=rgba(255,%20255,%20255,%201)" />
## Guide
<Steps>
<Step title="Navigate to Audio Native">
In the ElevenLabs dashboard, under "Audio Tools" navigate to ["Audio Native"](/app/audio-native).
</Step>
<Step title="Configure player appearance">
Customize the player apperance by selecting background and text colors.
</Step>
<Step title="Configure allowed sites">
The URL allowlist is the list of web pages that will be permitted to play your content.
You can choose to add a specific web page (e.g. `https://elevenlabs.io/blog`) or add a whole domain to the allowlist (e.g. `http://elevenlabs.io`). If a player is embedded on a page that is not in the allowlist, it will not work as intended.
</Step>
<Step title="Get embed code">
Once you've finished configuring the player and allowlist, copy the embed code and paste it into your website's source code.
</Step>
</Steps>
## Technology-specific guides
To integrate Audio Native into your web techology of choice, see the following guides:
<CardGroup cols={4}>
<Card title="React" icon="brands react" href="/docs/product-guides/audio-tools/audio-native/react" />
<Card title="Ghost" icon="duotone ghost" href="/docs/product-guides/audio-tools/audio-native/ghost" />
<Card title="Squarespace" icon="brands squarespace" href="/docs/product-guides/audio-tools/audio-native/squarespace" />
<Card title="Framer" icon="duotone browser" href="/docs/product-guides/audio-tools/audio-native/framer" />
<Card title="Webflow" icon="brands webflow" href="/docs/product-guides/audio-tools/audio-native/webflow" />
<Card title="Wordpress" icon="brands wordpress" href="/docs/product-guides/audio-tools/audio-native/word-press" />
<Card title="Wix" icon="brands wix" href="/docs/product-guides/audio-tools/audio-native/wix" />
</CardGroup>
## Using the API
You can use the [Audio Native API](/docs/api-reference/audio-native/create) to programmatically create an Audio Native player for your existing content.
<CodeBlocks>
```python title="Python"
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
response = client.audio_native.create(
name="name",
)
# Use the snippet in response.html_snippet to embed the player on your website
```
```javascript title="JavaScript"
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
const { html_snippet } = await client.audioNative.create({
name: "my-audio-native-player"
});
// Use the HTML code in html_snippet to embed the player on your website
```
</CodeBlocks>
## Settings
<AccordionGroup>
<Accordion title="Voice and model">
### Voices
To configure the voice and model that will be used to read the content of the page, navigate to the "Settings" tab and select the voice and modelyou want to use.
</Accordion>
<Accordion title="Pronunciation dictionaries">
### Pronunciation dictionaries
Sometimes you may want to specify the pronunciation of certain words, such as character or brand names, or specify how acronyms should be read. Pronunciation dictionaries allow this functionality by enabling you to upload a lexicon or dictionary file that includes rules about how specified words should be pronounced, either using a phonetic alphabet (phoneme tags) or word substitutions (alias tags).
Whenever one of these words is encountered in a project, the AI will pronounce the word using the specified replacement. When checking for a replacement word in a pronunciation dictionary, the dictionary is checked from start to end and only the first replacement is used.
</Accordion>
</AccordionGroup>
# Audio Native with React
> Integrate Audio Native into your React apps.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
This guide will show how to integrate Audio Native into React apps. The focus will be on a Next.js project, but the underlying concepts will work for any React based application.
<Steps>
<Step title="Create an Audio Native React component">
After completing the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native), you'll have an embed code snippet. Here's an example snippet:
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
We can extract the data from the snippet to create a customizable React component.
```tsx title="ElevenLabsAudioNative.tsx" maxLines=0
// ElevenLabsAudioNative.tsx
'use client';
import { useEffect } from 'react';
export type ElevenLabsProps = {
publicUserId: string;
textColorRgba?: string;
backgroundColorRgba?: string;
size?: 'small' | 'large';
children?: React.ReactNode;
};
export const ElevenLabsAudioNative = ({
publicUserId,
size,
textColorRgba,
backgroundColorRgba,
children,
}: ElevenLabsProps) => {
useEffect(() => {
const script = document.createElement('script');
script.src = 'https://elevenlabs.io/player/audioNativeHelper.js';
script.async = true;
document.body.appendChild(script);
return () => {
document.body.removeChild(script);
};
}, []);
return (
<div
id="elevenlabs-audionative-widget"
data-height={size === 'small' ? '90' : '120'}
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid={publicUserId}
data-playerurl="https://elevenlabs.io/player/index.html"
data-small={size === 'small' ? 'True' : 'False'}
data-textcolor={textColorRgba ?? 'rgba(0, 0, 0, 1.0)'}
data-backgroundcolor={backgroundColorRgba ?? 'rgba(255, 255, 255, 1.0)'}
>
{children ? children : 'Elevenlabs AudioNative Player'}
</div>
);
};
export default ElevenLabsAudioNative;
```
The above component can be found on [GitHub](https://github.com/elevenlabs/elevenlabs-examples/blob/main/examples/audio-native/react/ElevenLabsAudioNative.tsx).
</Step>
<Step title="Use the Audio Native component">
Before using the component on your page, you need to retrieve your public user ID from the original code snippet. Copy the contents of `data-publicuserid` from the embed code snippet and insert it into the `publicUserId` prop of the component.
```tsx title="page.tsx" maxLines=0
import { ElevenLabsAudioNative } from './path/to/ElevenLabsAudioNative';
export default function Page() {
return (
<div>
<h1>Your Page Title</h1>
// Insert the public user ID from the embed code snippet
<ElevenLabsAudioNative publicUserId="<your-public-user-id>" />
<p>Your page content...</p>
</div>
);
}
```
</Step>
<Step title="Customize the player with component props">
The component props can be used to customize the player. For example, you can change the size, text color, and background color.
```tsx title="page.tsx" maxLines=0
import { ElevenLabsAudioNative } from './path/to/ElevenLabsAudioNative';
export default function Page() {
return (
<div>
<h1>Your Page Title</h1>
<ElevenLabsAudioNative
publicUserId="<your-public-user-id>"
size="small"
textColorRgba="rgba(255, 255, 255, 1.0)"
backgroundColorRgba="rgba(0, 0, 0, 1.0)"
/>
<p>Your page content...</p>
</div>
);
}
```
</Step>
</Steps>
# Audio Native with Ghost
> Integrate Audio Native into your Ghost blog.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Add HTML to your blog post">
Navigate to your Ghost blog, sign in and open the settings page for the blog post you wish to narrate.
</Step>
<Step title="Add the embed code to your blog post">
Click the "+" symbol on the left and select "HTML" from the menu.
<img src="file:26f59d08-39ea-4ec5-aec0-76cea6345924" alt="Audio Native" />
Paste the Audio Native embed code into the HTML box and press enter.
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:665c8534-c841-4286-9829-3c1792b14c1a" alt="Audio Native" />
</Step>
<Step title="Update the blog post">
Click the "Update" button in the top right corner of the editor, which should now be highlighted in green text.
<img src="file:910da2b5-4658-4941-8a2a-e780575ca3e1" alt="Audio Native" />
</Step>
<Step title="Navigate to the live version of the blog post">
Finally, navigate to the live version of the blog post. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:e7d1803b-1f99-450f-bb0e-fb99b0d53043" alt="Audio Native" />
</Step>
</Steps>
# Audio Native with Squarespace
> Integrate Audio Native into your Squarespace sites.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Add HTML to your blog post">
Navigate to your Squarespace site, sign in and open the page you wish to add narration to.
</Step>
<Step title="Add the embed code to your blog post">
Click the "+" symbol on the spot you want to place the Audio Native player and select "Code" from the menu.
<img src="file:6bc941f9-0c3e-41e2-98d5-68c963ca9194" alt="Audio Native" />
Paste the Audio Native embed code into the HTML box and press enter.
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:efc171bb-c08e-43ee-9ad0-c9ec357e2566" alt="Audio Native" />
</Step>
<Step title="Update the blog post">
Click the "Save" button in the top right corner of the editor, which should now be highlighted.
</Step>
<Step title="Navigate to the live version of the blog post">
Finally, navigate to the live version of the blog post. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:fdb58762-f323-4777-9b84-091d3394d66a" alt="Audio Native" />
</Step>
</Steps>
# Audio Native with Framer
> Integrate Audio Native into your Framer websites.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Add Audio Native script to your page">
Navigate to your Framer page, sign in and go to your site settings. From the Audio Native embed code, extract the `<script>` tag and paste it in the "End of `<body>` tag" field.
```html title="Embed script "
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:c150a28d-88a9-4835-908f-bffcac2b02d2" alt="Audio Native" />
</Step>
<Step title="Add an Embed Element">
On your Framer blog page, add an Embed Element from Utilities.
<img src="file:f7cd983d-fe74-44b7-a511-33e492a0e0d9" alt="Audio Native" />
In the config for the Embed Element, switch the type to HTML and paste the `<div>` snippet from the Audio Native embed code into the HTML box.
```html title="Embed div"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
```
<img src="file:36296450-daf1-41e8-ba7a-74e284183921" alt="Audio Native" />
</Step>
<Step title="Publish your changes">
Finally, publish your changes and navigate to the live version of your page. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:90a1c9ac-581a-4b19-a7b7-00419cb51314" alt="Audio Native" />
</Step>
</Steps>
# Audio Native with Webflow
> Integrate Audio Native into your Webflow sites.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Add HTML to your blog post">
Navigate to your Webflow blog, sign in and open the editor for the blog post you wish to narrate.
</Step>
<Step title="Add the embed code to your blog post">
Click the "+" symbol in the top left and select "Code Embed" from the Elements menu.
<img src="file:be04def9-d128-48bb-931b-4c51157375dd" alt="Audio Native" />
Paste the Audio Native embed code into the HTML box and click "Save & Close".
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:7ac87daa-5e0b-48b6-a347-aca992090b1f" alt="Audio Native" />
</Step>
<Step title="Re-position the code embed">
In the Navigator, place the code embed where you want it to appear on the page.
<img src="file:dec0c8c5-396b-4c01-81c4-b950417543a6" alt="Audio Native" />
</Step>
<Step title="Publish your changes">
Finally, publish your changes and navigate to the live version of the blog post. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:ec6f7f06-0b44-4bed-9c9e-bff1320e7f41" alt="Audio Native" />
</Step>
</Steps>
# Audio Native with WordPress
> Integrate Audio Native into your WordPress sites.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Install the WPCode plugin">
Install the [WPCode plugin](https://wpcode.com/) into your WordPress website to embed HTML code.
</Step>
<Step title="Create a new code snippet">
In the WordPress admin console, click on "Code Snippets". Add the Audio Native embed code to the new code snippet.
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:8c06475f-6efa-4fcf-84d0-6048725ee614" alt="Audio Native" />
Pick "Auto Insert" for the insert method and set the location to be "Insert Before Content".
<img src="file:9c59ac58-9bdd-46df-af5e-260df08cbd57" alt="Audio Native" />
</Step>
<Step title="Publish your changes">
Finally, publish your changes and navigate to the live version of the blog post. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:2111fa39-ccf1-4bd9-b80c-ed10a416305b" alt="Audio Native" />
</Step>
</Steps>
# Audio Native with Wix
> Integrate Audio Native into your Wix sites.
<Info>
Follow the steps in the [Audio Native overview](/docs/product-guides/audio-tools/audio-native) to
get started with Audio Native before continuing with this guide.
</Info>
<Steps>
<Step title="Add HTML to your blog post">
Navigate to your Wix site, sign in and open the settings page for the page you wish to narrate.
</Step>
<Step title="Add the embed code to your blog post">
Click the "+" symbol at the top of your content and select "HTML Code" from the menu.
<img src="file:29bbf7a1-efb0-43e0-80d3-c0dbd3994cea" alt="Audio Native" />
Paste the Audio Native embed code into the HTML box and click "Save".
```html title="Embed code snippet"
<div
id="elevenlabs-audionative-widget"
data-height="90"
data-width="100%"
data-frameborder="no"
data-scrolling="no"
data-publicuserid="public-user-id"
data-playerurl="https://elevenlabs.io/player/index.html"
data-projectid="project-id"
>
Loading the <a href="https://elevenlabs.io/text-to-speech" target="_blank" rel="noopener">Elevenlabs Text to Speech</a> AudioNative Player...
</div>
<script src="https://elevenlabs.io/player/audioNativeHelper.js" type="text/javascript"></script>
```
<img src="file:09a8fe7d-fc88-4c8a-9e8e-d809a5d5f2cc" alt="Audio Native" />
</Step>
<Step title="Publish the page">
Click the "Publish" button in the top right corner of the editor.
</Step>
<Step title="Navigate to the live version of the blog post">
Finally, navigate to the live version of the blog post. You should see a message to let you know that the Audio Native project is being created. After a few minutes the text in your blog will be converted to an audio article and the embedded audio player will appear.
<img src="file:0d10ed30-10ee-40ec-b89f-3230bdb422ca" alt="Audio Native" />
</Step>
</Steps>
# Voiceover studio
> A guide on how to create long-form content with ElevenLabs Voiceover Studio
<img src="file:e318a924-aad8-4f37-9f6d-0feea6e9a8fa" alt="Voiceover studio" />
## Overview
Voiceover Studio combines the audio timeline with our Sound Effects feature, giving you the ability to write a dialogue between any number of speakers, choose those speakers, and intertwine your own creative sound effects anywhere you like.
<iframe width="100%" height="400" src="https://www.youtube.com/embed/GBdOQClluIA?autoplay=0" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
## Guide
<Steps>
<Step title="Navigate to the Voiceover studio">
In the ElevenLabs dashboard, click on the "Voiceover Studio" option in the sidebar under "Audio
Tools".
</Step>
<Step title="Create a new voiceover">
Click the "Create a new voiceover" button to begin. You can optionally upload video or audio to
create a voiceover from.
</Step>
<Step title="Modify the voiceover with the timeline">
On the bottom half of your screen, use the timeline to add and edit voiceover clips plus add
sound effects.
</Step>
<Step title="Export your voiceover">
Once you're happy with your voiceover, click the "Export" button in the bottom right, choose the
format you want and either view or download your voiceover.
</Step>
</Steps>
## FAQ
<AccordionGroup>
<Accordion title="How does the timeline work?">
### Timeline
The timeline is a linear representation of your Voiceover project. Each row represents a track, and on the far left section you have the track information for voiceover or SFX tracks. In the middle, you can create the clips that represent when a voice is speaking or a SFX is playing. On the right-hand side, you have the settings for the currently selected clip.
</Accordion>
<Accordion title="How do I add tracks?">
### Adding Tracks
To add a track, click the "Add Track" button in the bottom left of the timeline. You can choose to add a voiceover track or an SFX track.
There are three types of tracks you can add in the studio: Voiceover tracks, SFX tracks and uploaded audio.
* **Voiceover Tracks:** Voiceover tracks create new Speakers. You can click and add clips on the timeline wherever you like. After creating a clip, start writing your desired text on the speaker cards above and click "Generate". Similar to Dubbing Studio, you will also see a little cogwheel on each Speaker track - simply click on it to adjust the voice settings or replace any speaker with a voice directly from your Voices - including your own Professional Voice Clone if you have created one.
* **SFX Tracks:** Add a SFX track, then click anywhere on that track to create a SFX clip. Similar to our independent SFX feature, simply start writing your prompt in the Speaker card above and click "Generate" to create your new SFX audio. You can lengthen or shorten SFX clips and move them freely around your timeline to fit your project - make sure to press the "stale" button if you do so.
* **Uploaded Audio:** Add an audio track including background music or sound effects. It's best to avoid uploading audio with speakers, as any speakers in this track will not be detected, so you won't be able to translate or correct them.
</Accordion>
<Accordion title="How does this differ from Dubbing Studio?">
### Key Differences from Dubbing Studio
If you chose not to upload a video when you created your Voiceover project, then the entire timeline is yours to work with and there are no time constraints. This differs from Dubbing Studio as it gives you a lot more freedom to create what you want and adjust the timing more easily.
When you Add a Voiceover Track, you will instantly be able to create clips on your timeline. Once you create a Voiceover clip, begin by writing in the Speaker Card above. After generating that audio, you will notice your clip on the timeline will automatically adjust its length based on the text prompt - this is called "Dynamic Generation". This option is also available in Dubbing Studio by right-clicking specific clips, but because syncing is more important with dubbed videos, the default generation type there is "Fixed Generation," meaning the clips' lengths are not affected.
</Accordion>
<Accordion title="How are credits deducted with Voiceover Studio?">
### Credit Costs
Voiceover Studio does not deduct credits to create your initial project. Credits are deducted every time material is generated. Similar to Speech-Synthesis, credit costs for Voiceover Clips are based on the length of the text prompt. SFX clips will deduct 80 credits per generation.
If you choose to Dub (translate) your Voiceover Project into different languages, this will also cost additional credits depending on how much material needs to be generated. The cost is 1 credit per character for the translation, plus the cost of generating the new audio for the additional languages.
</Accordion>
<Accordion title="How do I upload a script?">
### Uploading Scripts
With Voiceover Studio, you have the option to upload a script for your project as a CSV file. You can either include speaker name and line, or speaker name, line, start time and end time. To upload a script, click on the cog icon in the top right hand corner of the page and select "Import Script".
Scripts should be provided in the following format:
```
speaker,line,
```
Example input:
```
speaker,line,
Joe,"Hey!"
Maria,"Oh, hi Joe! It's been a while."
```
You can also provide start and end times for each line in the following format:
```
speaker,line,start_time,end_time
```
Example input:
```
speaker,line,start_time,end_time
Joe,"Hey!",0.1,1.5
Maria,"Oh, hi Joe! It's been a while.",1.6,2.0
```
Once your script has imported, make sure to assign voices to each speaker before you generate the audio. To do this, click the cog icon in the information for each track, on the left.
If you don't specify start and end times for your clips, Voiceover Studio will estimate how long each clip will be, and distribute them along your timeline.
</Accordion>
<Accordion title="What's the difference between Dynamic Duration and Fixed Duration?">
### Dynamic Duration
By default, Voiceover Studio uses Dynamic Duration, which means that the length of the clip will vary depending on the text input and the voice used. This ensures that the audio sounds as natural as possible, but it means that the length of the clip might change after the audio has been generated. You can easily reposition your clips along the timeline once they have been generated to get a natural sounding flow. If you click "Generate Stale Audio", or use the generate button on the clip, the audio will be generated using Dynamic Duration.
This also applies if you do specify the start and end time for your clips. The clips will generate based on the start time you specify, but if you use the default Dynamic Duration, the end time is likely to change once you generate the audio.
### Fixed Duration
If you need the clip to remain the length specified, you can choose to generate with Fixed Duration instead. To do this, you need to right click on the clip and select "Generate Audio Fixed Duration". This will adjust the length of the generated audio to fit the specified length of the clip. This could lead to the audio sounding unnaturally quick or slow, depending on the length of your clip.
If you want to generate multiple clips at once, you can use shift + click to select multiple clips for a speaker at once, then right click on one of them to select "Generate Audio Fixed Duration" for all selected clips.
</Accordion>
</AccordionGroup>
# Voice isolator
> A guide on how to remove background noise from audio recordings.
<img src="file:55880acd-05ad-46f2-8de6-b64ef8c2a816" alt="Voice changer product feature" />
## Overview
Voice isolator is a tool that allows you to remove background noise from audio recordings.
## Guide
<img src="file:e459337b-1780-4b1d-9031-458f94d79d41" alt="Voice isolator" />
To use the voice isolator app, navigate to [Voice Isolator](/app/voice-isolator) under the Audio Tools section. Here you can upload or drag and drop your audio file into the app, or record a new audio file with your device's microphone.
Click "Isolate voice" to start the process. The app will isolate the voice from the background noise and return a new audio file with the isolated voice. Once the process is complete, you can download the audio file or play it back in the app.
The voice isolator functionality is also available via the [API](/docs/api-reference/audio-isolation/audio-isolation) to easily integrate this functionality into your own applications.
<CardGroup>
<Card title="Voice isolator app" href="/app/voice-isolator">
Use the voice isolator app.
</Card>
<Card title="API reference" href="/docs/api-reference/audio-isolation/audio-isolation">
Use the voice isolator API.
</Card>
</CardGroup>
# AI speech classifier
> A guide on how to detect AI audio
<img src="file:f03ad710-02e3-4a7b-8d47-9cbe608b9429" alt="AI speech classifier" />
## Overview
The AI speech classifier is a tool that allows you to detect if an audio file was generated by ElevenLabs.
## Guide
<Steps>
<Step title="Navigate to the AI speech classifier page">
Select the "AI speech classifier" option from the sidebar under "Audio Tools" in the ElevenLabs
dashboard.
</Step>
<Step title="Upload an audio file">
Click the "Upload audio" button upload an audio file and begin scanning.
</Step>
<Step title="Analyze the audio file">
The AI speech classifier will analyze the audio file and provide a result.
</Step>
</Steps>
## FAQ
<AccordionGroup>
<Accordion title="How accurate is the AI speech classifier?">
Our classifier maintains high accuracy (99% precision, 80% recall) for audio files generated
with ElevenLabs that have not been modified. We will continue to improve this tool, while
exploring other detection tools that provide transparency about how content was created.
</Accordion>
<Accordion title="Does using the tool cost me anything?">
No, the tool is free for all to use.
</Accordion>
<Accordion title="Do I have to be logged in to use the tool?">
A [web version](https://elevenlabs.io/ai-speech-classifier) of the tool is available for you to
use without having to log in.
</Accordion>
</AccordionGroup>
# Account
To begin using ElevenLabs, you'll need to create an account. Follow these steps:
* **Sign Up**: Visit the [ElevenLabs website](https://elevenlabs.io/sign-up) and click on the 'Get started free' button. You can register using your email or through one of the OAuth providers.
* **Verify Email**: Check your email for a verification link from ElevenLabs. Click the link to verify your account.
* **Initial Setup**: After verification, you'll be directed to the Speech Synthesis page where you can start generating audio from text.
**Exercise**: Try out an example to get started or type something, select a voice and click generate!
<img src="file:9ef8c7d8-f8a2-4acd-be03-8c84da49de1f" alt="Account creation exercise" />
You can sign up with traditional email and password or using popular OAuth providers like Google, Facebook, and GitHub.
If you choose to sign up with your email, you will be asked to verify your email address before you can start using the service. Once you have verified your email, you will be taken to the Speech Synthesis page, where you can immediately start using the service. Simply type anything into the box and press “generate” to convert the text into voiceover narration. Please note that each time you press “generate” anywhere on the website, it will deduct credits from your quota.
If you sign up using Google OAuth, your account will be intrinsically linked to your Google account, meaning you will not be able to change your email address, as it will always be linked to your Google email.
# Billing
<CardGroup>
<Card title="Pricing" href="/pricing">
View the pricing page
</Card>
<Card title="Subscription details" href="/app/subscription">
View your subscription details
</Card>
</CardGroup>
When signing up, you will be automatically assigned to the free tier. To view your subscription, click on "My Account" in the bottom left corner and select ["Subscription"](https://elevenlabs.io/app/subscription). You can read more about the different plans [here](https://elevenlabs.io/pricing). At the bottom of the page, you will find a comparison table to understand the differences between the various plans.
We offer five public plans: Free, Starter, Creator, Pro, Scale, and Business. In addition, we also offer an Enterprise option that's specifically tailored to the unique needs and usage of large organizations.
You can see details of all our plans on the subscription page. This includes information about the total monthly credit quota, the number of custom voices you can have saved simultaneously, and the quality of audio produced.
Cloning is only available on the Starter tier and above. The free plan offers three custom voices that you can create using our [Voice Design tool](/docs/product-guides/voices/voice-design), or you can add voices from the [Voice Library](/docs/product-guides/voices/voice-library) if they are not limited to the paid tiers.
You can upgrade your subscription at any time, and any unused quota from your previous plan will roll over to the new one. As long as you don’t cancel or downgrade, unused credits at the end of the month will carry over to the next month, up to a maximum of two months’ worth of credits. For more information, please visit our Help Center articles:
* ["How does credit rollover work?"](https://help.elevenlabs.io/hc/en-us/articles/27561768104081-How-does-credit-rollover-work)
* ["What happens to my subscription and quota at the end of the month?"](https://help.elevenlabs.io/hc/en-us/articles/13514114771857-What-happens-to-my-subscription-and-quota-at-the-end-of-the-month)
From the [subscription page](/app/subscription), you can also downgrade your subscription at any point in time if you would like. When downgrading, it won't take effect until the current cycle ends, ensuring that you won't lose any of the monthly quota before your month is up.
When generating content on our paid plans, you get commercial rights to use that content. If you are on the free plan, you can use the content non-commercially with attribution. Read more about the license in our [Terms of Service](https://elevenlabs.io/terms) and in our Help Center [here](https://help.elevenlabs.io/hc/en-us/articles/13313564601361-Can-I-publish-the-content-I-generate-on-the-platform-).
For more information on payment methods, please refer to the [Help Center](https://help.elevenlabs.io/).
# Usage analytics
Usage analytics lets you view all the activity on the platform for your account or workspace.
To access usage analytics, click on “My Account” in the bottom left corner and select [Usage Analytics](https://elevenlabs.io/app/usage)
<img src="file:4b3e2b4b-0303-447d-a571-3ef30838d99d" alt="Account and Workspace tabs" />
There are two tabs for usage analytics. On an Enterprise plan, the account tab shows data for your individual account, whereas the workspace tab covers all accounts under your workspace.
If you're not on an Enterprise plan, the data will be the same for your account and your workspace, but some information will only be available in your workspace tab, such as your Voice Add/Edit Operations quota.
## Credit usage
In the Credit Usage section, you can filter your usage data in a number of different ways.
In the account tab, you can break your usage down by voice, product or API key, for example.
In the workspace you have additional options allowing you to break usage down by individual user or workspace group.
You can view the data by day, week, month or cumulatively. If you want to be more specific, you can use filters to show only your usage for specific voices, products or API keys.
This feature is quite powerful, allowing you to gain great insights into your usage or understand your customers' usage if you've implemented us in your product.
<img src="file:d2a27dd8-19e5-4ece-9bb2-e4d8a640a1ba" alt="Credit use broken down by voice" />
## API requests
In the API Requests section, you'll find not only the total number of requests made within a specific timeframe but also the number of concurrent requests during that period.
You can view data by different time periods, for example, hour, day, month and year, and at different levels of granularity.
<img src="file:cb876bdb-913d-4570-9d0b-d6e471dd5a5d" alt="Workspace API calls" />
## Export data
You also have the option to export your usage data as a CSV file. To do this, just click the "Export as CSV" button, and the data from your current view will be exported and downloaded.
<img src="file:741e11a8-75c0-4c42-aa0b-0424cdf09204" alt="Export your usage data as CSV" />
# Workspaces
> An overview on how teams can collaborate in a shared workspace.
<img src="file:d1e618d6-95da-42c8-9782-93097172a00c" alt="Workspaces" />
<Info>
Workspaces are currently only available for Enterprise customers. To upgrade, [get in touch with
our sales team](https://elevenlabs.io/contact-sales).
</Info>
## Overview
For teams that want to collaborate in ElevenLabs, we offer shared workspaces. Workspaces offer the folowing benefits:
* **Shared billing** - Rather than having each of your team members individually create & manage subscriptions, all of your team’s character usage and billing is centralized under one workspace.
* **Shared resources** - Within a workspace, your team can share: voices, studio instances, conversational AI agents, dubbings and more.
* **Access management** - Your workspace admin can easily add and remove team members.
* **API Key management** - You can issue and revoke unlimited API keys for your team.
## FAQ
<AccordionGroup>
<Accordion title="How do I create a workspace?">
### Creating a workspace
Workspaces are automatically enabled for all Enterprise clients. When setting up your account, you’ll be asked to nominate a workspace admin who will have the power to add more team members as well as nominate others to be an admin.
</Accordion>
<Accordion title="How do I add a team member to a workspace?">
### Adding a team member to a workspace
<Info>
Only administrators can add and remove team members.
</Info>
<Frame>
<img src="file:95d1997d-8547-4b6f-a112-3884c79c3499" alt="Workspace domain verification" />
</Frame>
Once you are logged in, select your profile in the bottom left of the dashboard and choose Workspace Settings and then navigate to the "Members" tab. From there you’ll be able to add team members, assign roles and remove members from the workspace.
</Accordion>
<Accordion title="What roles can I assign members?">
### Roles
There are two roles, Admins and Members. Members have full access to your workspace and can generate an unlimited number of characters (within your current overall plan’s limit).
Admins have all of the access of Members, with the added ability to add/remove teammates and permissions to manage your subscription.
</Accordion>
<Accordion title="How do I manage billing?">
### Managing Billing
<Info>
Only admins can manage billing.
</Info>
To manage your billing, select your profile in the bottom left of the dashboard and choose "Subscription". From there, you’ll be able to update your payment information and access past invoices.
</Accordion>
<Accordion title="How do I manage API keys?">
### Managing API Keys
To manage workspace API keys, select your profile in the bottom left of the dashboard and choose "Workspace settings". Navigate to the "API keys" tab and you’ll be able to issue & revoke API keys.
</Accordion>
</AccordionGroup>
# Single Sign-On (SSO)
> An overview on how to set up SSO for your workspace.
<img src="file:00a63c50-3297-477c-910b-816059752c22" alt="SSO" />
## Overview
<Info>
Only workspace admins can use this feature.
</Info>
Single Sign-On (SSO) allows your team to log in to ElevenLabs by using your existing identity provider. This allows your team to use the same credentials they use for other services to log in to ElevenLabs.
## Guide
<Steps>
<Step title="Access your SSO settings">
Click on your profile icon located at the bottom left of the dashboard, select "Workspace settings", and then navigate to the "Security & SSO" tab.
</Step>
<Step title="Choose identity providers">
You can choose from a variety of pre-configured identity providers, including Google, Apple, GitHub, etc. Custom organization SSO providers will only appear in this list after they have been configured, as shown in the "SSO Provider" section.
</Step>
<Step title="Verify your email domain">
Next, you need to verify your email domain for authentication. This lets ElevenLabs know that you own the domain you are configuring for SSO. This is a security measure to prevent unauthorized access to your workspace.
Click the "Verify domain" button and enter the domain name you want to verify. After completing this step, click on the domain pending verification. You will be prompted to add a DNS TXT record to your domain's DNS settings. Once the DNS record has been added, click on the "Verify" button.
</Step>
<Step title="Configure SSO">
If you want to configure your own SSO provider, select the SSO provider dropdown to select between OIDC (OpenID Connect) and SAML (Security Assertion Markup Language). Note that only Service Provider (SP) initiated SSO is supported for SAML.
Once you've filled out the required fields, click the "Update SSO" button to save your changes.
<Warning>
Configuring a new SSO provider will log out all workspace members currently logged in with SSO.
</Warning>
</Step>
</Steps>
## FAQ
<AccordionGroup>
<Accordion title="Microsoft Entra Identifier / Azure AD - SAML">
What shall I fill for Identifier (Entity ID)?
* Use Service Provider Entity Id
What shall I fill for Reply URL (Assertion Consumer Service) URL in SAML?
* Use Redirect URL
What is ACS URL?
* Same as Assertion Consumer Service URL
Which fields should I use to provide ElevenLabs?
* Use *Microsoft Entra Identifier* for IdP Entity ID
* Use *Login URL* for IdP Sign-In URL
</Accordion>
<Accordion title="Okta - SAML">
What shall I fill for Audience Restriction?
* Use Service Provider Entity Id
What shall I fill for Single Sign-On URL/Recipient URL/Destination URL?
* Use Redirect URL
Which fields should I use to provide ElevenLabs?
* Use Issuer for IdP Entity ID
* Use Single Sign-On URL for IdP Sign-In URL
</Accordion>
<Accordion title="OneLogin - SAML">
* Please fill Recipient field with the value of Redirect URL.
</Accordion>
<Accordion title="I am getting the error 'Unable to login with saml.workspace...'">
* One known error: Inside the `<saml:Subject>` field of the SAML response, make sure `<saml:NameID>` is set to the email address of the user.
</Accordion>
</AccordionGroup>
# Sharing resources
> An overview on how to share resources within a workspace.
<img src="file:4055b042-87c9-4eb1-8a07-76935d8522f8" alt="Sharing a project" />
## Overview
If your subscription plan includes multiple seats, you can share resources with your members. Resources you
can share include: voices, conversational AI agents, studio projects and more. Check the
[Workspaces API](/docs/api-reference/workspace/share-workspace-resource) for an up-to-date list of resources you can share.
## Sharing
You can share a **resource** with a **principal**. A principal is one of the following:
* A user
* A user group
* A workspace API key
A resource can be shared with at most 100 principals.
Workspace API keys behave like individual users. They don't have access to anything in the workspace when they are created, but they can be added to resources by resource admins.
## Roles
When you share a resource with a principal, you can assign them a **role**. We support the following roles:
* **Viewer**: Viewers can discover the resource and its contents. They can also "use" the resource, e.g., generate TTS with a voice or listen to the audio of a studio instance.
* **Editor**: Everything a viewer can do, plus they can also edit the contents of the resource.
* **Admin**: Everything an editor can do, plus they can also delete the resource and manage sharing permissions.
When you create a resource, you have admin permissions on it. Other resource admins cannot remove your admin permissions on the resources you created.
<Warning>
Workspace admins have admin permissions on all resources in the workspace. This can be removed
from them only by removing their workspace admin role.
</Warning>
# User groups
> An overview on how to create and manage user groups.
<img src="file:6b337356-2dae-4a34-af73-90e4cd63770c" alt="Group Management" />
## Overview
<Info>
Only workspace admins can create, edit, and delete user groups.
</Info>
User groups allow you to manage permissions for multiple users at once.
## Creating a user group
You can create a user group from the workspace settings page. You can then [share resources](docs/product-guides/administration/workspaces/sharing-resources) with the group directly.
If access to a user group is lost, access to resources shared with that group is also lost.
## Multiple groups
User groups cannot be nested, but you can add users to multiple groups. If a user is part of multiple groups, they will have the union of all the permissions of the groups they are part of.
For example, you can create a voice and grant the **Sales** and **Marketing** groups viewer and editor roles on the voice, respectively.
If a user is part of both groups, they will have editor permissions on the voice. Losing access to the **Marketing** group will downgrade the user's permissions to viewer.
## Disabling platform features
Permissions for groups can be revoked for specific product features, such as Professional Voice Cloning or Sound Effects.
To do this, you first have to remove the relevant permissions from the **Everyone** group. Afterwards, enable the permissions for each group that should have access.
# Webhooks
> Enable external integrations by receiving webhook events.
## Overview
Certain events within ElevenLabs can be configured to trigger webhooks, allowing external applications and systems to receive and process these events as they occur. Currently supported event types include:
| Event type                       | Description                                                    |
| -------------------------------- | -------------------------------------------------------------- |
| `post_call_transcription`        | A conversational AI call has finished and analysis is complete |
| `voice_removal_notice`           | A shared voice is scheduled to be removed                      |
| `voice_removal_notice_withdrawn` | A shared voice is no longer scheduled for removal              |
| `voice_removed`                  | A shared voice has been removed and is no longer useable       |
## Configuration
Webhooks can be created, disabled and deleted from the general settings page. For users within [Workspaces](/docs/product-guides/administration/workspaces/overview), only the workspace admins can configure the webhooks for the workspace.
<Frame background="subtle">
![HMAC webhook configuration](file:ea962bfc-1e6e-4363-a680-75f87684b1ef)
</Frame>
After creation, the webhook can be selected to listen for events within product settings such as [Conversational AI](/docs/conversational-ai/customization/personalization/post-call-webhooks).
Webhooks can be disabled from the general settings page at any time. Webhooks that repeatedly fail are auto disabled if there are 10 or more consecutive failures and the last successful delivery was more than 7 days ago or has never been successfully delivered. Auto-disabled webhooks require re-enabling from the settings page. Webhooks can be deleted if not in use by any products.
## Integration
To integrate with webhooks, the listener should create an endpoint handler to receive the webhook event data POST requests. After validating the signature, the handler should quickly return HTTP 200 to indicate successful receipt of the webhook event, repeat failure to correctly return may result in the webhook becoming automatically disabled.
Each webhook event is dispatched only once, refer to the [API](/docs/api-reference/introduction) for methods to poll and get product specific data.
### Top-level fields
| Field             | Type   | Description              |
| ----------------- | ------ | ------------------------ |
| `type`            | string | Type of event            |
| `data`            | object | Data for the event       |
| `event_timestamp` | string | When this event occurred |
## Example webhook payload
```json
{
"type": "post_call_transcription",
"event_timestamp": 1739537297,
"data": {
"agent_id": "xyz",
"conversation_id": "abc",
"status": "done",
"transcript": [
{
"role": "agent",
"message": "Hey there angelo. How are you?",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 0,
"conversation_turn_metrics": null
},
{
"role": "user",
"message": "Hey, can you tell me, like, a fun fact about 11 Labs?",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 2,
"conversation_turn_metrics": null
},
{
"role": "agent",
"message": "I do not have access to fun facts about Eleven Labs. However, I can share some general information about the company. Eleven Labs is an AI voice technology platform that specializes in voice cloning and text-to-speech...",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 9,
"conversation_turn_metrics": {
"convai_llm_service_ttfb": {
"elapsed_time": 0.3704247010173276
},
"convai_llm_service_ttf_sentence": {
"elapsed_time": 0.5551181449554861
}
}
}
],
"metadata": {
"start_time_unix_secs": 1739537297,
"call_duration_secs": 22,
"cost": 296,
"deletion_settings": {
"deletion_time_unix_secs": 1802609320,
"deleted_logs_at_time_unix_secs": null,
"deleted_audio_at_time_unix_secs": null,
"deleted_transcript_at_time_unix_secs": null,
"delete_transcript_and_pii": true,
"delete_audio": true
},
"feedback": {
"overall_score": null,
"likes": 0,
"dislikes": 0
},
"authorization_method": "authorization_header",
"charging": {
"dev_discount": true
},
"termination_reason": ""
},
"analysis": {
"evaluation_criteria_results": {},
"data_collection_results": {},
"call_successful": "success",
"transcript_summary": "The conversation begins with the agent asking how Angelo is, but Angelo redirects the conversation by requesting a fun fact about 11 Labs. The agent acknowledges they don't have specific fun facts about Eleven Labs but offers to provide general information about the company. They briefly describe Eleven Labs as an AI voice technology platform specializing in voice cloning and text-to-speech technology. The conversation is brief and informational, with the agent adapting to the user's request despite not having the exact information asked for."
},
"conversation_initiation_client_data": {
"conversation_config_override": {
"agent": {
"prompt": null,
"first_message": null,
"language": "en"
},
"tts": {
"voice_id": null
}
},
"custom_llm_extra_body": {},
"dynamic_variables": {
"user_name": "angelo"
}
}
}
}
```
## Authentication
It is important for the listener to validate all incoming webhooks. Webhooks currently support authentication via HMAC signatures. Set up HMAC authentication by:
* Securely storing the shared secret generated upon creation of the webhook
* Verifying the ElevenLabs-Signature header in your endpoint using the shared secret
The ElevenLabs-Signature takes the following format:
```json
t=timestamp,v0=hash
```
The hash is equivalent to the hex encoded sha256 HMAC signature of `timestamp.request_body`. Both the hash and timestamp should be validated, an example is shown here:
<Tabs>
<Tab title="Python">
Example python webhook handler using FastAPI:
```python
from fastapi import FastAPI, Request
import time
import hmac
from hashlib import sha256
app = FastAPI()
# Example webhook handler
@app.post("/webhook")
async def receive_message(request: Request):
payload = await request.body()
headers = request.headers.get("elevenlabs-signature")
if headers is None:
return
timestamp = headers.split(",")[0][2:]
hmac_signature = headers.split(",")[1]
# Validate timestamp
tolerance = int(time.time()) - 30 * 60
if int(timestamp) < tolerance
return
# Validate signature
full_payload_to_sign = f"{timestamp}.{payload.decode('utf-8')}"
mac = hmac.new(
key=secret.encode("utf-8"),
msg=full_payload_to_sign.encode("utf-8"),
digestmod=sha256,
)
digest = 'v0=' + mac.hexdigest()
if hmac_signature != digest:
return
# Continue processing
return {"status": "received"}
```
</Tab>
<Tab title="JavaScript">
<Tabs>
<Tab title="Express">
Example javascript webhook handler using node express framework:
```javascript
const crypto = require('crypto');
const secret = process.env.WEBHOOK_SECRET;
const bodyParser = require('body-parser');
// Ensure express js is parsing the raw body through instead of applying it's own encoding
app.use(bodyParser.raw({ type: '*/*' }));
// Example webhook handler
app.post('/webhook/elevenlabs', async (req, res) => {
const headers = req.headers['ElevenLabs-Signature'].split(',');
const timestamp = headers.find((e) => e.startsWith('t=')).substring(2);
const signature = headers.find((e) => e.startsWith('v0='));
// Validate timestamp
const reqTimestamp = timestamp * 1000;
const tolerance = Date.now() - 30 * 60 * 1000;
if (reqTimestamp < tolerance) {
res.status(403).send('Request expired');
return;
} else {
// Validate hash
const message = `${timestamp}.${req.body}`;
const digest = 'v0=' + crypto.createHmac('sha256', secret).update(message).digest('hex');
if (signature !== digest) {
res.status(401).send('Request unauthorized');
return;
}
}
// Validation passed, continue processing ...
res.status(200).send();
});
```
</Tab>
<Tab title="Next.js">
Example javascript webhook handler using Next.js API route:
```javascript app/api/convai-webhook/route.js
import { NextResponse } from "next/server";
import type { NextRequest } from "next/server";
import crypto from "crypto";
export async function GET() {
return NextResponse.json({ status: "webhook listening" }, { status: 200 });
}
export async function POST(req: NextRequest) {
const secret = process.env.ELEVENLABS_CONVAI_WEBHOOK_SECRET; // Add this to your env variables
const { event, error } = await constructWebhookEvent(req, secret);
if (error) {
return NextResponse.json({ error: error }, { status: 401 });
}
if (event.type === "post_call_transcription") {
console.log("event data", JSON.stringify(event.data, null, 2));
}
return NextResponse.json({ received: true }, { status: 200 });
}
const constructWebhookEvent = async (req: NextRequest, secret?: string) => {
const body = await req.text();
const signature_header = req.headers.get("ElevenLabs-Signature");
console.log(signature_header);
if (!signature_header) {
return { event: null, error: "Missing signature header" };
}
const headers = signature_header.split(",");
const timestamp = headers.find((e) => e.startsWith("t="))?.substring(2);
const signature = headers.find((e) => e.startsWith("v0="));
if (!timestamp || !signature) {
return { event: null, error: "Invalid signature format" };
}
// Validate timestamp
const reqTimestamp = Number(timestamp) * 1000;
const tolerance = Date.now() - 30 * 60 * 1000;
if (reqTimestamp < tolerance) {
return { event: null, error: "Request expired" };
}
// Validate hash
const message = `${timestamp}.${body}`;
if (!secret) {
return { event: null, error: "Webhook secret not configured" };
}
const digest =
"v0=" + crypto.createHmac("sha256", secret).update(message).digest("hex");
console.log({ digest, signature });
if (signature !== digest) {
return { event: null, error: "Invalid signature" };
}
const event = JSON.parse(body);
return { event, error: null };
};
```
</Tab>
</Tabs>
</Tab>
</Tabs>
# Libraries & SDKs
> Explore language-specific libraries for using the ElevenLabs API.
## Official REST API libraries
ElevenLabs provides officially supported libraries that are updated with the latest features available in the [REST API](/docs/api-reference/introduction).
| Language          | GitHub                                                           | Package Manager                                 |
| ----------------- | ---------------------------------------------------------------- | ----------------------------------------------- |
| Python            | [GitHub README](https://github.com/elevenlabs/elevenlabs-python) | [PyPI](https://pypi.org/project/elevenlabs/)    |
| Javascript (Node) | [GitHub README](https://github.com/elevenlabs/elevenlabs-js)     | [npm](https://www.npmjs.com/package/elevenlabs) |
Test and explore all ElevenLabs API endpoints using our official [Postman collection](https://www.postman.com/elevenlabs/elevenlabs/collection/7i9rytu/elevenlabs-api-documentation?action=share\&creator=39903018).
## Conversational AI libraries
These libraries are designed for use with ElevenLabs [Conversational AI](/docs/conversational-ai/overview).
| Language   | Documentation                                         | Package Manager                                         |
| ---------- | ----------------------------------------------------- | ------------------------------------------------------- |
| Javascript | [Docs](/docs/conversational-ai/libraries/java-script) | [npm](https://www.npmjs.com/package/@11labs/client)     |
| React      | [Docs](/docs/conversational-ai/libraries/react)       | [npm](https://www.npmjs.com/package/@11labs/react)      |
| Python     | [Docs](/docs/conversational-ai/libraries/python)      | [PyPI](https://pypi.org/project/elevenlabs/)            |
| Swift      | [Docs](/docs/conversational-ai/libraries/swift)       | [Github](https://github.com/elevenlabs/ElevenLabsSwift) |
# Error messages
> Explore error messages and solutions.
This guide includes an overview of error messages you might see in the ElevenLabs dashboard & API.
## Dashboard errors
| Error Message                                          | Cause                                                                                                     | Solution                                                                                                                                                        |
| ------------------------------------------------------ | --------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| The selected model can not be used for text-to-speech. | Occurs when switching between speech-to-speech and text-to-speech if the model does not switch correctly. | Select the desired model. If unresolved, select a different model, then switch back.                                                                            |
| Oops, something went wrong.                            | Indicates a client-side error, often due to device or browser issues.                                     | Click “Try again” or refresh the page. If unresolved, clear browser cache and cookies. Temporarily pause browser-based translation tools like Google Translate. |
<Note>
If error messages persist after following these solutions, please [contact our support
team](https://help.elevenlabs.io/hc/en-us/requests/new?ticket_form_id=13145996177937) for further
assistance.
</Note>
## API errors
### Code 400/401
| Code                                   | Overview                                                                                                                                                                                                    |
| -------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| max\_character\_limit\_exceeded <br /> | **Cause:** You are sending too many characters in a single request. <br /> **Solution:** Split the request into smaller chunks, see [character limits](/docs/models#character-limits) for more information. |
| invalid\_api\_key                      | **Cause:** You have not set your API key correctly. <br /> **Solution:** Ensure the request is correctly authenticated. See [authentication](/docs/api-reference/authentication) for more information.      |
| quota\_exceeded                        | **Cause:** You have insufficient quota to complete the request. <br /> **Solution:** On the Creator plan and above, you can enable usage-based billing from your Subscription page.                         |
| voice\_not\_found                      | **Cause:** You have entered the incorrect voice\_id. <br /> **Solution:** Check that you are using the correct voice\_id for the voice you want to use. You can verify this in My Voices.                   |
### Code 403
| Code                | Overview                                                                                                                                                                    |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| only\_for\_creator+ | **Cause:** You are trying to use professional voices on a free or basic subscription. <br /> **Solution:** Upgrade to Creator tier or higher to access professional voices. |
### Code 429
| Code                                   | Overview                                                                                                                                                                                                                                                                               |
| -------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| too\_many\_concurrent\_requests <br /> | **Cause:** You have exceeded the concurrency limit for your subscription. <br /> **Solution:** See [concurrency limits and priority](/docs/models#concurrency-and-priority) for more information.                                                                                      |
| system\_busy                           | **Cause:** Our services are experiencing high levels of traffic and your request could not be processed. <br /> **Solution:** Retry the request later, with exponential backoff. Consider upgrading your subscription to get [higher priority](/docs/models#concurrency-and-priority). |
<Note>
If error messages persist after following these solutions, please [contact our support
team](https://help.elevenlabs.io/hc/en-us/requests/new?ticket_form_id=13145996177937) for further
assistance.
</Note>
# Troubleshooting
> Explore common issues and solutions.
Our models are non-deterministic, meaning outputs can vary based on inputs. While we strive to enhance predictability, some variability is inherent. This guide outlines common issues and preventive measures.
## General
<AccordionGroup>
<Accordion title="Inconsistencies in volume and quality">
If the generated voice output varies in volume or tone, it is often due to inconsistencies in the voice clone training audio.
* **Apply compression**: Compress the training audio to reduce dynamic range and ensure consistent audio. Aim for a RMS between -23 dB and -18 dB and the true peak below -3 dB.
* **Background noise**: Ensure the training audio contains only the voice you want to clone — no music, noise, or pops. Background noise, sudden bursts of energy or consistent low-frequency energy can make the AI less stable.
* **Speaker consistency**: Ensure the speaker maintains a consistent distance from the microphone and avoids whispering or shouting. Variations can lead to inconsistent volume or tonality.
* **Audio length**:
* **Instant Voice Cloning**: Use 1–2 minutes of consistent audio. Consistency in tonality, performance, accent, and quality is crucial.
* **Professional Voice Cloning**: Use at least 30 minutes, ideally 2+ hours, of consistent audio for best results.
To minimize issues, consider breaking your text into smaller segments. This approach helps maintain consistent volume and reduces degradation over longer audio generations. Utilize our Studio feature to generate several smaller audio segments simultaneously, ensuring better quality and consistency.
<Note>
Refer to our guides for optimizing Instant and Professional Voice Clones for best practices and
advice.
</Note>
</Accordion>
<Accordion title="Mispronunciation">
The multilingual models may rarely mispronounce certain words, even in English. This issue appears to be somewhat arbitrary but seems to be voice and text-dependent. It occurs more frequently with certain voices and text, especially when using words that also appear in other languages.
* **Use Studio**: This feature helps minimize mispronunciation issues, which are more prevalent in longer text sections when using Speech Synthesis. While it won't completely eliminate the problem, it can help avoid it and make it easier to regenerate specific sections without redoing the entire text.
* **Properly cloned voices**: Similar to addressing inconsistency issues, using a properly cloned voice in the desired languages can help reduce mispronunciation.
* **Specify pronunciation**: When using our Studio feature, consider specifying the pronunciation of certain words, such as character names and brand names, or how acronyms should be read. For more information, refer to the Pronunciation Dictionary section of our guide to Studio.
</Accordion>
<Accordion title="Language switching and accent drift">
The AI can sometimes switch languages or accents throughout a single generation, especially if that generation is longer in length. This issue is similar to the mispronunciation problem and is something we are actively working to improve.
* **Use properly cloned voices**: Using an Instant Voice Clone or a Professional Voice Clone trained on high-quality, consistent audio in the desired language can help mitigate this issue. Pairing this with the Studio feature can further enhance stability.
* **Understand voice limitations**: Default and generated voices are primarily English and may carry an English accent when used for other languages. Cloning a voice that speaks the target language with the desired accent provides the AI with better context, reducing the likelihood of language switching.
* **Language selection**: Currently, the AI determines the language based on the input text. Writing in the desired language is crucial, especially when using pre-made voices that are English-based, as they may introduce an English accent.
* **Optimal text length**: The AI tends to maintain a consistent accent over shorter text segments. For best results, keep text generations under 800-900 characters when using Text-to-Speech. The Studio workflow can help manage longer texts by breaking them into smaller, more manageable segments.
</Accordion>
<Accordion title="Mispronounced numbers, symbols or acronyms">
The models may mispronounce certain numbers, symbols and acronyms. For example, the numbers "1, 2, 3" might be pronounced as "one," "two," "three" in English. To ensure correct pronunciation in another language, write them out phonetically or in words as you want them to be spoken.
* **Example**: For the number "1" to be pronounced in French, write "un."
* **Symbols**: Specify how symbols should be read, e.g., "\$" as "dollar" or "euro."
* **Acronyms**: Spell out acronyms phonetically.
</Accordion>
<Accordion title="Corrupt speech">
Corrupt speech is a rare issue where the model generates muffled or distorted audio. This occurs
unpredictably, and we have not identified a cause. If encountered, regenerate the section to
resolve the issue.
</Accordion>
<Accordion title="Audio degradation over longer generations">
Audio quality may degrade during extended text-to-speech conversions, especially with the Multilingual v1 model. To mitigate this, break text into sections under 800 characters.
* **Voice Selection**: Some voices are more susceptible to degradation. Use high-quality samples for cloned voices to minimize artifacts.
* **Stability and Similarity**: Adjust these settings to influence voice behavior and artifact prominence. Hover over each setting for more details.
</Accordion>
<Accordion title="Style exaggeration">
For some voices, this voice setting can lead to instability, including inconsistent speed,
mispronunciation and the addition of extra sounds. We recommend keeping this setting at 0,
especially if you find you are experiencing these issues in your generated audio.
</Accordion>
</AccordionGroup>
## Studio (formerly Projects)
<AccordionGroup>
<Accordion title="File imports">
The import function attempts to import the file you provide to the website. Given the variability in website structures and book formatting, including images, always verify the import for accuracy.
* **Chapter images**: If a book's chapters start with an image as the first letter, the AI may not recognize the letter. Manually add the letter to each chapter.
* **Paragraph structure**: If text imports as a single long paragraph instead of following the original book's structure, it may not function correctly. Ensure the text maintains its original line breaks. If issues persist, try copying and pasting. If this fails, the text format may need conversion or rewriting.
* **Preferred format**: EPUB is the recommended file format for creating a project in Studio. A well-structured EPUB will automatically split each chapter in Studio, facilitating navigation. Ensure each chapter heading is formatted as "Heading 1" for proper recognition.
<Note>
Always double-check imported content for accuracy and structure.
</Note>
</Accordion>
<Accordion title="Glitches between paragraphs">
Occasionally, glitches or sharp breaths may occur between paragraphs. This is rare and differs
from standard Text to Speech issues. If encountered, regenerate the preceding paragraph, as the
problem often originates there.
</Accordion>
</AccordionGroup>
<Note>
If an issue persists after following this troubleshooting guide, please [contact our support
team](https://help.elevenlabs.io/hc/en-us/requests/new?ticket_form_id=13145996177937).
</Note>
# Zero Retention Mode (Enterprise)
> Learn how to use Zero Retention Mode to protect sensitive data.
## Background
By default, we retain data, in accordance with our Privacy Policy, to enhance our services, troubleshoot issues, and ensure the security of our systems. However, for some enterprise customers, we offer a "Zero Retention Mode" option for specific products. In this Zero Retention Mode, most data in requests and responses are immediately deleted once the request is completed.
## What is Zero Retention Mode?
Zero Retention Mode provides an additional level of security and peace of mind for especially sensitive workflows. When enabled, logging of certain data points is restricted, including:
* TTS text input
* TTS audio output
* Voice Changer audio input
* Voice Changer audio output
* STT audio input
* STT text output
* Conversational AI all input and output
* Email associated with the account generating the input in our logs
This data is related to the processing of the request, and can only be seen by the user doing the request and the volatile memory of the process serving the request. None of this data is sent at any point to a database where data is stored long term.
## Who has access to Zero Retention Mode?
Enterprise customers can use Zero Retention Mode. It is primarily intended for use by our customers in the healthcare and banking sector, and other customers who may use our services to process sensitive information.
## When can a customer use Zero Retention Mode?
Zero Retention Mode is available to select enterprise customers. However, access to this feature may be restricted if ElevenLabs determines a customer's use case to be high risk, if an account is flagged by an automated system for additional moderation or at ElevenLabs' sole discretion. In such cases, the enterprise administrator will be promptly notified of the restriction.
## How does Zero Retention Mode work?
Zero Retention Mode only works for API requests, specifically:
* **Text to Speech**: this covers the Text-to-Speech (TTS) API, including all endpoints beginning with `/v1/text-to-speech/` and the TTS websocket connection.
* **Voice Changer**: this covers the Voice Changer API, including all endpoints starting with `/v1/speech-to-speech/`.
After setup, check the request history to verify Zero Retention Mode is enabled. If enabled, there should be no requests in the history.
Zero Retention Mode can be used by sending `enable_logging=false` with the product which supports it.
For example, in the Text to Speech API, you can set the query parameter [enable\_logging](https://elevenlabs.io/docs/api-reference/text-to-speech#parameter-enable-logging) to a `false` value:
<CodeBlocks>
```python title="Python" {12}
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
response = client.text_to_speech.convert(
voice_id=voice_id,
output_format="mp3_22050_32",
text=text,
model_id="eleven_turbo_v2",
enable_logging=False,
)
```
```javascript title="JavaScript" {9}
import { ElevenLabsClient } from 'elevenlabs';
const client = new ElevenLabsClient({ apiKey: 'YOUR_API_KEY' });
await client.textToSpeech.convert(voiceId, {
output_format: 'mp3_44100_128',
text: text,
model_id: 'eleven_turbo_v2',
enable_logging: false,
});
```
```bash title="cURL"
curl --request POST \
--url 'https://api.elevenlabs.io/v1/text-to-speech/{voice_id}?enable_logging=false' \
--header 'Content-Type: application/json'
```
</CodeBlocks>
## What products are configured for Zero Retention Mode?
| Product                    | Type                 | Default Retention | Eligible for zero Retention |
| -------------------------- | -------------------- | ----------------- | --------------------------- |
| Text to Speech             | Text Input           | Enabled           | Yes                         |
|                            | Audio Output         | Enabled           | Yes                         |
| Voice Changer              | Audio Input          | Enabled           | Yes                         |
|                            | Audio Output         | Enabled           | Yes                         |
| Speech to Text             | Audio Input          | Enabled           | On request                  |
|                            | Text Output          | Enabled           | On request                  |
| Instant Voice Cloning      | Audio Samples        | Enabled           | No                          |
| Professional Voice Cloning | Audio Samples        | Enabled           | No                          |
| Dubbing                    | Audio/Video Input    | Enabled           | No                          |
|                            | Audio Output         | Enabled           | No                          |
| Projects                   | Text Input           | Enabled           | No                          |
|                            | Audio Output         | Enabled           | No                          |
| Conv AI                    | All Input and Output | Enabled           | Yes                         |
## FAQ
<AccordionGroup>
<Accordion title="What are some limitations of Zero Retention Mode?" default>
Troubleshooting and support for Zero Retention Mode is limited. Because of the configuration, we
will not be able to diagnose issues with TTS/STS generations. Debugging will be more difficult
as a result.
</Accordion>
<Accordion title="How does retention work if Zero Retention Mode is not active?">
Customers by default have history preservation enabled. All customers can use the API to delete
generations at any time. This action will immediately remove the corresponding audio and text
from our database; however, debugging and moderation logs may still retain data related to the
generation.
</Accordion>
<Accordion title="Data backup (When Zero Retention Mode is not used)">
For any retained data, we regularly back up such data to prevent data loss in the event of any
unexpected incidents. Following data deletion, database items are retained in backups for up to
30 days After this period, the data expires and is not recoverable.
</Accordion>
<Accordion title="Account deletion (When Zero Retention Mode is not used)">
All data is deleted from our systems permanently when you delete your account. This includes all
data associated with your account, such as API keys, request history, and any other data stored
in your account. We also take commercially reasonable efforts to delete debugging data related
to your account.
</Accordion>
</AccordionGroup>
# Conversational AI overview
> Deploy customized, conversational voice agents in minutes.
<div>
<iframe src="https://player.vimeo.com/video/1029660636" frameBorder="0" allow="autoplay; fullscreen; picture-in-picture" allowFullScreen />
</div>
## What is Conversational AI?
ElevenLabs [Conversational AI](https://elevenlabs.io/conversational-ai) is a platform for deploying customized, conversational voice agents. Built in response to our customers' needs, our platform eliminates months of development time typically spent building conversation stacks from scratch. It combines these building blocks:
<CardGroup cols={2}>
<Card title="Speech to text">
Our fine tuned ASR model that transcribes the caller's dialogue.
</Card>
<Card title="Language model">
Choose from Gemini, Claude, OpenAI and more, or bring your own.
</Card>
<Card title="Text to speech">
Our low latency, human-like TTS across 5k+ voices and 31 languages.
</Card>
<Card title="Turn taking">
Our custom turn taking and interruption detection service that feels human.
</Card>
</CardGroup>
Altogether it is a highly composable AI Voice agent solution that can scale to thousands of calls per day. With [server](/docs/conversational-ai/customization/tools) & [client side](/docs/conversational-ai/customization/tools-events/client-tools) tools, [knowledge](/docs/conversational-ai/customization/knowledge-base) bases, [dynamic](/docs/conversational-ai/customization/personalization/dynamic-variables) agent instantiation and [overrides](/docs/conversational-ai/customization/overrides), plus built-in monitoring, it's the complete developer toolkit.
<Card title="Pricing" horizontal>
15 minutes to get started on the free plan. Get 13,750 minutes included on the Business plan at
\$0.08 per minute on the Business plan, with extra minutes billed at \$0.08, as well as
significantly discounted pricing at higher volumes.
<br />
**Setup & Prompt Testing**: billed at half the cost.
</Card>
<Note>
Usage is billed to the account that created the agent. If authentication is not enabled, anybody
with your agent's id can connect to it and consume your credits. To protect against this, either
enable authentication for your agent or handle the agent id as a secret.
</Note>
## Pricing tiers
<Tabs>
<Tab title="In Minutes">
| Tier     | Price   | Minutes included | Cost per extra minute              |
| -------- | ------- | ---------------- | ---------------------------------- |
| Free     | \$0     | 15               | Unavailable                        |
| Starter  | \$5     | 50               | Unavailable                        |
| Creator  | \$22    | 250              | \~\$0.12                           |
| Pro      | \$99    | 1100             | \~\$0.11                           |
| Scale    | \$330   | 3,600            | \~\$0.10                           |
| Business | \$1,320 | 13,750           | \$0.08 (annual), \$0.096 (monthly) |
</Tab>
<Tab title="In Credits">
| Tier     | Price   | Credits included | Cost in credits per extra minute |
| -------- | ------- | ---------------- | -------------------------------- |
| Free     | \$0     | 10,000           | Unavailable                      |
| Starter  | \$5     | 30,000           | Unavailable                      |
| Creator  | \$22    | 100,000          | 400                              |
| Pro      | \$99    | 500,000          | 454                              |
| Scale    | \$330   | 2,000,000        | 555                              |
| Business | \$1,320 | 11,000,000       | 800                              |
</Tab>
</Tabs>
<Note>
Today we're covering the LLM costs, though these will be passed through to customers in the
future.
</Note>
## Models
Currently, the following models are natively supported and can be configured via the agent settings:
* Gemini 2.0 Flash
* Gemini 1.5 Flash
* Gemini 1.5 Pro
* Gemini 1.0 Pro
* GPT-4o Mini
* GPT-4o
* GPT-4 Turbo
* GPT-3.5 Turbo
* Claude 3.5 Sonnet
* Claude 3 Haiku
![Supported models](file:0c000211-111e-476c-accc-2ae205985fdf)
You can start with our [free tier](https://elevenlabs.io/app/sign-up), which includes 15 minutes of conversation per month.
Need more? Upgrade to a [paid plan](https://elevenlabs.io/pricing/api) instantly - no sales calls required. For enterprise usage (6+ hours of daily conversation), [contact our sales team](https://elevenlabs.io/contact-sales) for custom pricing tailored to your needs.
## Popular applications
Companies and creators use our Conversational AI orchestration platform to create:
* **Customer service**: Assistants trained on company documentation that can handle customer queries, troubleshoot issues, and provide 24/7 support in multiple languages.
* **Virtual assistants**: Assistants trained to manage scheduling, set reminders, look up information, and help users stay organized throughout their day.
* **Retail support**: Assistants that help customers find products, provide personalized recommendations, track orders, and answer product-specific questions.
* **Personalized learning**: Assistants that help students learn new topics & enhance reading comprehension by speaking with books and [articles](https://elevenlabs.io/blog/time-brings-conversational-ai-to-journalism).
<Note>
Ready to get started? Check out our [quickstart guide](/docs/conversational-ai/quickstart) to
create your first AI agent in minutes.
</Note>
## FAQ
<AccordionGroup>
<Accordion title="Concurrency limits">
Plan limits
Your subscription plan determines how many calls can be made simultaneously.
| Plan       | Concurrency limit |
| ---------- | ----------------- |
| Free       | 4                 |
| Starter    | 6                 |
| Creator    | 10                |
| Pro        | 20                |
| Scale      | 30                |
| Business   | 30                |
| Enterprise | Elevated          |
<Note>
To increase your concurrency limit [upgrade your subscription plan](https://elevenlabs.io/pricing/api)
or [contact sales](https://elevenlabs.io/contact-sales) to discuss enterprise plans.
</Note>
</Accordion>
<Accordion title="Supported audio formats">
The following audio output formats are supported in the Conversational AI platform:
* PCM (8 kHz / 16 kHz / 22.05 kHz / 24 kHz / 44.1 kHz)
* μ-law 8000Hz
</Accordion>
</AccordionGroup>
# Quickstart
> Build your first conversational AI voice agent in 5 minutes.
In this guide, you'll learn how to create your first Conversational AI voice agent. This will serve as a foundation for building conversational workflows tailored to your business use cases.
## Getting started
Conversational AI agents are managed through the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai). This is used to:
* Create and manage AI assistants
* Configure voice settings and conversation parameters
* Equip the agent with [tools](/docs/conversational-ai/customization/tools) and a [knowledge base](/docs/conversational-ai/customization/knowledge-base)
* Review conversation analytics and transcripts
* Manage API keys and integration settings
<Note>
The web dashboard uses our [Web SDK](/docs/conversational-ai/libraries/react) under the hood to
handle real-time conversations.
</Note>
<Tabs>
<Tab title="Build a support agent">
## Overview
In this guide, we'll create a conversational support assistant capable of answering questions about your product, documentation, or service. This assistant can be embedded into your website or app to provide real-time support to your customers.
<Frame caption="The assistant at the bottom right corner of this page is capable of answering questions about ElevenLabs, navigating pages & taking you to external resources." background="subtle">
![Conversational AI widget](file:3e8c825a-7c14-4a69-a729-955c77a8df92)
</Frame>
### Prerequisites
* An [ElevenLabs account](https://www.elevenlabs.io)
### Assistant setup
<Steps>
<Step title="Sign in to ElevenLabs">
Go to [elevenlabs.io](https://elevenlabs.io/sign-up) and sign in to your account.
</Step>
<Step title="Create a new assistant">
In the **ElevenLabs Dashboard**, create a new assistant by entering a name and selecting the `Blank template` option.
<Frame caption="Creating a new assistant" background="subtle">
![Dashboard](file:bddd9ab9-ebca-430c-a005-30223d5f06c4)
</Frame>
</Step>
<Step title="Configure the assistant behavior">
Go to the **Agent** tab to configure the assistant's behavior. Set the following:
<Steps>
<Step title="First message">
This is the first message the assistant will speak out loud when a user starts a conversation.
```plaintext First message
Hi, this is Alexis from <company name> support. How can I help you today?
```
</Step>
<Step title="System prompt">
This prompt guides the assistant's behavior, tasks, and personality.
Customize the following example with your company details:
```plaintext System prompt
You are a friendly and efficient virtual assistant for [Your Company Name]. Your role is to assist customers by answering questions about the company's products, services, and documentation. You should use the provided knowledge base to offer accurate and helpful responses.
Tasks:
- Answer Questions: Provide clear and concise answers based on the available information.
- Clarify Unclear Requests: Politely ask for more details if the customer's question is not clear.
Guidelines:
- Maintain a friendly and professional tone throughout the conversation.
- Be patient and attentive to the customer's needs.
- If unsure about any information, politely ask the customer to repeat or clarify.
- Avoid discussing topics unrelated to the company's products or services.
- Aim to provide concise answers. Limit responses to a couple of sentences and let the user guide you on where to provide more detail.
```
</Step>
</Steps>
</Step>
<Step title="Add a knowledge base">
Go to the **Knowledge Base** section to provide your assistant with context about your business.
This is where you can upload relevant documents & links to external resources:
* Include documentation, FAQs, and other resources to help the assistant respond to customer inquiries.
* Keep the knowledge base up-to-date to ensure the assistant provides accurate and current information.
</Step>
</Steps>
### Configure the voice
<Steps>
<Step title="Select a voice">
In the **Voice** tab, choose a voice that best matches your assistant from the [voice library](https://elevenlabs.io/community):
<Frame background="subtle">
![Voice settings](file:d04977c1-25e8-4c03-88dd-02faad37faaf)
</Frame>
<Note>
Using higher quality voices, models, and LLMs may increase response time. For an optimal customer experience, balance quality and latency based on your assistant's expected use case.
</Note>
</Step>
<Step title="Testing your assistant">
Press the **Test AI agent** button and try conversing with your assistant.
</Step>
</Steps>
### Analyze and collect conversation data
Configure evaluation criteria and data collection to analyze conversations and improve your assistant's performance.
<Steps>
<Step title="Configure evaluation criteria">
Navigate to the **Analysis** tab in your assistant's settings to define custom criteria for evaluating conversations.
<Frame background="subtle">
![Analysis settings](file:5d0acd27-e6a9-4b5f-9794-a29bd3650952)
</Frame>
Every conversation transcript is passed to the LLM to verify if specific goals were met. Results will either be `success`, `failure`, or `unknown`, along with a rationale explaining the chosen result.
Let's add an evaluation criteria with the name `solved_user_inquiry`:
```plaintext Prompt
The assistant was able to answer all of the queries or redirect them to a relevant support channel.
Success Criteria:
- All user queries were answered satisfactorily.
- The user was redirected to a relevant support channel if needed.
```
</Step>
<Step title="Configure data collection">
In the **Data Collection** section, configure details to be extracted from each conversation.
Click **Add item** and configure the following:
1. **Data type:** Select "string"
2. **Identifier:** Enter a unique identifier for this data point: `user_question`
3. **Description:** Provide detailed instructions for the LLM about how to extract the specific data from the transcript:
```plaintext Prompt
Extract the user's questions & inquiries from the conversation.
```
<Tip>
Test your assistant by posing as a customer. Ask questions, evaluate its responses, and tweak the prompts until you're happy with how it performs.
</Tip>
</Step>
<Step title="View conversation history">
View evaluation results and collected data for each conversation in the **Call history** tab.
<Frame background="subtle">
![Conversation history](file:e0f7c77d-0f0b-42c7-abe5-06be5823c92e)
</Frame>
<Tip>
Regularly review conversation history to identify common issues and patterns.
</Tip>
</Step>
</Steps>
Your assistant is now configured. Embed the widget on your website to start providing real-time support to your customers.
</Tab>
<Tab title="Build a restaurant ordering agent">
## Overview
In this guide, we’ll create a conversational ordering assistant for Pierogi Palace, a Polish restaurant that takes food orders, addressing their challenge of managing high call volumes.
The assistant will guide customers through menu selection, order details, and delivery.
### Prerequisites
* An [ElevenLabs account](https://www.elevenlabs.io)
### Assistant setup
<Steps>
<Step title="Sign in to ElevenLabs">
Go to [elevenlabs.io](https://elevenlabs.io/sign-up) and sign in to your account.
</Step>
<Step title="Create a new assistant">
In the **ElevenLabs Dashboard**, create a new assistant by entering a name and selecting the `Blank template` option.
<Frame caption="Creating a new assistant" background="subtle">
![Dashboard](file:bddd9ab9-ebca-430c-a005-30223d5f06c4)
</Frame>
</Step>
<Step title="Configure the assistant behavior">
Go to the **Agent** tab to configure the assistant's behavior. Set the following:
<Steps>
<Step title="First message">
This is the first message the assistant will speak out loud when a user starts a conversation.
```plaintext First message
Welcome to Pierogi Palace! I'm here to help you place your order. What can I get started for you today?
```
</Step>
<Step title="System prompt">
This prompt guides the assistant's behavior, tasks, and personality:
```plaintext System prompt
You are a friendly and efficient virtual assistant for Pierogi Palace, a modern Polish restaurant specializing in pierogi. It is located in the Zakopane mountains in Poland.
Your role is to help customers place orders over voice conversations. You have comprehensive knowledge of the menu items and their prices.
Menu Items:
- Potato & Cheese Pierogi – 30 Polish złoty per dozen
- Beef & Onion Pierogi – 40 Polish złoty per dozen
- Spinach & Feta Pierogi – 30 Polish złoty per dozen
Your Tasks:
1. Greet the Customer: Start with a warm welcome and ask how you can assist.
2. Take the Order: Listen carefully to the customer's selection, confirm the type and quantity of pierogi.
3. Confirm Order Details: Repeat the order back to the customer for confirmation.
4. Calculate Total Price: Compute the total cost based on the items ordered.
5. Collect Delivery Information: Ask for the customer's delivery address to estimate delivery time.
6. Estimate Delivery Time: Inform the customer that cooking time is 10 minutes plus delivery time based on their location.
7. Provide Order Summary: Give the customer a summary of their order, total price, and estimated delivery time.
8. Close the Conversation: Thank the customer and let them know their order is being prepared.
Guidelines:
- Use a friendly and professional tone throughout the conversation.
- Be patient and attentive to the customer's needs.
- If unsure about any information, politely ask the customer to repeat or clarify.
- Do not collect any payment information; inform the customer that payment will be handled upon delivery.
- Avoid discussing topics unrelated to taking and managing the order.
```
</Step>
</Steps>
</Step>
</Steps>
### Configure the voice
<Steps>
<Step title="Select a voice">
In the **Voice** tab, choose a voice that best matches your assistant from the [voice library](https://elevenlabs.io/community):
<Frame background="subtle">
![Voice settings](file:d04977c1-25e8-4c03-88dd-02faad37faaf)
</Frame>
<Note>
Using higher quality voices, models, and LLMs may increase response time. For an optimal customer experience, balance quality and latency based on your assistant's expected use case.
</Note>
</Step>
<Step title="Testing your assistant">
Press the **Test AI agent** button and try ordering some pierogi.
</Step>
</Steps>
### Analyze and collect conversation data
Configure evaluation criteria and data collection to analyze conversations and improve your assistant's performance.
<Steps>
<Step title="Configure evaluation criteria">
Navigate to the **Analysis** tab in your assistant's settings to define custom criteria for evaluating conversations.
<Frame background="subtle">
![Analysis settings](file:5d0acd27-e6a9-4b5f-9794-a29bd3650952)
</Frame>
Every conversation transcript is passed to the LLM to verify if specific goals were met. Results will either be `success`, `failure`, or `unknown`, along with a rationale explaining the chosen result.
Let's add an evaluation criteria with the name `order_completion`:
```plaintext Prompt
Evaluate if the conversation resulted in a successful order.
Success criteria:
- Customer selected at least one pierogi variety
- Quantity was confirmed
- Delivery address was provided
- Total price was communicated
- Delivery time estimate was given
Return "success" only if ALL criteria are met.
```
</Step>
<Step title="Configure data collection">
In the **Data Collection** section, configure details to be extracted from each conversation.
Click **Add item** and configure the following:
1. **Data type:** Select "string"
2. **Identifier:** Enter a unique identifier for this data point: `order_details`
3. **Description:** Provide detailed instructions for the LLM about how to extract the specific data from the transcript:
```plaintext Prompt
Extract order details from the conversation, including:
- Type of order (delivery, pickup, inquiry_only)
- List of pierogi varieties and quantities ordered in the format: "item: quantity"
- Delivery zone based on the address (central_zakopane, outer_zakopane, outside_delivery_zone)
- Interaction type (completed_order, abandoned_order, menu_inquiry, general_inquiry)
If no order was placed, return "none"
```
<Tip>
Test your assistant by posing as a customer. Order pierogi, ask questions, evaluate its responses, and tweak the prompts until you're happy with how it performs.
</Tip>
</Step>
<Step title="View conversation history">
View evaluation results and collected data for each conversation in the **Call history** tab.
<Frame background="subtle">
![Conversation history](file:e0f7c77d-0f0b-42c7-abe5-06be5823c92e)
</Frame>
<Tip>
Regularly review conversation history to identify common issues and patterns.
</Tip>
</Step>
</Steps>
Your assistant is now configured & ready to take orders.
</Tab>
</Tabs>
## Next steps
<CardGroup cols={2}>
<Card title="Customize your agent" href="/docs/conversational-ai/customization">
Learn how to customize your agent with tools, knowledge bases, dynamic variables and overrides.
</Card>
<Card title="Integration quickstart" href="/docs/conversational-ai/guides/quickstarts">
Learn how to integrate Conversational AI into your app using the SDK for advanced configuration.
</Card>
</CardGroup>
# Conversational AI dashboard
> Monitor and analyze your agents' performance effortlessly.
## Overview
The Agents Dashboard provides real-time insights into your Conversational AI agents. It displays performance metrics over customizable time periods. You can review data for individual agents or across your entire workspace.
## Analytics
You can monitor activity over various daily, weekly, and monthly time periods.
<Frame caption="Dashboard view for Last Day" background="subtle">
<img src="file:e517c242-37cc-4440-8321-f8289b348ff2" alt="Dashboard view showing last day metrics" />
</Frame>
<Frame caption="Dashboard view for Last Month" background="subtle">
<img src="file:ccfb40f9-9714-4e79-8474-e51b533ad8df" alt="Dashboard view showing last month metrics" />
</Frame>
The dashboard can be toggled to show different metrics, including: number of calls, average duration, total cost, and average cost.
## Language Breakdown
A key benefit of Conversational AI is the ability to support multiple languages.
The Language Breakdown section shows the percentage of calls (overall, or per-agent) in each language.
<Frame caption="Language Breakdown" background="subtle">
<img src="file:184226b7-c14e-491b-8012-f30c3d97d757" alt="Language breakdown showing percentage of calls in each language" />
</Frame>
## Active Calls
At the top left of the dashboard, the current number of active calls is displayed. This real-time counter reflects ongoing sessions for your workspace's agents, and is also accessible via the API.
# Client events
> Understand and handle real-time communication events in your conversational applications.
**Client events** are system-level events that facilitate real-time communication between the client and server. These events manage various aspects of the conversation, including audio playback, transcription, interruptions, and more.
## Overview
Client events are essential for maintaining the real-time nature of conversations. They handle everything from initialization to audio playback and user interactions.
<Info>
These events are part of the WebSocket communication protocol and are automatically handled by our
SDKs. Understanding them is crucial for advanced implementations and debugging.
</Info>
## Client event types
<AccordionGroup>
<Accordion title="conversation_initiation_metadata">
* Automatically sent when starting a conversation
* Initializes conversation settings and parameters
```javascript
// Example initialization metadata
{
"type": "conversation_initiation_metadata",
"conversation_initiation_metadata_event": {
"conversation_id": "conv_123",
"agent_output_audio_format": "pcm_44100",  // TTS output format
"user_input_audio_format": "pcm_16000"    // ASR input format
}
}
```
</Accordion>
<Accordion title="ping">
* Health check event requiring immediate response
* Automatically handled by SDK
* Used to maintain WebSocket connection
```javascript
// Example ping event structure
{
"ping_event": {
"event_id": 123456,
"ping_ms": 50  // Optional, estimated latency in milliseconds
},
"type": "ping"
}
```
```javascript
// Example ping handler
websocket.on('ping', () => {
websocket.send('pong');
});
```
</Accordion>
<Accordion title="audio">
* Contains base64 encoded audio for playback
* Includes numeric event ID for tracking and sequencing
* Handles voice output streaming
```javascript
// Example audio event structure
{
"audio_event": {
"audio_base_64": "base64_encoded_audio_string",
"event_id": 12345
},
"type": "audio"
}
```
```javascript
// Example audio event handler
websocket.on('audio', (event) => {
const { audio_event } = event;
const { audio_base_64, event_id } = audio_event;
audioPlayer.play(audio_base_64);
});
```
</Accordion>
<Accordion title="user_transcript">
* Contains finalized speech-to-text results
* Represents complete user utterances
* Used for conversation history
```javascript
// Example transcript event structure
{
"type": "user_transcript",
"user_transcription_event": {
"user_transcript": "Hello, how can you help me today?"
}
}
```
```javascript
// Example transcript handler
websocket.on('user_transcript', (event) => {
const { user_transcription_event } = event;
const { user_transcript } = user_transcription_event;
updateConversationHistory(user_transcript);
});
```
</Accordion>
<Accordion title="agent_response">
* Contains complete agent message
* Sent with first audio chunk
* Used for display and history
```javascript
// Example response event structure
{
"type": "agent_response",
"agent_response_event": {
"agent_response": "Hello, how can I assist you today?"
}
}
```
```javascript
// Example response handler
websocket.on('agent_response', (event) => {
const { agent_response_event } = event;
const { agent_response } = agent_response_event;
displayAgentMessage(agent_response);
});
```
</Accordion>
<Accordion title="agent_response_correction">
* Contains truncated response after interruption
* Updates displayed message
* Maintains conversation accuracy
```javascript
// Example response correction event structure
{
"type": "agent_response_correction",
"agent_response_correction_event": {
"original_agent_response": "Let me tell you about the complete history...",
"corrected_agent_response": "Let me tell you about..."  // Truncated after interruption
}
}
```
```javascript
// Example response correction handler
websocket.on('agent_response_correction', (event) => {
const { agent_response_correction_event } = event;
const { corrected_agent_response } = agent_response_correction_event;
displayAgentMessage(corrected_agent_response);
});
```
</Accordion>
<Accordion title="client_tool_call">
* Represents a function call the agent wants the client to execute
* Contains tool name, tool call ID, and parameters
* Requires client-side execution of the function and sending the result back to the server
<Info>
If you are using the SDK, callbacks are provided to handle sending the result back to the server.
</Info>
```javascript
// Example tool call event structure
{
"type": "client_tool_call",
"client_tool_call": {
"tool_name": "search_database",
"tool_call_id": "call_123456",
"parameters": {
"query": "user information",
"filters": {
"date": "2024-01-01"
}
}
}
}
```
```javascript
// Example tool call handler
websocket.on('client_tool_call', async (event) => {
const { client_tool_call } = event;
const { tool_name, tool_call_id, parameters } = client_tool_call;
try {
const result = await executeClientTool(tool_name, parameters);
// Send success response back to continue conversation
websocket.send({
type: "client_tool_result",
tool_call_id: tool_call_id,
result: result,
is_error: false
});
} catch (error) {
// Send error response if tool execution fails
websocket.send({
type: "client_tool_result",
tool_call_id: tool_call_id,
result: error.message,
is_error: true
});
}
});
```
</Accordion>
</AccordionGroup>
## Event flow
Here's a typical sequence of events during a conversation:
```mermaid
sequenceDiagram
participant Client
participant Server
Server->>Client: conversation_initiation_metadata
Note over Client,Server: Connection established
Server->>Client: ping
Client->>Server: pong
Server->>Client: audio
Note over Client: Playing audio
Note over Client: User responds
Server->>Client: user_transcript
Server->>Client: agent_response
Server->>Client: audio
Server->>Client: client_tool_call
Note over Client: Client tool runs
Client->>Server: client_tool_result
Server->>Client: agent_response
Server->>Client: audio
Note over Client: Playing audio
Note over Client: Interruption detected
Server->>Client: agent_response_correction
```
### Best practices
1. **Error handling**
* Implement proper error handling for each event type
* Log important events for debugging
* Handle connection interruptions gracefully
2. **Audio management**
* Buffer audio chunks appropriately
* Implement proper cleanup on interruption
* Handle audio resource management
3. **Connection management**
* Respond to PING events promptly
* Implement reconnection logic
* Monitor connection health
## Troubleshooting
<AccordionGroup>
<Accordion title="Connection issues">
* Ensure proper WebSocket connection
* Check PING/PONG responses
* Verify API credentials
</Accordion>
<Accordion title="Audio problems">
* Check audio chunk handling
* Verify audio format compatibility
* Monitor memory usage
</Accordion>
<Accordion title="Event handling">
* Log all events for debugging
* Implement error boundaries
* Check event handler registration
</Accordion>
</AccordionGroup>
<Info>
For detailed implementation examples, check our [SDK
documentation](/docs/conversational-ai/libraries/python).
</Info>
# Client tools
> Empower your assistant to trigger client-side operations.
**Client tools** enable your assistant to execute client-side functions. Unlike [server-side tools](/docs/conversational-ai/customization/tools), client tools allow the assistant to perform actions such as triggering browser events, running client-side functions, or sending notifications to a UI.
## Overview
Applications may require assistants to interact directly with the user's environment. Client-side tools give your assistant the ability to perform client-side operations.
Here are a few examples where client tools can be useful:
* **Triggering UI events**: Allow an assistant to trigger browser events, such as alerts, modals or notifications.
* **Interacting with the DOM**: Enable an assistant to manipulate the Document Object Model (DOM) for dynamic content updates or to guide users through complex interfaces.
<Info>
To perform operations server-side, use
[server-tools](/docs/conversational-ai/customization/tools-events/server-tools) instead.
</Info>
## Guide
### Prerequisites
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs Conversational Agent ([create one here](https://elevenlabs.io/app/conversational-ai))
<Steps>
<Step title="Create a new client-side tool">
Navigate to your agent dashboard. In the **Tools** section, click **Add Tool**. Ensure the **Tool Type** is set to **Client**. Then configure the following:
| Setting     | Parameter                                                        |
| ----------- | ---------------------------------------------------------------- |
| Name        | logMessage                                                       |
| Description | Use this client-side tool to log a message to the user's client. |
Then create a new parameter `message` with the following configuration:
| Setting     | Parameter                                                                          |
| ----------- | ---------------------------------------------------------------------------------- |
| Data Type   | String                                                                             |
| Identifier  | message                                                                            |
| Required    | true                                                                               |
| Description | The message to log in the console. Ensure the message is informative and relevant. |
<Frame background="subtle">
![logMessage client-tool setup](file:e8fb80fc-84e7-45a8-8b23-2fec9d3b33b8)
</Frame>
</Step>
<Step title="Register the client tool in your code">
Unlike server-side tools, client tools need to be registered in your code.
Use the following code to register the client tool:
<CodeBlocks>
```python title="Python" focus={4-16}
from elevenlabs import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation, ClientTools
def log_message(parameters):
message = parameters.get("message")
print(message)
client_tools = ClientTools()
client_tools.register("logMessage", log_message)
conversation = Conversation(
client=ElevenLabs(api_key="your-api-key"),
agent_id="your-agent-id",
client_tools=client_tools,
# ...
)
conversation.start_session()
```
```javascript title="JavaScript" focus={2-10}
// ...
const conversation = await Conversation.startSession({
// ...
clientTools: {
logMessage: async ({message}) => {
console.log(message);
}
},
// ...
});
```
```swift title="Swift" focus={2-10}
// ...
var clientTools = ElevenLabsSDK.ClientTools()
clientTools.register("logMessage") { parameters async throws -> String? in
guard let message = parameters["message"] as? String else {
throw ElevenLabsSDK.ClientToolError.invalidParameters
}
print(message)
return message
}
```
</CodeBlocks>
<Note>
The tool and parameter names in the agent configuration are case-sensitive and **must** match those registered in your code.
</Note>
</Step>
<Step title="Testing">
Initiate a conversation with your agent and say something like:
> *Log a message to the console that says Hello World*
You should see a `Hello World` log appear in your console.
</Step>
<Step title="Next steps">
Now that you've set up a basic client-side event, you can:
* Explore more complex client tools like opening modals, navigating to pages, or interacting with the DOM.
* Combine client tools with server-side webhooks for full-stack interactions.
* Use client tools to enhance user engagement and provide real-time feedback during conversations.
</Step>
</Steps>
### Passing client tool results to the conversation context
When you want your agent to receive data back from a client tool, ensure that you tick the **Wait for response** option in the tool configuration.
<Frame background="subtle">
<img src="file:223553e6-4138-4fa0-9e3d-6da6084866b1" alt="Wait for response option in client tool configuration" />
</Frame>
Once the client tool is added, when the function is called the agent will wait for its response and append the response to the conversation context.
<CodeBlocks>
```python title="Python"
def get_customer_details():
# Fetch customer details (e.g., from an API or database)
customer_data = {
"id": 123,
"name": "Alice",
"subscription": "Pro"
}
# Return the customer data; it can also be a JSON string if needed.
return customer_data
client_tools = ClientTools()
client_tools.register("getCustomerDetails", get_customer_details)
conversation = Conversation(
client=ElevenLabs(api_key="your-api-key"),
agent_id="your-agent-id",
client_tools=client_tools,
# ...
)
conversation.start_session()
```
```javascript title="JavaScript"
const clientTools = {
getCustomerDetails: async () => {
// Fetch customer details (e.g., from an API)
const customerData = {
id: 123,
name: "Alice",
subscription: "Pro"
};
// Return data directly to the agent.
return customerData;
}
};
// Start the conversation with client tools configured.
const conversation = await Conversation.startSession({ clientTools });
```
</CodeBlocks>
In this example, when the agent calls **getCustomerDetails**, the function will execute on the client and the agent will receive the returned data, which is then used as part of the conversation context.
### Troubleshooting
<AccordionGroup>
<Accordion title="Tools not being triggered">
* Ensure the tool and parameter names in the agent configuration match those registered in your code.
* View the conversation transcript in the agent dashboard to verify the tool is being executed.
</Accordion>
<Accordion title="Console errors">
* Open the browser console to check for any errors.
* Ensure that your code has necessary error handling for undefined or unexpected parameters.
</Accordion>
</AccordionGroup>
## Best practices
<h4>
Name tools intuitively, with detailed descriptions
</h4>
If you find the assistant does not make calls to the correct tools, you may need to update your tool names and descriptions so the assistant more clearly understands when it should select each tool. Avoid using abbreviations or acronyms to shorten tool and argument names.
You can also include detailed descriptions for when a tool should be called. For complex tools, you should include descriptions for each of the arguments to help the assistant know what it needs to ask the user to collect that argument.
<h4>
Name tool parameters intuitively, with detailed descriptions
</h4>
Use clear and descriptive names for tool parameters. If applicable, specify the expected format for a parameter in the description (e.g., YYYY-mm-dd or dd/mm/yy for a date).
<h4>
Consider providing additional information about how and when to call tools in your assistant's
system prompt
</h4>
Providing clear instructions in your system prompt can significantly improve the assistant's tool calling accuracy. For example, guide the assistant with instructions like the following:
```plaintext
Use `check_order_status` when the user inquires about the status of their order, such as 'Where is my order?' or 'Has my order shipped yet?'.
```
Provide context for complex scenarios. For example:
```plaintext
Before scheduling a meeting with `schedule_meeting`, check the user's calendar for availability using check_availability to avoid conflicts.
```
<h4>
LLM selection
</h4>
<Warning>
When using tools, we recommend picking high intelligence models like GPT-4o mini or Claude 3.5
Sonnet and avoiding Gemini 1.5 Flash.
</Warning>
It's important to note that the choice of LLM matters to the success of function calls. Some LLMs can struggle with extracting the relevant parameters from the conversation.
# Tools
> Connect your assistant to external data & systems.
**Tools** enable your assistant to connect to external data and systems. You can define a set of tools that the assistant has access to, and the assistant will use them where appropriate based on the conversation.
## Overview
Many applications require assistants to call external APIs to get real-time information. Tools give your assistant the ability to make external function calls to third party apps so you can get real-time information.
Here are a few examples where tools can be useful:
* **Fetching data**: enable an assistant to retrieve real-time data from any REST-enabled database or 3rd party integration before responding to the user.
* **Taking action**: allow an assistant to trigger authenticated actions based on the conversation, like scheduling meetings or initiating order returns.
<Info>
To interact with Application UIs or trigger client-side events use [client
tools](/docs/conversational-ai/customization/tools-events/client-tools) instead.
</Info>
## Tool configuration
Conversational AI assistants can be equipped with tools to interact with external APIs. Unlike traditional requests, the assistant generates query, body, and path parameters dynamically based on the conversation and parameter descriptions you provide.
All tool configurations and parameter descriptions help the assistant determine **when** and **how** to use these tools. To orchestrate tool usage effectively, update the assistant’s system prompt to specify the sequence and logic for making these calls. This includes:
* **Which tool** to use and under what conditions.
* **What parameters** the tool needs to function properly.
* **How to handle** the responses.
<br />
<Tabs>
<Tab title="Configuration">
Define a high-level `Name` and `Description` to describe the tool's purpose. This helps the LLM understand the tool and know when to call it.
<Info>
If the API requires path parameters, include variables in the URL path by wrapping them in curly
braces `{}`, for example: `/api/resource/{id}` where `id` is a path parameter.
</Info>
<Frame background="subtle">
![Configuration](file:7df9f96e-20ae-4ecc-a78a-da0951e6fd51)
</Frame>
</Tab>
<Tab title="Secrets">
Assistant secrets can be used to add authentication headers to requests.
<Frame background="subtle">
![Tool secrets](file:491bd3aa-f05c-4111-8585-de15919ddd08)
</Frame>
</Tab>
<Tab title="Headers">
Specify any headers that need to be included in the request.
<Frame background="subtle">
![Headers](file:da9f1047-5c0e-4a46-8504-455b8ac3b50c)
</Frame>
</Tab>
<Tab title="Path parameters">
Include variables in the URL path by wrapping them in curly braces `{}`:
* **Example**: `/api/resource/{id}` where `id` is a path parameter.
<Frame background="subtle">
![Path parameters](file:2576a5fd-25d0-4922-a9ff-1f7078ed36b7)
</Frame>
</Tab>
<Tab title="Body parameters">
Specify any body parameters to be included in the request.
<Frame background="subtle">
![Body parameters](file:337aebc1-649d-4137-9673-39b125fc4382)
</Frame>
</Tab>
<Tab title="Query parameters">
Specify any query parameters to be included in the request.
<Frame background="subtle">
![Query parameters](file:013b5657-2ef0-40db-9d62-bfffa5c9dd92)
</Frame>
</Tab>
</Tabs>
## Guide
In this guide, we'll create a weather assistant that can provide real-time weather information for any location. The assistant will use its geographic knowledge to convert location names into coordinates and fetch accurate weather data.
<div>
<iframe src="https://player.vimeo.com/video/1061374724?h=bd9bdb535e&badge=0&autopause=0&player_id=0&app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write; encrypted-media" title="weatheragent" />
</div>
<Steps>
<Step title="Configure the weather tool">
First, on the **Agent** section of your agent settings page, choose **Add Tool**. Select **Webhook** as the Tool Type, then configure the weather API integration:
<AccordionGroup>
<Accordion title="Weather Tool Configuration">
<Tabs>
<Tab title="Configuration">
| Field       | Value                                                                                                                                                                                                                                                                                                                                                                                  |
| ----------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name        | get\_weather                                                                                                                                                                                                                                                                                                                                                                           |
| Description | Gets the current weather forecast for a location                                                                                                                                                                                                                                                                                                                                       |
| Method      | GET                                                                                                                                                                                                                                                                                                                                                                                    |
| URL         | [https://api.open-meteo.com/v1/forecast?latitude=\{latitude}\&longitude=\{longitude}\&current=temperature\_2m,wind\_speed\_10m\&hourly=temperature\_2m,relative\_humidity\_2m,wind\_speed\_10m](https://api.open-meteo.com/v1/forecast?latitude=\{latitude}\&longitude=\{longitude}\&current=temperature_2m,wind_speed_10m\&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m) |
</Tab>
<Tab title="Path Parameters">
| Data Type | Identifier | Value Type | Description                                         |
| --------- | ---------- | ---------- | --------------------------------------------------- |
| string    | latitude   | LLM Prompt | The latitude coordinate for the requested location  |
| string    | longitude  | LLM Prompt | The longitude coordinate for the requested location |
</Tab>
</Tabs>
</Accordion>
</AccordionGroup>
<Warning>
An API key is not required for this tool. If one is required, this should be passed in the headers and stored as a secret.
</Warning>
</Step>
<Step title="Orchestration">
Configure your assistant to handle weather queries intelligently with this system prompt:
```plaintext System prompt
You are a helpful conversational AI assistant with access to a weather tool. When users ask about
weather conditions, use the get_weather tool to fetch accurate, real-time data. The tool requires
a latitude and longitude - use your geographic knowledge to convert location names to coordinates
accurately.
Never ask users for coordinates - you must determine these yourself. Always report weather
information conversationally, referring to locations by name only. For weather requests:
1. Extract the location from the user's message
2. Convert the location to coordinates and call get_weather
3. Present the information naturally and helpfully
For non-weather queries, provide friendly assistance within your knowledge boundaries. Always be
concise, accurate, and helpful.
First message: "Hey, how can I help you today?"
```
<Success>
Test your assistant by asking about the weather in different locations. The assistant should
handle specific locations ("What's the weather in Tokyo?") and ask for clarification after general queries ("How's
the weather looking today?").
</Success>
</Step>
</Steps>
## Best practices
<h4>
Name tools intuitively, with detailed descriptions
</h4>
If you find the assistant does not make calls to the correct tools, you may need to update your tool names and descriptions so the assistant more clearly understands when it should select each tool. Avoid using abbreviations or acronyms to shorten tool and argument names.
You can also include detailed descriptions for when a tool should be called. For complex tools, you should include descriptions for each of the arguments to help the assistant know what it needs to ask the user to collect that argument.
<h4>
Name tool parameters intuitively, with detailed descriptions
</h4>
Use clear and descriptive names for tool parameters. If applicable, specify the expected format for a parameter in the description (e.g., YYYY-mm-dd or dd/mm/yy for a date).
<h4>
Consider providing additional information about how and when to call tools in your assistant's
system prompt
</h4>
Providing clear instructions in your system prompt can significantly improve the assistant's tool calling accuracy. For example, guide the assistant with instructions like the following:
```plaintext
Use `check_order_status` when the user inquires about the status of their order, such as 'Where is my order?' or 'Has my order shipped yet?'.
```
Provide context for complex scenarios. For example:
```plaintext
Before scheduling a meeting with `schedule_meeting`, check the user's calendar for availability using check_availability to avoid conflicts.
```
<h4>
LLM selection
</h4>
<Warning>
When using tools, we recommend picking high intelligence models like GPT-4o mini or Claude 3.5
Sonnet and avoiding Gemini 1.5 Flash.
</Warning>
It's important to note that the choice of LLM matters to the success of function calls. Some LLMs can struggle with extracting the relevant parameters from the conversation.
# End call
> Let your agent automatically hang up on the user.
<Warning>
The **End Call** tool is added to agents created in the ElevenLabs dashboard by default. For
agents created via API or SDK, if you would like to enable the End Call tool, you must add it
manually as a system tool in your agent configuration. [See API Implementation
below](#api-implementation) for details.
</Warning>
<Frame background="subtle">
![End call](file:c47f5cca-5003-4f8e-937a-5b5036434f55)
</Frame>
## Overview
The **End Call** tool allows your conversational agent to terminate a call with the user. This is a system tool that provides flexibility in how and when calls are ended.
## Functionality
* **Default behavior**: The tool can operate without any user-defined prompts, ending the call when the conversation naturally concludes.
* **Custom prompts**: Users can specify conditions under which the call should end. For example:
* End the call if the user says "goodbye."
* Conclude the call when a specific task is completed.
### API Implementation
When creating an agent via API, you can add the End Call tool to your agent configuration. It should be defined as a system tool:
<CodeBlocks>
```python
from elevenlabs import (
ConversationalConfig,
ElevenLabs,
AgentConfig,
PromptAgent,
PromptAgentToolsItem_System
)
# Initialize the client
client = ElevenLabs(api_key="YOUR_API_KEY")
# Create the end call tool
end_call_tool = PromptAgentToolsItem_System(
name="end_call",
description=""  # Optional: Customize when the tool should be triggered
)
# Create the agent configuration
conversation_config = ConversationalConfig(
agent=AgentConfig(
prompt=PromptAgent(
tools=[end_call_tool]
)
)
)
# Create the agent
response = client.conversational_ai.create_agent(
conversation_config=conversation_config
)
```
```javascript
import { ElevenLabs } from 'elevenlabs';
// Initialize the client
const client = new ElevenLabs({
apiKey: 'YOUR_API_KEY',
});
// Create the agent with end call tool
await client.conversationalAi.createAgent({
conversation_config: {
agent: {
prompt: {
tools: [
{
type: 'system',
name: 'end_call',
description: '', // Optional: Customize when the tool should be triggered
},
],
},
},
},
});
```
```bash
curl -X POST https://api.elevenlabs.io/v1/convai/agents/create \
-H "xi-api-key: YOUR_API_KEY" \
-H "Content-Type: application/json" \
-d '{
"conversation_config": {
"agent": {
"prompt": {
"tools": [
{
"type": "system",
"name": "end_call",
"description": ""
}
]
}
}
}
}'
```
</CodeBlocks>
<Tip>
Leave the description blank to use the default end call prompt.
</Tip>
## Example prompts
**Example 1: Basic End Call**
```
End the call when the user says goodbye, thank you, or indicates they have no more questions.
```
**Example 2: End Call with Custom Prompt**
```
End the call when the user says goodbye, thank you, or indicates they have no more questions. You can only end the call after all their questions have been answered. Please end the call only after confirming that the user doesn't need any additional assistance.
```
# Language detection
> Let your agent automatically switch to the language
## Overview
The `language detection` system tool allows your Conversational AI agent to switch its output language to any the agent supports.
This system tool is not enabled automatically. Its description can be customized to accommodate your specific use case.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/Bq-KYatAIU4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Note>
Where possible, we recommend enabling all languages for an agent and enabling the language
detection system tool.
</Note>
Our language detection tool triggers language switching in two cases, both based on the received audio's detected language and content:
* `detection` if a user speaks a different language than the current output language, a switch will be triggered
* `content` if the user asks in the current language to change to a new language, a switch will be triggered
## Enabling language detection
<Steps>
<Step title="Configure supported languages">
The languages that the agent can switch to must be defined in the `Agent` settings tab.
<Frame background="subtle">
![Agent languages](file:795b65b1-db41-456f-8ee5-1df40ca29ef7)
</Frame>
</Step>
<Step title="Add the language detection tool">
Enable language detection by selecting the pre-configured system tool to your agent's tools in the `Agent` tab.
This is automatically available as an option when selecting `add tool`.
<Frame background="subtle">
![System tool](file:21208918-a4dc-4623-8ce0-b41534d106c4)
</Frame>
</Step>
<Step title="Configure tool description">
Add a description that specifies when to call the tool
<Frame background="subtle">
![Description](file:aded8407-4e98-44a1-bd63-332647be5a8e)
</Frame>
</Step>
</Steps>
### API Implementation
When creating an agent via API, you can add the `language detection` tool to your agent configuration. It should be defined as a system tool:
<CodeBlocks>
```python
from elevenlabs import (
ConversationalConfig,
ElevenLabs,
AgentConfig,
PromptAgent,
PromptAgentToolsItem_System
)
# Initialize the client
client = ElevenLabs(api_key="YOUR_API_KEY")
# Create the language detection tool
language_detection_tool = PromptAgentToolsItem_System(
name="language_detection",
description=""  # Optional: Customize when the tool should be triggered
)
# Create the agent configuration
conversation_config = ConversationalConfig(
agent=AgentConfig(
prompt=PromptAgent(
tools=[language_detection_tool]
)
)
)
# Create the agent
response = client.conversational_ai.create_agent(
conversation_config=conversation_config
)
```
```javascript
import { ElevenLabs } from 'elevenlabs';
// Initialize the client
const client = new ElevenLabs({
apiKey: 'YOUR_API_KEY',
});
// Create the agent with language detection tool
await client.conversationalAi.createAgent({
conversation_config: {
agent: {
prompt: {
tools: [
{
type: 'system',
name: 'language_detection',
description: '', // Optional: Customize when the tool should be triggered
},
],
},
},
},
});
```
```bash
curl -X POST https://api.elevenlabs.io/v1/convai/agents/create \
-H "xi-api-key: YOUR_API_KEY" \
-H "Content-Type: application/json" \
-d '{
"conversation_config": {
"agent": {
"prompt": {
"tools": [
{
"type": "system",
"name": "language_detection",
"description": ""
}
]
}
}
}
}'
```
</CodeBlocks>
<Tip>
Leave the description blank to use the default language detection prompt.
</Tip>
# Knowledge base
> Enhance your conversational agent with custom knowledge.
**Knowledge bases** allow you to equip your agent with relevant, domain-specific information.
## Overview
A well-curated knowledge base helps your agent go beyond its pre-trained data and deliver context-aware answers.
Here are a few examples where knowledge bases can be useful:
* **Product catalogs**: Store product specifications, pricing, and other essential details.
* **HR or corporate policies**: Provide quick answers about vacation policies, employee benefits, or onboarding procedures.
* **Technical documentation**: Equip your agent with in-depth guides or API references to assist developers.
* **Customer FAQs**: Answer common inquiries consistently.
<Info>
The agent on this page is configured with full knowledge of ElevenLabs' documentation and sitemap. Go ahead and ask it about anything about ElevenLabs.
</Info>
## Usage
Files, URLs, and text can be added to the knowledge base in the dashboard. They can also be added programmatically through our [API](https://elevenlabs.io/docs/api-reference).
<Steps>
<Step title="File">
Upload files in formats like PDF, TXT, DOCX, HTML, and EPUB.
<Frame background="subtle">
![File upload interface showing supported formats (PDF, TXT, DOCX, HTML, EPUB) with a 21MB
size limit](file:0afe3a3d-ea5c-4689-949e-40af78d3c150)
</Frame>
</Step>
<Step title="URL">
Import URLs from sources like documentation and product pages.
<Frame background="subtle">
![URL import interface where users can paste documentation
links](file:14eee740-3804-4453-bd8f-c8ef09d14768)
</Frame>
<Note>
When creating a knowledge base item from a URL, we do not currently support scraping all pages
linked to from the initial URL, or continuously updating the knowledge base over time.
However, these features are coming soon.
</Note>
<Warning>
Ensure you have permission to use the content from the URLs you provide
</Warning>
</Step>
<Step title="Text">
Manually add text to the knowledge base.
<Frame background="subtle">
![Text input interface where users can name and add custom
content](file:60c73156-a1af-46f8-9de5-70529a638639)
</Frame>
</Step>
</Steps>
## Best practices
<h4>
Content quality
</h4>
Provide clear, well-structured information that's relevant to your agent's purpose.
<h4>
Size management
</h4>
Break large documents into smaller, focused pieces for better processing.
<h4>
Regular updates
</h4>
Regularly review and update the agent's knowledge base to ensure the information remains current and accurate.
<h4>
Identify knowledge gaps
</h4>
Review conversation transcripts to identify popular topics, queries and areas where users struggle to find information. Note any knowledge gaps and add the missing context to the knowledge base.
## Enterprise features
Non-enterprise accounts have a limit of 5 knowledge base items, with a maximum of 20MB or 300k characters.
<Info>
Need higher limits? [Contact our sales team](https://elevenlabs.io/contact-sales) to discuss
enterprise plans with expanded knowledge base capabilities.
</Info>
# Knowledge base dashboard
> Learn how to manage and organize your knowledge base through the ElevenLabs dashboard
## Overview
The [knowledge base dashboard](https://elevenlabs.io/app/conversational-ai/knowledge-base) provides a centralized way to manage documents and track their usage across your AI agents. This guide explains how to navigate and use the knowledge base dashboard effectively.
<Frame background="subtle">
![Knowledge base main interface showing list of
documents](file:1c9c79f3-7abd-42c4-9a78-bd26001761c1)
</Frame>
## Adding existing documents to agents
When configuring an agent's knowledge base, you can easily add existing documents to an agent.
1. Navigate to the agent's [configuration](https://elevenlabs.io/app/conversational-ai/)
2. Click "Add document" in the knowledge base section of the "Agent" tab.
3. The option to select from your existing knowledge base documents or upload a new document will appear.
<Frame background="subtle">
![Interface for adding documents to an
agent](file:1df406a9-fd73-48c7-8e0e-c8f794e18119)
</Frame>
<Tip>
Documents can be reused across multiple agents, making it efficient to maintain consistent
knowledge across your workspace.
</Tip>
## Document dependencies
Each document in your knowledge base includes a "Agents" tab that shows which agents currently depend on that document.
<Frame background="subtle">
![Dependent agents tab showing which agents use a
document](file:0c141f64-56a6-42a5-9748-e086b48b6304)
</Frame>
It is not possible to delete a document if any agent depends on it.
# Retrieval-Augmented Generation
> Enhance your agent with large knowledge bases using RAG.
## Overview
**Retrieval-Augmented Generation (RAG)** enables your agent to access and use large knowledge bases during conversations. Instead of loading entire documents into the context window, RAG retrieves only the most relevant information for each user query, allowing your agent to:
* Access much larger knowledge bases than would fit in a prompt
* Provide more accurate, knowledge-grounded responses
* Reduce hallucinations by referencing source material
* Scale knowledge without creating multiple specialized agents
RAG is ideal for agents that need to reference large documents, technical manuals, or extensive
knowledge bases that would exceed the context window limits of traditional prompting.
RAG adds on slight latency to the response time of your agent, around 500ms.
## How RAG works
When RAG is enabled, your agent processes user queries through these steps:
1. **Query processing**: The user's question is analyzed and reformulated for optimal retrieval.
2. **Embedding generation**: The processed query is converted into a vector embedding that represents the user's question.
3. **Retrieval**: The system finds the most semantically similar content from your knowledge base.
4. **Response generation**: The agent generates a response using both the conversation context and the retrieved information.
This process ensures that relevant information to the user's query is passed to the LLM to generate a factually correct answer.
<Note>
When RAG is enabled, the size of knowledge base items that can be assigned to an agent is
increased from 300KB to 10MB
</Note>
## Guide
### Prerequisites
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs [Conversational Agent](/docs/conversational-ai/quickstart)
* At least one document added to your agent's knowledge base
<Steps>
<Step title="Enable RAG for your agent">
In your agent's settings, navigate to the **Knowledge Base** section and toggle on the **Use RAG** option.
<Frame background="subtle">
<img src="file:45183515-dc58-4a57-ba90-f67f12ee51fc" alt="Toggle switch to enable RAG in the agent settings" />
</Frame>
</Step>
<Step title="Configure RAG settings (optional)">
After enabling RAG, you'll see additional configuration options:
* **Embedding model**: Select the model that will convert text into vector embeddings
* **Maximum document chunks**: Set the maximum amount of retrieved content per query
* **Maximum vector distance**: Set the maximum distance between the query and the retrieved chunks
These parameters could impact latency. They also could impact LLM cost which in the future will be passed on to you.
For example, retrieving more chunks increases cost.
Increasing vector distance allows for more context to be passed, but potentially less relevant context.
This may affect quality and you should experiment with different parameters to find the best results.
<Frame background="subtle">
<img src="file:71d8b387-4576-46b9-98a9-d961524050b4" alt="RAG configuration options including embedding model selection" />
</Frame>
</Step>
<Step title="Knowledge base indexing">
Each document in your knowledge base needs to be indexed before it can be used with RAG. This
process happens automatically when a document is added to an agent with RAG enabled.
<Info>
Indexing may take a few minutes for large documents. You can check the indexing status in the
knowledge base list.
</Info>
</Step>
<Step title="Configure document usage modes (optional)">
For each document in your knowledge base, you can choose how it's used:
* **Auto (default)**: The document is only retrieved when relevant to the query
* **Prompt**: The document is always included in the system prompt, regardless of relevance, but can also be retrieved by RAG
<Frame background="subtle">
<img src="file:f348b439-786d-4d58-8fc0-a64a7f237773" alt="Document usage mode options in the knowledge base" />
</Frame>
<Warning>
Setting too many documents to "Prompt" mode may exceed context limits. Use this option sparingly
for critical information.
</Warning>
</Step>
<Step title="Test your RAG-enabled agent">
After saving your configuration, test your agent by asking questions related to your knowledge base. The agent should now be able to retrieve and reference specific information from your documents.
</Step>
</Steps>
## API implementation
You can also implement RAG through the [API](/docs/api-reference/knowledge-base/rag-index-status):
<CodeBlocks>
```python
import requests
# First, index a document for RAG
document_id = "your-document-id"
response = requests.post(
f"https://api.elevenlabs.io/v1/conversational-ai/knowledge-base/{document_id}/rag-index",
headers={"xi-api-key": "your-api-key"},
json={"model": "e5_mistral_7b_instruct"}
)
# Check indexing status
while True:
if response.json()["status"] in ["SUCCEEDED", "FAILED"]:
break
time.sleep(5) # wait 5 seconds before checking status again
response = requests.get(
f"https://api.elevenlabs.io/v1/conversational-ai/knowledge-base/{document_id}/rag-index",
headers={"xi-api-key": "your-api-key"}
)
# Then update agent configuration to use RAG
agent_id = "your-agent-id"
agent_config = requests.get(
f"https://api.elevenlabs.io/v1/conversational-ai/agents/{agent_id}",
headers={"xi-api-key": "your-api-key"}
).json()
# Enable RAG in the agent configuration
agent_config["agent"]["prompt"]["rag"] = {
"enabled": True,
"embedding_model": "e5_mistral_7b_instruct",
"max_documents_length": 10000
}
# Update document usage mode if needed
for i, doc in enumerate(agent_config["agent"]["prompt"]["knowledge_base"]):
if doc["id"] == document_id:
agent_config["agent"]["prompt"]["knowledge_base"][i]["usage_mode"] = "auto"
# Update the agent configuration
requests.put(
f"https://api.elevenlabs.io/v1/conversational-ai/agents/{agent_id}",
headers={"xi-api-key": "your-api-key"},
json=agent_config
)
```
```javascript
// First, index a document for RAG
async function enableRAG(documentId, agentId, apiKey) {
try {
// Start document indexing
let response = await fetch(
`https://api.elevenlabs.io/v1/conversational-ai/knowledge-base/${documentId}/rag-index`,
{
method: 'POST',
headers: {
'xi-api-key': apiKey,
'Content-Type': 'application/json',
},
body: JSON.stringify({ model: 'e5_mistral_7b_instruct' }),
}
);
let data = await response.json();
// Check indexing status
while (true) {
const status = data.status;
if (status === 'SUCCEEDED' || status === 'FAILED') {
break;
}
await new Promise((resolve) => setTimeout(resolve, 5000)); // Wait 5 seconds
response = await fetch(
`https://api.elevenlabs.io/v1/conversational-ai/knowledge-base/${documentId}/rag-index`,
{ headers: { 'xi-api-key': apiKey } }
);
data = await response.json();
}
// Get agent configuration
const agentResponse = await fetch(
`https://api.elevenlabs.io/v1/conversational-ai/agents/${agentId}`,
{ headers: { 'xi-api-key': apiKey } }
);
const agentConfig = await agentResponse.json();
// Enable RAG in the agent configuration
agentConfig.agent.prompt.rag = {
enabled: true,
embedding_model: 'e5_mistral_7b_instruct',
max_documents_length: 10000,
};
// Update document usage mode if needed
agentConfig.agent.prompt.knowledge_base.forEach((doc, index) => {
if (doc.id === documentId) {
agentConfig.agent.prompt.knowledge_base[index].usage_mode = 'auto';
}
});
// Update the agent configuration
await fetch(`https://api.elevenlabs.io/v1/conversational-ai/agents/${agentId}`, {
method: 'PUT',
headers: {
'xi-api-key': apiKey,
'Content-Type': 'application/json',
},
body: JSON.stringify(agentConfig),
});
console.log('RAG configuration updated successfully');
} catch (error) {
console.error('Error:', error.message);
}
}
```
</CodeBlocks>
# Personalization
> Learn how to personalize your agent's behavior using dynamic variables and overrides.
## Overview
Personalization allows you to adapt your agent's behavior for each individual user, enabling more natural and contextually relevant conversations. ElevenLabs offers multiple approaches to personalization:
1. **Dynamic Variables** - Inject runtime values into prompts and messages
2. **Overrides** - Completely replace system prompts or messages
3. **Twilio Integration** - Personalize inbound call experiences via webhooks
## Personalization Methods
<CardGroup cols={3}>
<Card title="Dynamic Variables" icon="duotone lambda" href="/docs/conversational-ai/customization/personalization/dynamic-variables">
Define runtime values using `{{var_name}}` syntax to personalize your agent's messages, system
prompts, and tools.
</Card>
<Card title="Overrides" icon="duotone sliders" href="/docs/conversational-ai/customization/personalization/overrides">
Completely replace system prompts, first messages, language, or voice settings for each
conversation.
</Card>
<Card title="Twilio Integration" icon="duotone phone-arrow-down-left" href="/docs/conversational-ai/customization/personalization/twilio-personalization">
Dynamically personalize inbound Twilio calls using webhook data.
</Card>
</CardGroup>
## Conversation Initiation Client Data Structure
The `conversation_initiation_client_data` object defines what can be customized when starting a conversation:
```json
{
"type": "conversation_initiation_client_data",
"conversation_config_override": {
"agent": {
"prompt": {
"prompt": "overriding system prompt"
},
"first_message": "overriding first message",
"language": "en"
},
"tts": {
"voice_id": "voice-id-here"
}
},
"custom_llm_extra_body": {
"temperature": 0.7,
"max_tokens": 100
},
"dynamic_variables": {
"string_var": "text value",
"number_var": 1.2,
"integer_var": 123,
"boolean_var": true
}
}
```
## Choosing the Right Approach
<Table>
<thead>
<tr>
<th>
Method
</th>
<th>
Best For
</th>
<th>
Implementation
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
**Dynamic Variables**
</td>
<td>
* Inserting user-specific data into templated content - Maintaining consistent agent
behavior with personalized details - Personalizing tool parameters
</td>
<td>
Define variables with
`{{ variable_name }}`
and pass values at runtime
</td>
</tr>
<tr>
<td>
**Overrides**
</td>
<td>
* Completely changing agent behavior per user - Switching languages or voices - Legacy
applications (consider migrating to Dynamic Variables)
</td>
<td>
Enable specific override permissions in security settings and pass complete replacement
content
</td>
</tr>
</tbody>
</Table>
## Learn More
* [Dynamic Variables Documentation](/docs/conversational-ai/customization/personalization/dynamic-variables)
* [Overrides Documentation](/docs/conversational-ai/customization/personalization/overrides)
* [Twilio Integration Documentation](/docs/conversational-ai/customization/personalization/twilio-personalization)
# Dynamic variables
> Pass runtime values to personalize your agent's behavior.
**Dynamic variables** allow you to inject runtime values into your agent's messages, system prompts, and tools. This enables you to personalize each conversation with user-specific data without creating multiple agents.
## Overview
Dynamic variables can be integrated into multiple aspects of your agent:
* **System prompts** to customize behavior and context
* **First messages** to personalize greetings
* **Tool parameters** to pass user-specific data
Here are a few examples where dynamic variables are useful:
* **Personalizing greetings** with user names
* **Including account details** in responses
* **Passing data** to tool calls
* **Customizing behavior** based on subscription tiers
* **Accessing system information** like conversation ID or call duration
<Info>
Dynamic variables are ideal for injecting user-specific data that shouldn't be hardcoded into your
agent's configuration.
</Info>
## System dynamic variables
Your agent has access to these automatically available system variables:
* `system__agent_id` - Unique agent identifier
* `system__caller_id` - Caller's phone number (voice calls only)
* `system__called_number` - Destination phone number (voice calls only)
* `system__call_duration_secs` - Call duration in seconds
* `system__time_utc` - Current UTC time (ISO format)
* `system__conversation_id` - Unique conversation identifier
System variables:
* Are available without runtime configuration
* Are prefixed with `system__` (reserved prefix)
* In system prompts: Set once at conversation start (value remains static)
* In tool calls: Updated at execution time (value reflects current state)
<Warning>
Custom dynamic variables cannot use the reserved
`system__`
prefix.
</Warning>
## Guide
### Prerequisites
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs Conversational Agent ([create one here](/docs/conversational-ai/quickstart))
<Steps>
<Step title="Define dynamic variables in prompts">
Add variables using double curly braces `{{variable_name}}` in your:
* System prompts
* First messages
* Tool parameters
<Frame background="subtle">
![Dynamic variables in messages](file:5c9df94e-0197-4056-92c4-8a48fe4523d6)
</Frame>
<Frame background="subtle">
![Dynamic variables in messages](file:404ec35c-3dbf-487c-95cb-059ae8ddf154)
</Frame>
</Step>
<Step title="Define dynamic variables in tools">
You can also define dynamic variables in the tool configuration.
To create a new dynamic variable, set the value type to Dynamic variable and click the `+` button.
<Frame background="subtle">
![Setting placeholders](file:2aa5ec77-a4dc-4a4e-b02d-879a0a748ee1)
</Frame>
<Frame background="subtle">
![Setting placeholders](file:de1179bb-0eb4-4605-8502-7890eaeb80f2)
</Frame>
</Step>
<Step title="Set placeholders">
Configure default values in the web interface for testing:
<Frame background="subtle">
![Setting placeholders](file:d1e2c802-57d2-4a5e-a3ba-f73c630f7fd2)
</Frame>
</Step>
<Step title="Pass variables at runtime">
When starting a conversation, provide the dynamic variables in your code:
<Tip>
Ensure you have the latest [SDK](/docs/conversational-ai/libraries) installed.
</Tip>
<CodeGroup>
```python title="Python" focus={10-23} maxLines=25
import os
import signal
from elevenlabs.client import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation, ConversationConfig
from elevenlabs.conversational_ai.default_audio_interface import DefaultAudioInterface
agent_id = os.getenv("AGENT_ID")
api_key = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(api_key=api_key)
dynamic_vars = {
"user_name": "Angelo",
}
config = ConversationConfig(
dynamic_variables=dynamic_vars
)
conversation = Conversation(
client,
agent_id,
config=config,
# Assume auth is required when API_KEY is set.
requires_auth=bool(api_key),
# Use the default audio interface.
audio_interface=DefaultAudioInterface(),
# Simple callbacks that print the conversation to the console.
callback_agent_response=lambda response: print(f"Agent: {response}"),
callback_agent_response_correction=lambda original, corrected: print(f"Agent: {original} -> {corrected}"),
callback_user_transcript=lambda transcript: print(f"User: {transcript}"),
# Uncomment the below if you want to see latency measurements.
# callback_latency_measurement=lambda latency: print(f"Latency: {latency}ms"),
)
conversation.start_session()
signal.signal(signal.SIGINT, lambda sig, frame: conversation.end_session())
```
```javascript title="JavaScript" focus={7-20} maxLines=25
import { Conversation } from '@11labs/client';
class VoiceAgent {
...
async startConversation() {
try {
// Request microphone access
await navigator.mediaDevices.getUserMedia({ audio: true });
this.conversation = await Conversation.startSession({
agentId: 'agent_id_goes_here', // Replace with your actual agent ID
dynamicVariables: {
user_name: 'Angelo'
},
... add some callbacks here
});
} catch (error) {
console.error('Failed to start conversation:', error);
alert('Failed to start conversation. Please ensure microphone access is granted.');
}
}
}
```
```swift title="Swift"
let dynamicVars: [String: DynamicVariableValue] = [
"customer_name": .string("John Doe"),
"account_balance": .number(5000.50),
"user_id": .int(12345),
"is_premium": .boolean(true)
]
// Create session config with dynamic variables
let config = SessionConfig(
agentId: "your_agent_id",
dynamicVariables: dynamicVars
)
// Start the conversation
let conversation = try await Conversation.startSession(
config: config
)
```
```html title="Widget"
<elevenlabs-convai
agent-id="your-agent-id"
dynamic-variables='{"user_name": "John", "account_type": "premium"}'
></elevenlabs-convai>
```
</CodeGroup>
</Step>
</Steps>
## Supported Types
Dynamic variables support these value types:
<CardGroup cols={3}>
<Card title="String">
Text values
</Card>
<Card title="Number">
Numeric values
</Card>
<Card title="Boolean">
True/false values
</Card>
</CardGroup>
## Troubleshooting
<AccordionGroup>
<Accordion title="Variables not replacing">
Verify that:
* Variable names match exactly (case-sensitive)
* Variables use double curly braces: `{{ variable_name }}`
* Variables are included in your dynamic\_variables object
</Accordion>
<Accordion title="Type errors">
Ensure that:
* Variable values match the expected type
* Values are strings, numbers, or booleans only
</Accordion>
</AccordionGroup>
# Overrides
> Tailor each conversation with personalized context for each user.
<Warning>
While overrides are still supported for completely replacing system prompts or first messages, we
recommend using [Dynamic
Variables](/docs/conversational-ai/customization/personalization/dynamic-variables) as the
preferred way to customize your agent's responses and inject real-time data. Dynamic Variables
offer better maintainability and a more structured approach to personalization.
</Warning>
**Overrides** enable your assistant to adapt its behavior for each user interaction. You can pass custom data and settings at the start of each conversation, allowing the assistant to personalize its responses and knowledge with real-time context. Overrides completely override the agent's default values defined in the agent's [dashboard](https://elevenlabs.io/app/conversational-ai/agents).
## Overview
Overrides allow you to modify your AI agent's behavior in real-time without creating multiple agents. This enables you to personalize responses with user-specific data.
Overrides can be enable for the following fields in the agent's security settings:
* System prompt
* First message
* Language
* Voice ID
When overrides are enabled for a field, providing an override is still optional. If not provided, the agent will use the default values defined in the agent's [dashboard](https://elevenlabs.io/app/conversational-ai/agents). An error will be thrown if an override is provided for a field that does not have overrides enabled.
Here are a few examples where overrides can be useful:
* **Greet users** by their name
* **Include account-specific details** in responses
* **Adjust the agent's language** or tone based on user preferences
* **Pass real-time data** like account balances or order status
<Info>
Overrides are particularly useful for applications requiring personalized interactions or handling
sensitive user data that shouldn't be stored in the agent's base configuration.
</Info>
## Guide
### Prerequisites
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs Conversational Agent ([create one here](/docs/conversational-ai/quickstart))
This guide will show you how to override the default agent **System prompt** & **First message**.
<Steps>
<Step title="Enable overrides">
For security reasons, overrides are disabled by default. Navigate to your agent's settings and
select the **Security** tab.
Enable the `First message` and `System prompt` overrides.
<Frame background="subtle">
![Enable overrides](file:2b141079-8352-4e3f-9166-6aa2c0945e66)
</Frame>
</Step>
<Step title="Override the conversation">
In your code, where the conversation is started, pass the overrides as a parameter.
<Tip>
Ensure you have the latest [SDK](/docs/conversational-ai/libraries) installed.
</Tip>
<CodeGroup>
```python title="Python" focus={3-14} maxLines=14
from elevenlabs.conversational_ai.conversation import Conversation, ConversationConfig
...
conversation_override = {
"agent": {
"prompt": {
"prompt": f"The customer's bank account balance is {customer_balance}. They are based in {customer_location}."
},
"first_message": f"Hi {customer_name}, how can I help you today?",
"language": "en" # Optional: override the language.
},
"tts": {
"voice_id": "" # Optional: override the voice.
}
}
config = ConversationConfig(
conversation_config_override=conversation_override
)
conversation = Conversation(
...
config=config,
...
)
conversation.start_session()
```
```javascript title="JavaScript" focus={4-15} maxLines=15
...
const conversation = await Conversation.startSession({
...
overrides: {
agent: {
prompt: {
prompt: `The customer's bank account balance is ${customer_balance}. They are based in ${customer_location}.`
},
firstMessage: `Hi ${customer_name}, how can I help you today?`,
language: "en" // Optional: override the language.
},
tts: {
voiceId: "" // Optional: override the voice.
}
},
...
})
```
```swift title="Swift" focus={3-14} maxLines=14
import ElevenLabsSDK
let promptOverride = ElevenLabsSDK.AgentPrompt(
prompt: "The customer's bank account balance is \(customer_balance). They are based in \(customer_location)."
)
let agentConfig = ElevenLabsSDK.AgentConfig(
prompt: promptOverride,
firstMessage: "Hi \(customer_name), how can I help you today?",
language: .en // Optional: override the language.
)
let overrides = ElevenLabsSDK.ConversationConfigOverride(
agent: agentConfig,
tts: TTSConfig(voiceId: "custom_voice_id") // Optional: override the voice.
)
let config = ElevenLabsSDK.SessionConfig(
agentId: "",
overrides: overrides
)
let conversation = try await ElevenLabsSDK.Conversation.startSession(
config: config,
callbacks: callbacks
)
```
```html title="Widget"
<elevenlabs-convai
agent-id="your-agent-id"
override-config='{
"agent": {
"prompt": {
"prompt": "Custom system prompt for this user"
},
"first_message": "Hi! How can I help you today?",
"language": "es"
}
}'
> </elevenlabs-convai>
```
</CodeGroup>
<Info>
To override the agent voice or language, you'll need to enable these in the Security tab.
</Info>
</Step>
</Steps>
# Twilio personalization
> Configure personalization for incoming Twilio calls using webhooks.
## Overview
When receiving inbound Twilio calls, you can dynamically fetch conversation initiation data through a webhook. This allows you to customize your agent's behavior based on caller information and other contextual data.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/cAuSo8qNs-8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
## How it works
1. When a Twilio call is received, the ElevenLabs Conversational AI platform will make a webhook call to your specified endpoint, passing call information (`caller_id`, `agent_id`, `called_number`, `call_sid`) as arguments
2. Your webhook returns conversation initiation client data, including dynamic variables and overrides (an example is shown below)
3. This data is used to initiate the conversation
<Tip>
The system uses Twilio's connection/dialing period to fetch webhook data in parallel, creating a
seamless experience where:
* Users hear the expected telephone connection sound
* In parallel, theConversational AI platform fetches necessary webhook data
* The conversation is initiated with the fetched data by the time the audio connection is established
</Tip>
## Configuration
<Steps>
<Step title="Configure webhook details">
In the [settings page](https://elevenlabs.io/app/conversational-ai/settings) of the Conversational AI platform, configure the webhook URL and add any
secrets needed for authentication.
<Frame background="subtle">
![Enable webhook](file:86f869fe-f254-4fb1-ad76-2618d06cedbc)
</Frame>
Click on the webhook to modify which secrets are sent in the headers.
<Frame background="subtle">
![Add secrets to headers](file:a74e0ade-65f4-45ea-90ef-5e8be56ca1e5)
</Frame>
</Step>
<Step title="Enable fetching conversation initiation data">
In the "Security" tab of the [agent's page](https://elevenlabs.io/app/conversational-ai/agents/), enable fetching conversation initiation data for inbound Twilio calls, and define fields that can be overridden.
<Frame background="subtle">
![Enable webhook](file:e735a758-cca7-4982-8f67-0bc2ae5bef04)
</Frame>
</Step>
<Step title="Implement the webhook endpoint to receive Twilio data">
The webhook will receive a POST request with the following parameters:
| Parameter       | Type   | Description                            |
| --------------- | ------ | -------------------------------------- |
| `caller_id`     | string | The phone number of the caller         |
| `agent_id`      | string | The ID of the agent receiving the call |
| `called_number` | string | The Twilio number that was called      |
| `call_sid`      | string | Unique identifier for the Twilio call  |
</Step>
<Step title="Return conversation initiation client data">
Your webhook must return a JSON response containing the initiation data for the agent.
<Info>
The `dynamic_variables` field must contain all dynamic variables defined for the agent. Overrides
on the other hand are entirely optional. For more information about dyanmic variables and
overrides see the [dynamic variables](/conversational-ai/customization/dynamic-variables) and
[overrides](/conversational-ai/customization/conversation-config-overrides) docs.
</Info>
An example response could be:
```json
{
"dynamic_variables": {
"customer_name": "John Doe",
"account_status": "premium",
"last_interaction": "2024-01-15"
},
"conversation_config_override": {
"agent": {
"prompt": {
"prompt": "The customer's bank account balance is $100. They are based in San Francisco."
},
"first_message": "Hi, how can I help you today?",
"language": "en"
},
"tts": {
"voice_id": "new-voice-id"
}
}
}
```
</Step>
</Steps>
The Conversational AI platform will use the dynamic variables to populate the conversation initiation data, and the conversation will start smoothly.
<Warning>
Ensure your webhook responds within a reasonable timeout period to avoid delaying the call
handling.
</Warning>
## Security
* Use HTTPS endpoints only
* Implement authentication using request headers
* Store sensitive values as secrets through the [ElevenLabs secrets manager](https://elevenlabs.io/app/conversational-ai/settings)
* Validate the incoming request parameters
# Voice customization
> Learn how to customize your AI agent's voice and speech patterns.
## Overview
You can customize various aspects of your AI agent's voice to create a more natural and engaging conversation experience. This includes controlling pronunciation, speaking speed, and language-specific voice settings.
## Available customizations
<CardGroup cols={3}>
<Card title="Pronunciation dictionary" icon="microphone-stand" href="/docs/conversational-ai/customization/voice/pronunciation-dictionary">
Control how your agent pronounces specific words and phrases using
[IPA](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet) or
[CMU](https://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary) notation.
</Card>
<Card title="Speed control" icon="waveform" href="/docs/conversational-ai/customization/voice/speed-control">
Adjust how quickly or slowly your agent speaks, with values ranging from 0.7x to 1.2x.
</Card>
<Card title="Language-specific voices" icon="language" href="/docs/conversational-ai/customization/language">
Configure different voices for each supported language to ensure natural pronunciation.
</Card>
</CardGroup>
## Best practices
<AccordionGroup>
<Accordion title="Voice selection">
Choose voices that match your target language and region for the most natural pronunciation.
Consider testing multiple voices to find the best fit for your use case.
</Accordion>
<Accordion title="Speed optimization">
Start with the default speed (1.0) and adjust based on your specific needs. Test different
speeds with your content to find the optimal balance between clarity and natural flow.
</Accordion>
<Accordion title="Pronunciation dictionaries">
Focus on terms specific to your business or use case that need consistent pronunciation and are
not widely used in everyday conversation. Test pronunciations with your chosen voice and model
combination.
</Accordion>
</AccordionGroup>
<Note>
Some voice customization features may be model-dependent. For example, phoneme-based pronunciation
control is only available with the Turbo v2 model.
</Note>
# Pronunciation dictionaries
> Learn how to control how your AI agent pronounces specific words and phrases.
## Overview
Pronunciation dictionaries allow you to customize how your AI agent pronounces specific words or phrases. This is particularly useful for:
* Correcting pronunciation of names, places, or technical terms
* Ensuring consistent pronunciation across conversations
* Customizing regional pronunciation variations
<Frame background="subtle">
<img src="file:5c09dae7-40f3-4167-a9ad-fd7f68bd0bf1" alt="Pronunciation dictionary settings under the Voice tab" />
</Frame>
## Configuration
You can find the pronunciation dictionary settings under the **Voice** tab in your agent's configuration.
<Note>
The phoneme function of pronunciation dictionaries only works with the Turbo v2 model, while the
alias function works with all models.
</Note>
## Dictionary file format
Pronunciation dictionaries use XML-based `.pls` files. Here's an example structure:
```xml
<?xml version="1.0" encoding="UTF-8"?>
<lexicon version="1.0"
xmlns="http://www.w3.org/2005/01/pronunciation-lexicon"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.w3.org/2005/01/pronunciation-lexicon
http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd"
alphabet="ipa" xml:lang="en-GB">
<lexeme>
<grapheme>Apple</grapheme>
<phoneme>ˈæpl̩</phoneme>
</lexeme>
<lexeme>
<grapheme>UN</grapheme>
<alias>United Nations</alias>
</lexeme>
</lexicon>
```
## Supported formats
We support two types of pronunciation notation:
1. **IPA (International Phonetic Alphabet)**
* More precise control over pronunciation
* Requires knowledge of IPA symbols
* Example: "nginx" as `/ˈɛndʒɪnˈɛks/`
2. **CMU (Carnegie Mellon University) Dictionary format**
* Simpler ASCII-based format
* More accessible for English pronunciations
* Example: "tomato" as "T AH M EY T OW"
<Tip>
You can use AI tools like Claude or ChatGPT to help generate IPA or CMU notations for specific
words.
</Tip>
## Best practices
1. **Case sensitivity**: Create separate entries for capitalized and lowercase versions of words if needed
2. **Testing**: Always test pronunciations with your chosen voice and model
3. **Maintenance**: Keep your dictionary organized and documented
4. **Scope**: Focus on words that are frequently mispronounced or critical to your use case
## FAQ
<AccordionGroup>
<Accordion title="Which models support phoneme-based pronunciation?">
Currently, only the Turbo v2 model supports phoneme-based pronunciation. Other models will
silently skip phoneme entries.
</Accordion>
<Accordion title="Can I use multiple dictionaries?">
Yes, you can upload multiple dictionary files to handle different sets of pronunciations.
</Accordion>
<Accordion title="What happens if a word isn't in the dictionary?">
The model will use its default pronunciation rules for any words not specified in the
dictionary.
</Accordion>
</AccordionGroup>
## Additional resources
* [Professional Voice Cloning](/docs/product-guides/voices/voice-cloning/professional-voice-cloning)
* [Voice Design](/docs/product-guides/voices/voice-design)
* [Text to Speech API Reference](/docs/api-reference/text-to-speech)
# Speed control
> Learn how to adjust the speaking speed of your conversational AI agent.
## Overview
The speed control feature allows you to adjust how quickly or slowly your agent speaks. This can be useful for:
* Making speech more accessible for different audiences
* Matching specific use cases (e.g., slower for educational content)
* Optimizing for different types of conversations
<Frame background="subtle">
<img src="file:5950ece2-5191-470c-96d7-b5e82962c689" alt="Speed control settings under the Voice tab" />
</Frame>
## Configuration
Speed is controlled through the [`speed` parameter](/docs/api-reference/agents/create-agent#request.body.conversation_config.tts.speed) with the following specifications:
* **Range**: 0.7 to 1.2
* **Default**: 1.0
* **Type**: Optional
## How it works
The speed parameter affects the pace of speech generation:
* Values below 1.0 slow down the speech
* Values above 1.0 speed up the speech
* 1.0 represents normal speaking speed
<Note>
Extreme values near the minimum or maximum may affect the quality of the generated speech.
</Note>
## Best practices
* Start with the default speed (1.0) and adjust based on user feedback
* Test different speeds with your specific content
* Consider your target audience when setting the speed
* Monitor speech quality at extreme values
<Warning>
Values outside the 0.7-1.2 range are not supported.
</Warning>
# Language
> Learn how to configure your agent to speak multiple languages.
## Overview
This guide shows you how to configure your agent to speak multiple languages. You'll learn to:
* Configure your agent's primary language
* Add support for multiple languages
* Set language-specific voices and first messages
* Optimize voice selection for natural pronunciation
* Enable automatic language switching
## Guide
<Steps>
<Step title="Default agent language">
When you create a new agent, it's configured with:
* English as the primary language
* Flash v2 model for fast, English-only responses
* A default first message.
<Frame background="subtle">
![](file:dff1bade-77df-423a-975a-98bd93fb08c6)
</Frame>
<Note>
Additional languages switch the agent to use the v2.5 Multilingual model. English will always use
the v2 model.
</Note>
</Step>
<Step title="Add additional languages">
First, navigate to your agent's configuration page and locate the **Agent** tab.
1. In the **Additional Languages** add an additional language (e.g. French)
2. Review the first message, which is automatically translated using a Large Language Model (LLM). Customize it as needed for each additional language to ensure accuracy and cultural relevance.
<Frame background="subtle">
![](file:93d1786b-719a-4b86-a664-25324b25c993)
</Frame>
<Note>
Selecting the **All** option in the **Additional Languages** dropdown will configure the agent to
support 31 languages. Collectively, these languages are spoken by approximately 90% of the world's
population.
</Note>
</Step>
<Step title="Configure language-specific voices">
For optimal pronounciation, configure each additional language with a language-specific voice from our [Voice Library](https://elevenlabs.io/app/voice-library).
<Note>
To find great voices for each language curated by the ElevenLabs team, visit the [language top
picks](https://elevenlabs.io/app/voice-library/collections).
</Note>
<Tabs>
<Tab title="Language-specific voice settings">
<Frame background="subtle">
![](file:0603fde8-fc4c-4a3c-a2d3-d3d5465fecb5)
</Frame>
</Tab>
<Tab title="Voice library">
<Frame background="subtle">
![](file:8b49a338-6b3b-4784-b26e-6315be58c0de)
</Frame>
</Tab>
</Tabs>
</Step>
<Step title="Enable language detection">
Add the [language detection tool](/docs/conversational-ai/customization/tools-events/server-tools/language-detection) to your agent can automatically switch to the user's preferred language.
</Step>
<Step title="Starting a call">
Now that the agent is configured to support additional languages, the widget will prompt the user for their preferred language before the conversation begins.
If using the SDK, the language can be set programmatically using conversation overrides. See the
[Overrides](/docs/conversational-ai/customization/personalization/overrides) guide for implementation details.
<Frame background="subtle">
![](file:4414cca2-d8ab-42c9-8b66-51980ece2097)
</Frame>
<Note>
Language selection is fixed for the duration of the call - users cannot switch languages
mid-conversation.
</Note>
</Step>
</Steps>
### Internationalization
You can integrate the widget with your internationalization framework by dynamically setting the language and UI text attributes.
```html title="Widget"
<elevenlabs-convai
language="es"
action-text={i18n["es"]["actionText"]}
start-call-text={i18n["es"]["startCall"]}
end-call-text={i18n["es"]["endCall"]}
expand-text={i18n["es"]["expand"]}
listening-text={i18n["es"]["listening"]}
speaking-text={i18n["es"]["speaking"]}
></elevenlabs-convai>
```
<Note>
Ensure the language codes match between your i18n framework and the agent's supported languages.
</Note>
## Best practices
<AccordionGroup>
<Accordion title="Voice selection">
Select voices specifically trained in your target languages. This ensures:
* Natural pronunciation
* Appropriate regional accents
* Better handling of language-specific nuances
</Accordion>
<Accordion title="First message customization">
While automatic translations are provided, consider:
<div>
* Reviewing translations for accuracy
* Adapting greetings for cultural context
* Adjusting formal/informal tone as needed
</div>
</Accordion>
</AccordionGroup>
# Integrate your own model
> Connect an agent to your own LLM or host your own server.
Currently, the following models are natively supported and can be configured via the agent settings:
* Gemini 2.0 Flash
* Gemini 1.5 Flash
* Gemini 1.5 Pro
* Gemini 1.0 Pro
* GPT-4o Mini
* GPT-4o
* GPT-4 Turbo
* GPT-3.5 Turbo
* Claude 3.5 Sonnet
* Claude 3 Haiku
![Supported models](file:0c000211-111e-476c-accc-2ae205985fdf)
**Custom LLMs** let you bring your own OpenAI API key or run an entirely custom LLM server.
## Overview
By default, we use our own internal credentials for popular models like OpenAI. To use a custom LLM server, it must align with the OpenAI [create chat completion](https://platform.openai.com/docs/api-reference/chat/create) request/response structure.
The following guides cover both use cases:
1. **Bring your own OpenAI key**: Use your own OpenAI API key with our platform.
2. **Custom LLM server**: Host and connect your own LLM server implementation.
You'll learn how to:
* Store your OpenAI API key in ElevenLabs
* host a server that replicates OpenAI's [create chat completion](https://platform.openai.com/docs/api-reference/chat/create) endpoint
* Direct ElevenLabs to your custom endpoint
* Pass extra parameters to your LLM as needed
<br />
## Using your own OpenAI key
To integrate a custom OpenAI key, create a secret containing your OPENAI\_API\_KEY:
<Steps>
<Step>
Navigate to the "Secrets" page and select "Add Secret"
<Frame background="subtle">
![Add Secret](file:4dcaeecf-28c1-428b-8167-4d092f559e95)
</Frame>
</Step>
<Step>
Choose "Custom LLM" from the dropdown menu.
<Frame background="subtle">
![Choose custom llm](file:2b04772e-6f04-4312-9402-af8880866cb1)
</Frame>
</Step>
<Step>
Enter the URL, your model, and the secret you created.
<Frame background="subtle">
![Enter url](file:ddd3068c-a602-437e-9482-316dc44781fb)
</Frame>
</Step>
<Step>
Set "Custom LLM extra body" to true.
<Frame background="subtle">
![](file:b4d6ce4d-c5ad-4462-872c-8edc5adc6a3b)
</Frame>
</Step>
</Steps>
## Custom LLM Server
To bring a custom LLM server, set up a compatible server endpoint using OpenAI's style, specifically targeting create\_chat\_completion.
Here's an example server implementation using FastAPI and OpenAI's Python SDK:
```python
import json
import os
import fastapi
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI
import uvicorn
import logging
from dotenv import load_dotenv
from pydantic import BaseModel
from typing import List, Optional
# Load environment variables from .env file
load_dotenv()
# Retrieve API key from environment
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
raise ValueError("OPENAI_API_KEY not found in environment variables")
app = fastapi.FastAPI()
oai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
class Message(BaseModel):
role: str
content: str
class ChatCompletionRequest(BaseModel):
messages: List[Message]
model: str
temperature: Optional[float] = 0.7
max_tokens: Optional[int] = None
stream: Optional[bool] = False
user_id: Optional[str] = None
@app.post("/v1/chat/completions")
async def create_chat_completion(request: ChatCompletionRequest) -> StreamingResponse:
oai_request = request.dict(exclude_none=True)
if "user_id" in oai_request:
oai_request["user"] = oai_request.pop("user_id")
chat_completion_coroutine = await oai_client.chat.completions.create(**oai_request)
async def event_stream():
try:
async for chunk in chat_completion_coroutine:
# Convert the ChatCompletionChunk to a dictionary before JSON serialization
chunk_dict = chunk.model_dump()
yield f"data: {json.dumps(chunk_dict)}\n\n"
yield "data: [DONE]\n\n"
except Exception as e:
logging.error("An error occurred: %s", str(e))
yield f"data: {json.dumps({'error': 'Internal error occurred!'})}\n\n"
return StreamingResponse(event_stream(), media_type="text/event-stream")
if __name__ == "__main__":
uvicorn.run(app, host="0.0.0.0", port=8013)
```
Run this code or your own server code.
<Frame background="subtle">
![](file:b244b5b2-7cf8-49d6-a6de-6cb0e5c6b34a)
</Frame>
### Setting Up a Public URL for Your Server
To make your server accessible, create a public URL using a tunneling tool like ngrok:
```shell
ngrok http --url=<Your url>.ngrok.app 8013
```
<Frame background="subtle">
![](file:50bb331e-b128-46f1-ad80-fd9a4f03712f)
</Frame>
### Configuring Elevenlabs CustomLLM
Now let's make the changes in Elevenlabs
<Frame background="subtle">
![](file:5f13cfd6-2951-4403-a083-a9ac99de560b)
</Frame>
<Frame background="subtle">
![](file:0a7f2462-d7f2-4bc4-8cf2-4767c12698ea)
</Frame>
Direct your server URL to ngrok endpoint, setup "Limit token usage" to 5000 and set "Custom LLM extra body" to true.
You can start interacting with Conversational AI with your own LLM server
# Additional Features
<Accordion title="Custom LLM Parameters">
You may pass additional parameters to your custom LLM implementation.
<Tabs>
<Tab title="Python">
<Steps>
<Step title="Define the Extra Parameters">
Create an object containing your custom parameters:
```python
from elevenlabs.conversational_ai.conversation import Conversation, ConversationConfig
extra_body_for_convai = {
"UUID": "123e4567-e89b-12d3-a456-426614174000",
"parameter-1": "value-1",
"parameter-2": "value-2",
}
config = ConversationConfig(
extra_body=extra_body_for_convai,
)
```
</Step>
<Step title="Update the LLM Implementation">
Modify your custom LLM code to handle the additional parameters:
```python
import json
import os
import fastapi
from fastapi.responses import StreamingResponse
from fastapi import Request
from openai import AsyncOpenAI
import uvicorn
import logging
from dotenv import load_dotenv
from pydantic import BaseModel
from typing import List, Optional
# Load environment variables from .env file
load_dotenv()
# Retrieve API key from environment
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
raise ValueError("OPENAI_API_KEY not found in environment variables")
app = fastapi.FastAPI()
oai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
class Message(BaseModel):
role: str
content: str
class ChatCompletionRequest(BaseModel):
messages: List[Message]
model: str
temperature: Optional[float] = 0.7
max_tokens: Optional[int] = None
stream: Optional[bool] = False
user_id: Optional[str] = None
elevenlabs_extra_body: Optional[dict] = None
@app.post("/v1/chat/completions")
async def create_chat_completion(request: ChatCompletionRequest) -> StreamingResponse:
oai_request = request.dict(exclude_none=True)
print(oai_request)
if "user_id" in oai_request:
oai_request["user"] = oai_request.pop("user_id")
if "elevenlabs_extra_body" in oai_request:
oai_request.pop("elevenlabs_extra_body")
chat_completion_coroutine = await oai_client.chat.completions.create(**oai_request)
async def event_stream():
try:
async for chunk in chat_completion_coroutine:
chunk_dict = chunk.model_dump()
yield f"data: {json.dumps(chunk_dict)}\n\n"
yield "data: [DONE]\n\n"
except Exception as e:
logging.error("An error occurred: %s", str(e))
yield f"data: {json.dumps({'error': 'Internal error occurred!'})}\n\n"
return StreamingResponse(event_stream(), media_type="text/event-stream")
if __name__ == "__main__":
uvicorn.run(app, host="0.0.0.0", port=8013)
```
</Step>
</Steps>
### Example Request
With this custom message setup, your LLM will receive requests in this format:
```json
{
"messages": [
{
"role": "system",
"content": "\n  <Redacted>"
},
{
"role": "assistant",
"content": "Hey I'm currently unavailable."
},
{
"role": "user",
"content": "Hey, who are you?"
}
],
"model": "gpt-4o",
"temperature": 0.5,
"max_tokens": 5000,
"stream": true,
"elevenlabs_extra_body": {
"UUID": "123e4567-e89b-12d3-a456-426614174000",
"parameter-1": "value-1",
"parameter-2": "value-2"
}
}
```
</Tab>
</Tabs>
</Accordion>
# Cloudflare Workers AI
> Connect an agent to a custom LLM on Cloudflare Workers AI.
## Overview
[Cloudflare's Workers AI platform](https://developers.cloudflare.com/workers-ai/) lets you run machine learning models, powered by serverless GPUs, on Cloudflare's global network, even on the free plan!
Workers AI comes with a curated set of [popular open-source models](https://developers.cloudflare.com/workers-ai/models/) that enable you to do tasks such as image classification, text generation, object detection and more.
## Choosing a model
To make use of the full power of ElevenLabs Conversational AI you need to use a model that supports [function calling](https://developers.cloudflare.com/workers-ai/function-calling/#what-models-support-function-calling).
When browsing the [model catalog](https://developers.cloudflare.com/workers-ai/models/), look for models with the function calling property beside it.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/8iwPIdzTwAA?rel=0&autoplay=0" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Tip title="Try out DeepSeek R1" icon="leaf">
Cloudflare Workers AI provides access to
[DeepSeek-R1-Distill-Qwen-32B](https://developers.cloudflare.com/workers-ai/models/deepseek-r1-distill-qwen-32b/),
a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various
benchmarks, achieving new state-of-the-art results for dense models.
</Tip>
## Set up DeepSeek R1 on Cloudflare Workers AI
<Steps>
<Step>
Navigate to [dash.cloudflare.com](https://dash.cloudflare.com) and create or sign in to your account. In the navigation, select AI > Workers AI, and then click on the "Use REST API" widget.
<Frame background="subtle">
![Add Secret](file:280e3243-d7e0-484b-b141-bdd98ab07aef)
</Frame>
</Step>
<Step>
Once you have your API key, you can try it out immediately with a curl request. Cloudflare provides an OpenAI-compatible API endpoint making this very convenient. At this point make a note of the model and the full endpoint — including the account ID. For example: `https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}c/ai/v1/`.
```bash
curl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1/chat/completions \
-X POST \
-H "Authorization: Bearer {API_TOKEN}" \
-d '{
"model": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
"messages": [
{"role": "system", "content": "You are a helpful assistant."},
{"role": "user", "content": "How many Rs in the word Strawberry?"}
],
"stream": false
}'
```
</Step>
<Step>
Navigate to your [AI Agent](https://elevenlabs.io/app/conversational-ai), scroll down to the "Secrets" section and select "Add Secret". After adding the secret, make sure to hit "Save" to make the secret available to your agent.
<Frame background="subtle">
![Add Secret](file:88ff66fd-ed52-4a3c-93a0-2fd4290544c2)
</Frame>
</Step>
<Step>
Choose "Custom LLM" from the dropdown menu.
<Frame background="subtle">
![Choose custom llm](file:2b04772e-6f04-4312-9402-af8880866cb1)
</Frame>
</Step>
<Step>
For the Server URL, specify Cloudflare's OpenAI-compatible API endpoint: `https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1/`. For the Model ID, specify `@cf/deepseek-ai/deepseek-r1-distill-qwen-32b` as discussed above, and select your API key from the dropdown menu.
<Frame background="subtle">
![Enter url](file:85f05c3b-55da-4075-b835-4b34393d8d89)
</Frame>
</Step>
<Step>
Now you can go ahead and click "Test AI Agent" to chat with your custom DeepSeek R1 model.
</Step>
</Steps>
# Groq Cloud
> Connect an agent to a custom LLM on Groq Cloud.
## Overview
[Groq Cloud](https://console.groq.com/) provides easy access to fast AI inference, giving you OpenAI-compatible API endpoints in a matter of clicks.
Use leading [Openly-available Models](https://console.groq.com/docs/models) like Llama, Mixtral, and Gemma as the brain for your ElevenLabs Conversational AI agents in a few easy steps.
## Choosing a model
To make use of the full power of ElevenLabs Conversational AI you need to use a model that supports tool use and structured outputs. Groq recommends the following Llama-3.3 models their versatility and performance:
* llama-3.3-70b-versatile (128k context window | 32,768 max output tokens)
* llama-3.1-8b-instant (128k context window | 8,192 max output tokens)
With this in mind, it's recommended to use `llama-3.3-70b-versatile` for your ElevenLabs Conversational AI agent.
## Set up Llama 3.3 on Groq Cloud
<Steps>
<Step>
Navigate to [console.groq.com/keys](https://console.groq.com/keys) and create a new API key.
<Frame background="subtle">
![Add Secret](file:7d527bf7-0bea-4aca-85cb-e3a353c209b8)
</Frame>
</Step>
<Step>
Once you have your API key, you can test it by running the following curl command:
```bash
curl https://api.groq.com/openai/v1/chat/completions -s \
-H "Content-Type: application/json" \
-H "Authorization: Bearer $GROQ_API_KEY" \
-d '{
"model": "llama-3.3-70b-versatile",
"messages": [{
"role": "user",
"content": "Hello, how are you?"
}]
}'
```
</Step>
<Step>
Navigate to your [AI Agent](https://elevenlabs.io/app/conversational-ai), scroll down to the "Secrets" section and select "Add Secret". After adding the secret, make sure to hit "Save" to make the secret available to your agent.
<Frame background="subtle">
![Add Secret](file:f7be9e81-b8df-444e-9a9d-be98cff3ca7b)
</Frame>
</Step>
<Step>
Choose "Custom LLM" from the dropdown menu.
<Frame background="subtle">
![Choose custom llm](file:2b04772e-6f04-4312-9402-af8880866cb1)
</Frame>
</Step>
<Step>
For the Server URL, specify Groq's OpenAI-compatible API endpoint: `https://api.groq.com/openai/v1`. For the Model ID, specify `llama-3.3-70b-versatile` as discussed above, and select your API key from the dropdown menu.
<Frame background="subtle">
![Enter url](file:10b66a3e-66de-4096-9547-bbc6064e35b0)
</Frame>
</Step>
<Step>
Now you can go ahead and click "Test AI Agent" to chat with your custom Llama 3.3 model.
</Step>
</Steps>
# Together AI
> Connect an agent to a custom LLM on Together AI.
## Overview
[Together AI](https://www.together.ai/) provides an AI Acceleration Cloud, allowing you to train, fine-tune, and run inference on AI models blazing fast, at low cost, and at production scale.
Instantly run [200+ models](https://together.xyz/models) including DeepSeek, Llama3, Mixtral, and Stable Diffusion, optimized for peak latency, throughput, and context length.
## Choosing a model
To make use of the full power of ElevenLabs Conversational AI you need to use a model that supports tool use and structured outputs. Together AI supports function calling for [these models](https://docs.together.ai/docs/function-calling):
* meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
* meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
* meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
* meta-llama/Llama-3.3-70B-Instruct-Turbo
* mistralai/Mixtral-8x7B-Instruct-v0.1
* mistralai/Mistral-7B-Instruct-v0.1
With this in mind, it's recommended to use at least `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` for your ElevenLabs Conversational AI agent.
## Set up Llama 3.1 on Together AI
<Steps>
<Step>
Navigate to [api.together.xyz/settings/api-keys](https://api.together.xyz/settings/api-keys) and create a new API key.
<Frame background="subtle">
![Add Secret](file:2e6101a2-26a0-4e5a-ad99-6f7face1f528)
</Frame>
</Step>
<Step>
Once you have your API key, you can test it by running the following curl command:
```bash
curl https://api.together.xyz/v1/chat/completions -s \
-H "Content-Type: application/json" \
-H "Authorization: Bearer <API_KEY>" \
-d '{
"model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
"messages": [{
"role": "user",
"content": "Hello, how are you?"
}]
}'
```
</Step>
<Step>
Navigate to your [AI Agent](https://elevenlabs.io/app/conversational-ai), scroll down to the "Secrets" section and select "Add Secret". After adding the secret, make sure to hit "Save" to make the secret available to your agent.
<Frame background="subtle">
![Add Secret](file:736dc462-8ff2-422a-82c6-ac38e49e01b5)
</Frame>
</Step>
<Step>
Choose "Custom LLM" from the dropdown menu.
<Frame background="subtle">
![Choose custom llm](file:2b04772e-6f04-4312-9402-af8880866cb1)
</Frame>
</Step>
<Step>
For the Server URL, specify Together AI's OpenAI-compatible API endpoint: `https://api.together.xyz/v1`. For the Model ID, specify `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo` as discussed above, and select your API key from the dropdown menu.
<Frame background="subtle">
![Enter url](file:8ff8046a-5c63-46ff-887d-d3fc64c367c6)
</Frame>
</Step>
<Step>
Now you can go ahead and click "Test AI Agent" to chat with your custom Llama 3.1 model.
</Step>
</Steps>
# Widget customization
> Learn how to customize the widget appearance to match your brand, and personalize the agent's behavior from html.
**Widgets** enable instant integration of Conversational AI into any website. You can either customize your widget through the UI or through our type-safe [Conversational AI SDKs](/docs/conversational-ai/libraries) for complete control over styling and behavior. The SDK overrides take priority over UI customization.
<Note>
Widgets currently require public agents with authentication disabled. Ensure this is disabled in
the **Advanced** tab of your agent settings.
</Note>
## Embedding the widget
Add this code snippet to your website's `<body>` section. Place it in your main `index.html` file for site-wide availability:
<CodeBlocks>
```html title="Widget embed code"
<elevenlabs-convai agent-id="<replace-with-your-agent-id>"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</CodeBlocks>
<Info>
For enhanced security, define allowed domains in your agent's **Allowlist** (located in the
**Security** tab). This restricts access to specified hosts only.
</Info>
## Widget attributes
This basic embed code will display the widget with the default configuration defined in the agent's dashboard.
The widget supports various HTML attributes for further customization:
<AccordionGroup>
<Accordion title="Core configuration">
```html
<elevenlabs-convai
agent-id="agent_id"              // Required: Your agent ID
signed-url="signed_url"          // Alternative to agent-id
server-location="us"             // Optional: "us" or default
variant="expanded"               // Optional: Widget display mode
></elevenlabs-convai>
```
</Accordion>
<Accordion title="Visual customization">
```html
<elevenlabs-convai
avatar-image-url="https://..." // Optional: Custom avatar image
avatar-orb-color-1="#6DB035" // Optional: Orb gradient color 1
avatar-orb-color-2="#F5CABB" // Optional: Orb gradient color 2
></elevenlabs-convai>
```
</Accordion>
<Accordion title="Text customization">
```html
<elevenlabs-convai
action-text="Need assistance?"         // Optional: CTA button text
start-call-text="Begin conversation"   // Optional: Start call button
end-call-text="End call"              // Optional: End call button
expand-text="Open chat"               // Optional: Expand widget text
listening-text="Listening..."         // Optional: Listening state
speaking-text="Assistant speaking"     // Optional: Speaking state
></elevenlabs-convai>
```
</Accordion>
</AccordionGroup>
## Runtime configuration
Two more html attributes can be used to customize the agent's behavior at runtime. These two features can be used together, separately, or not at all
### Dynamic variables
Dynamic variables allow you to inject runtime values into your agent's messages, system prompts, and tools.
```html
<elevenlabs-convai
agent-id="your-agent-id"
dynamic-variables='{"user_name": "John", "account_type": "premium"}'
></elevenlabs-convai>
```
All dynamic variables that the agent requires must be passed in the widget.
<Info>
See more in our [dynamic variables
guide](/docs/conversational-ai/customization/personalization/dynamic-variables).
</Info>
### Overrides
Overrides enable complete customization of your agent's behavior at runtime:
```html
<elevenlabs-convai
agent-id="your-agent-id"
override-config='{
"agent": {
"prompt": {
"prompt": "Custom system prompt for this user"
},
"first_message": "Hi! How can I help you today?",
"language": "es"
}
}'
></elevenlabs-convai>
```
Overrides can be enabled for specific fields, and are entirely optional.
<Info>
See more in our [overrides
guide](/docs/conversational-ai/customization/personalization/overrides).
</Info>
## Visual customization
Customize the widget's appearance, text content, language selection, and more in the [dashboard](https://elevenlabs.io/app/conversational-ai/dashboard) **Widget** tab.
<Frame background="subtle">
![Widget customization](file:16412a8a-33ef-4051-91b2-f12a3d0e8385)
</Frame>
<Tabs>
<Tab title="Appearance">
Customize the widget colors and shapes to match your brand identity.
<Frame background="subtle">
![Widget appearance](file:49979b4c-3da5-4335-9801-9156f4711cbb)
</Frame>
</Tab>
<Tab title="Feedback">
Gather user insights to improve agent performance. This can be used to fine-tune your agent's knowledge-base & system prompt.
<Frame background="subtle">
![Widget feedback](file:531b95a2-61b8-46e0-bbc4-b03db6871b26)
</Frame>
**Collection modes**
* <strong>None</strong>: Disable feedback collection entirely.
* <strong>During conversation</strong>: Support real-time feedback during conversations. Additionnal metadata such as the agent response that prompted the feedback will be collected to help further identify gaps.
* <strong>After conversation</strong>: Display a single feedback prompt after the conversation.
<Note>
Send feedback programmatically via the [API](docs/conversational-ai/api-reference/conversations/post-conversation-feedback) when using custom SDK implementations.
</Note>
</Tab>
<Tab title="Avatar">
Configure the voice orb or provide your own avatar.
<Frame background="subtle">
![Widget orb customization](file:db16777d-c1d2-4832-8b39-89397a25c8fd)
</Frame>
**Available options**
* <strong>Orb</strong>: Choose two gradient colors (e.g., #6DB035 & #F5CABB).
* <strong>Link/image</strong>: Use a custom avatar image.
</Tab>
<Tab title="Display text">
Customize all displayed widget text elements, for example to modify button labels.
<Frame background="subtle">
![Widget text contents](file:83f7686a-6e38-4a1c-9031-1a2a2445dfb4)
</Frame>
</Tab>
<Tab title="Terms">
Display custom terms and conditions before the conversation.
<Frame background="subtle">
![Terms setup](file:2fd172cc-67a2-4c52-9239-ad4cef4e0a0b)
</Frame>
**Available options**
* <strong>Terms content</strong>: Use Markdown to format your policy text.
* <strong>Local storage key</strong>: A key (e.g., "terms\_accepted") to avoid prompting returning users.
**Usage**
The terms are displayed to users in a modal before starting the call:
<Frame background="subtle">
![Terms display](file:112c3874-b93e-42c0-9f9e-b7c34c346fcb)
</Frame>
The terms can be written in Markdown, allowing you to:
* Add links to external policies
* Format text with headers and lists
* Include emphasis and styling
For more help with Markdown, see the [CommonMark help guide](https://commonmark.org/help/).
<Info>
Once accepted, the status is stored locally and the user won't be prompted again on subsequent
visits.
</Info>
</Tab>
<Tab title="Language">
Enable multi-language support in the widget.
![Widget language](file:4414cca2-d8ab-42c9-8b66-51980ece2097)
<Note>
To enable language selection, you must first [add additional
languages](/docs/conversational-ai/customization/language) to your agent.
</Note>
</Tab>
<Tab title="Shareable page">
Customize your public widget landing page (shareable link).
<Frame background="subtle">
![Widget shareable page](file:38399337-4ef3-40cc-8df4-f5a95d7f490c)
</Frame>
**Available options**
* <strong>Description</strong>: Provide a short paragraph explaining the purpose of the call.
</Tab>
</Tabs>
***
## Advanced implementation
<Note>
For more advanced customization, you should use the type-safe [Conversational AI
SDKs](/docs/conversational-ai/libraries) with a Next.js, React, or Python application.
</Note>
### Client Tools
Client tools allow you to extend the functionality of the widget by adding event listeners. This enables the widget to perform actions such as:
* Redirecting the user to a specific page
* Sending an email to your support team
* Redirecting the user to an external URL
To see examples of these tools in action, start a call with the agent in the bottom right corner of this page. The [source code is available on GitHub](https://github.com/elevenlabs/elevenlabs-docs/blob/main/fern/assets/scripts/widget.js) for reference.
#### Creating a Client Tool
To create your first client tool, follow the [client tools guide](/docs/conversational-ai/customization/tools-events/client-tools).
<Accordion title="Example: Creating the `redirectToExternalURL` Tool">
<Frame background="subtle">
![Client tool configuration](file:66fe1702-aedc-4a12-996d-c2aa273aa9f3)
</Frame>
</Accordion>
#### Example Implementation
Below is an example of how to handle the `redirectToExternalURL` tool triggered by the widget in your JavaScript code:
<CodeBlocks>
```javascript title="index.js"
document.addEventListener('DOMContentLoaded', () => {
const widget = document.querySelector('elevenlabs-convai');
if (widget) {
// Listen for the widget's "call" event to trigger client-side tools
widget.addEventListener('elevenlabs-convai:call', (event) => {
event.detail.config.clientTools = {
// Note: To use this example, the client tool called "redirectToExternalURL" (case-sensitive) must have been created with the configuration defined above.
redirectToExternalURL: ({ url }) => {
window.open(url, '_blank', 'noopener,noreferrer');
},
};
});
}
});
```
</CodeBlocks>
<Info>
Explore our type-safe [SDKs](/docs/conversational-ai/libraries) for React, Next.js, and Python
implementations.
</Info>
# Conversation flow
> Configure how your assistant handles timeouts and interruptions during conversations.
## Overview
Conversation flow settings determine how your assistant handles periods of user silence and interruptions during speech. These settings help create more natural conversations and can be customized based on your use case.
<CardGroup cols={2}>
<Card title="Timeouts" icon="clock" href="#timeouts">
Configure how long your assistant waits during periods of silence
</Card>
<Card title="Interruptions" icon="hand" href="#interruptions">
Control whether users can interrupt your assistant while speaking
</Card>
</CardGroup>
## Timeouts
Timeout handling determines how long your assistant will wait during periods of user silence before prompting for a response.
### Configuration
Timeout settings can be configured in the agent's **Advanced** tab under **Turn Timeout**.
The timeout duration is specified in seconds and determines how long the assistant will wait in silence before prompting the user. Turn timeouts must be between 1 and 30 seconds.
#### Example Timeout Settings
<Frame background="subtle">
![Timeout settings](file:64620b4a-794a-436c-bf92-27e0d71d08e0)
</Frame>
<Note>
Choose an appropriate timeout duration based on your use case. Shorter timeouts create more
responsive conversations but may interrupt users who need more time to respond, leading to a less
natural conversation.
</Note>
### Best practices for timeouts
* Set shorter timeouts (5-10 seconds) for casual conversations where quick back-and-forth is expected
* Use longer timeouts (10-30 seconds) when users may need more time to think or formulate complex responses
* Consider your user context - customer service may benefit from shorter timeouts while technical support may need longer ones
## Interruptions
Interruption handling determines whether users can interrupt your assistant while it's speaking.
### Configuration
Interruption settings can be configured in the agent's **Advanced** tab under **Client Events**.
To enable interruptions, make sure interruption is a selected client event.
#### Interruptions Enabled
<Frame background="subtle">
![Interruption allowed](file:938cbf53-621b-40d8-93e0-5f0d084206ea)
</Frame>
#### Interruptions Disabled
<Frame background="subtle">
![Interruption ignored](file:6a2bf5d3-896c-468c-9e35-8032e9554eb0)
</Frame>
<Note>
Disable interruptions when the complete delivery of information is crucial, such as legal
disclaimers or safety instructions.
</Note>
### Best practices for interruptions
* Enable interruptions for natural conversational flows where back-and-forth dialogue is expected
* Disable interruptions when message completion is critical (e.g., terms and conditions, safety information)
* Consider your use case context - customer service may benefit from interruptions while information delivery may not
## Recommended configurations
<AccordionGroup>
<Accordion title="Customer service">
* Shorter timeouts (5-10 seconds) for responsive interactions - Enable interruptions to allow
customers to interject with questions
</Accordion>
<Accordion title="Legal disclaimers">
* Longer timeouts (15-30 seconds) to allow for complex responses - Disable interruptions to
ensure full delivery of legal information
</Accordion>
<Accordion title="Conversational EdTech">
* Longer timeouts (10-30 seconds) to allow time to think and formulate responses - Enable
interruptions to allow students to interject with questions
</Accordion>
</AccordionGroup>
# Authentication
> Learn how to secure access to your conversational AI agents
## Overview
When building conversational AI agents, you may need to restrict access to certain agents or conversations. ElevenLabs provides multiple authentication mechanisms to ensure only authorized users can interact with your agents.
## Authentication methods
ElevenLabs offers two primary methods to secure your conversational AI agents:
<CardGroup cols={2}>
<Card title="Signed URLs" icon="signature" href="#using-signed-urls">
Generate temporary authenticated URLs for secure client-side connections without exposing API
keys.
</Card>
<Card title="Allowlists" icon="list-check" href="#using-allowlists">
Restrict access to specific domains or hostnames that can connect to your agent.
</Card>
</CardGroup>
## Using signed URLs
Signed URLs are the recommended approach for client-side applications. This method allows you to authenticate users without exposing your API key.
<Note>
The guides below uses the [JS client](https://www.npmjs.com/package/@11labs/client) and [Python
SDK](https://github.com/elevenlabs/elevenlabs-python/).
</Note>
### How signed URLs work
1. Your server requests a signed URL from ElevenLabs using your API key.
2. ElevenLabs generates a temporary token and returns a signed WebSocket URL.
3. Your client application uses this signed URL to establish a WebSocket connection.
4. The signed URL expires after 15 minutes.
<Warning>
Never expose your ElevenLabs API key client-side.
</Warning>
### Generate a signed URL via the API
To obtain a signed URL, make a request to the `get_signed_url` [endpoint](/docs/conversational-ai/api-reference/conversations/get-signed-url) with your agent ID:
<CodeBlocks>
```python
# Server-side code using the Python SDK
from elevenlabs.client import ElevenLabs
async def get_signed_url():
try:
client = ElevenLabs(api_key="your-api-key")
response = await client.conversational_ai.get_signed_url(agent_id="your-agent-id")
return response.signed_url
except Exception as error:
print(f"Error getting signed URL: {error}")
raise
```
```javascript
import { ElevenLabsClient } from 'elevenlabs';
// Server-side code using the JavaScript SDK
const client = new ElevenLabsClient({ apiKey: 'your-api-key' });
async function getSignedUrl() {
try {
const response = await client.conversationalAi.getSignedUrl({
agent_id: 'your-agent-id',
});
return response.signed_url;
} catch (error) {
console.error('Error getting signed URL:', error);
throw error;
}
}
```
```bash
curl -X GET "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=your-agent-id" \
-H "xi-api-key: your-api-key"
```
</CodeBlocks>
The curl response has the following format:
```json
{
"signed_url": "wss://api.elevenlabs.io/v1/convai/conversation?agent_id=your-agent-id&conversation_signature=your-token"
}
```
### Connecting to your agent using a signed URL
Retrieve the server generated signed URL from the client and use the signed URL to connect to the websocket.
<CodeBlocks>
```python
# Client-side code using the Python SDK
from elevenlabs.conversational_ai.conversation import (
Conversation,
AudioInterface,
ClientTools,
ConversationInitiationData
)
import os
from elevenlabs.client import ElevenLabs
api_key = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(api_key=api_key)
conversation = Conversation(
client=client,
agent_id=os.getenv("AGENT_ID"),
requires_auth=True,
audio_interface=AudioInterface(),
config=ConversationInitiationData()
)
async def start_conversation():
try:
signed_url = await get_signed_url()
conversation = Conversation(
client=client,
url=signed_url,
)
conversation.start_session()
except Exception as error:
print(f"Failed to start conversation: {error}")
```
```javascript
// Client-side code using the JavaScript SDK
import { Conversation } from '@11labs/client';
async function startConversation() {
try {
const signedUrl = await getSignedUrl();
const conversation = await Conversation.startSession({
signedUrl,
});
return conversation;
} catch (error) {
console.error('Failed to start conversation:', error);
throw error;
}
}
```
</CodeBlocks>
### Signed URL expiration
Signed URLs are valid for 15 minutes. The conversation session can last longer, but the conversation must be initiated within the 15 minute window.
## Using allowlists
Allowlists provide a way to restrict access to your conversational AI agents based on the origin domain. This ensures that only requests from approved domains can connect to your agent.
### How allowlists work
1. You configure a list of approved hostnames for your agent.
2. When a client attempts to connect, ElevenLabs checks if the request's origin matches an allowed hostname.
3. If the origin is on the allowlist, the connection is permitted; otherwise, it's rejected.
### Configuring allowlists
Allowlists are configured as part of your agent's authentication settings. You can specify up to 10 unique hostnames that are allowed to connect to your agent.
### Example: setting up an allowlist
<CodeBlocks>
```python
from elevenlabs.client import ElevenLabs
import os
from elevenlabs.types import *
api_key = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(api_key=api_key)
agent = client.conversational_ai.create_agent(
conversation_config=ConversationalConfig(
agent=AgentConfig(
first_message="Hi. I'm an authenticated agent.",
)
),
platform_settings=AgentPlatformSettingsRequestModel(
auth=AuthSettings(
enable_auth=False,
allowlist=[
AllowlistItem(hostname="example.com"),
AllowlistItem(hostname="app.example.com"),
AllowlistItem(hostname="localhost:3000")
]
)
)
)
```
```javascript
async function createAuthenticatedAgent(client) {
try {
const agent = await client.conversationalAi.createAgent({
conversation_config: {
agent: {
first_message: "Hi. I'm an authenticated agent.",
},
},
platform_settings: {
auth: {
enable_auth: false,
allowlist: [
{ hostname: 'example.com' },
{ hostname: 'app.example.com' },
{ hostname: 'localhost:3000' },
],
},
},
});
return agent;
} catch (error) {
console.error('Error creating agent:', error);
throw error;
}
}
```
</CodeBlocks>
## Combining authentication methods
For maximum security, you can combine both authentication methods:
1. Use `enable_auth` to require signed URLs.
2. Configure an allowlist to restrict which domains can request those signed URLs.
This creates a two-layer authentication system where clients must:
* Connect from an approved domain
* Possess a valid signed URL
<CodeBlocks>
```python
from elevenlabs.client import ElevenLabs
import os
from elevenlabs.types import *
api_key = os.getenv("ELEVENLABS_API_KEY")
client = ElevenLabs(api_key=api_key)
agent = client.conversational_ai.create_agent(
conversation_config=ConversationalConfig(
agent=AgentConfig(
first_message="Hi. I'm an authenticated agent that can only be called from certain domains.",
)
),
platform_settings=AgentPlatformSettingsRequestModel(
auth=AuthSettings(
enable_auth=True,
allowlist=[
AllowlistItem(hostname="example.com"),
AllowlistItem(hostname="app.example.com"),
AllowlistItem(hostname="localhost:3000")
]
)
)
)
```
```javascript
async function createAuthenticatedAgent(client) {
try {
const agent = await client.conversationalAi.createAgent({
conversation_config: {
agent: {
first_message: "Hi. I'm an authenticated agent.",
},
},
platform_settings: {
auth: {
enable_auth: true,
allowlist: [
{ hostname: 'example.com' },
{ hostname: 'app.example.com' },
{ hostname: 'localhost:3000' },
],
},
},
});
return agent;
} catch (error) {
console.error('Error creating agent:', error);
throw error;
}
}
```
</CodeBlocks>
## FAQ
<AccordionGroup>
<Accordion title="Can I use the same signed URL for multiple users?">
This is possible but we recommend generating a new signed URL for each user session.
</Accordion>
<Accordion title="What happens if the signed URL expires during a conversation?">
If the signed URL expires (after 15 minutes), any WebSocket connection created with that signed
url will **not** be closed, but trying to create a new connection with that signed URL will
fail.
</Accordion>
<Accordion title="Can I restrict access to specific users?">
The signed URL mechanism only verifies that the request came from an authorized source. To
restrict access to specific users, implement user authentication in your application before
requesting the signed URL.
</Accordion>
<Accordion title="Is there a limit to how many signed URLs I can generate?">
There is no specific limit on the number of signed URLs you can generate.
</Accordion>
<Accordion title="How do allowlists handle subdomains?">
Allowlists perform exact matching on hostnames. If you want to allow both a domain and its
subdomains, you need to add each one separately (e.g., "example.com" and "app.example.com").
</Accordion>
<Accordion title="Do I need to use both authentication methods?">
No, you can use either signed URLs or allowlists independently based on your security
requirements. For highest security, we recommend using both.
</Accordion>
<Accordion title="What other security measures should I implement?">
Beyond signed URLs and allowlists, consider implementing:
* User authentication before requesting signed URLs
* Rate limiting on API requests
* Usage monitoring for suspicious patterns
* Proper error handling for auth failures
</Accordion>
</AccordionGroup>
# Privacy
> Manage how your agent handles data storage and privacy.
Privacy settings give you fine-grained control over your data. You can manage both call audio recordings and conversation data retention to meet your compliance and privacy requirements.
<CardGroup cols={2}>
<Card title="Retention" icon="database" href="/docs/conversational-ai/customization/privacy/retention">
Configure how long conversation transcripts and audio recordings are retained.
</Card>
<Card title="Audio Saving" icon="microphone" href="/docs/conversational-ai/customization/privacy/audio-saving">
Control whether call audio recordings are retained.
</Card>
</CardGroup>
## Retention
Retention settings control the duration for which conversation transcripts and audio recordings are stored.
For detailed instructions, see our [Retention](/docs/conversational-ai/customization/privacy/retention) page.
## Audio Saving
Audio Saving settings determine if call audio recordings are stored. Adjust this feature based on your privacy and data retention needs.
For detailed instructions, see our [Audio Saving](/docs/conversational-ai/customization/privacy/audio-saving) page.
## Recommended Privacy Configurations
<AccordionGroup>
<Accordion title="Maximum Privacy">
Disable audio saving and set retention to 0 days for immediate deletion of data.
</Accordion>
<Accordion title="Balanced Privacy">
Enable audio saving for critical interactions while setting a moderate retention period.
</Accordion>
<Accordion title="Compliance Focus">
Enable audio saving and configure retention settings to adhere to regulatory requirements such
as GDPR and HIPAA. For HIPAA compliance, we recommend enabling audio saving and setting a
retention period of at least 6 years. For GDPR, retention periods should align with your data
processing purposes.
</Accordion>
</AccordionGroup>
# Retention
> Control how long your agent retains conversation history and recordings.
**Retention** settings allow you to configure how long your Conversational AI agent stores conversation transcripts and audio recordings. These settings help you comply with data privacy regulations.
## Overview
By default, ElevenLabs retains conversation data for 2 years. You can modify this period to:
* Any number of days (e.g., 30, 90, 365)
* Unlimited retention by setting the value to -1
* Immediate deletion by setting the value to 0
The retention settings apply separately to:
* **Conversation transcripts**: Text records of all interactions
* **Audio recordings**: Voice recordings from both the user and agent
<Info>
For GDPR compliance, we recommend setting retention periods that align with your data processing
purposes. For HIPAA compliance, retain records for a minimum of 6 years.
</Info>
## Modifying retention settings
### Prerequisites
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs Conversational Agent ([create one here](/docs/conversational-ai/quickstart))
Follow these steps to update your retention settings:
<Steps>
<Step title="Access retention settings">
Navigate to your agent's settings and select the "Advanced" tab. The retention settings are located in the "Data Retention" section.
<Frame background="subtle">
![Enable overrides](file:442cf8bb-5f5d-4352-a84e-d8f4c0d03e0e)
</Frame>
</Step>
<Step title="Update retention period">
1. Enter the desired retention period in days
2. Choose whether to apply changes to existing data
3. Click "Save" to confirm changes
<Frame background="subtle">
![Enable overrides](file:f446acc4-e9b3-4665-bdd1-2c83894d98d5)
</Frame>
When modifying retention settings, you'll have the option to apply the new retention period to existing conversation data or only to new conversations going forward.
</Step>
</Steps>
<Warning>
Reducing the retention period may result in immediate deletion of data older than the new
retention period if you choose to apply changes to existing data.
</Warning>
# Audio saving
> Control whether call audio recordings are retained.
**Audio Saving** settings allow you to choose whether recordings of your calls are retained in your call history, on a per-agent basis. This control gives you flexibility over data storage and privacy.
## Overview
By default, audio recordings are enabled. You can modify this setting to:
* **Enable audio saving**: Save call audio for later review.
* **Disable audio saving**: Omit audio recordings from your call history.
<Info>
Disabling audio saving enhances privacy but limits the ability to review calls. However,
transcripts can still be viewed. To modify transcript retention settings, please refer to the
[retention](/docs/conversational-ai/customization/privacy/retention) documentation.
</Info>
## Modifying Audio Saving Settings
### Prerequisites
* A configured [ElevenLabs Conversational Agent](/docs/conversational-ai/quickstart)
Follow these steps to update your audio saving preference:
<Steps>
<Step title="Access audio saving settings">
Find your agent in the Conversational AI agents
[page](https://elevenlabs.io/app/conversational-ai/agents) and select the "Advanced" tab. The
audio saving control is located in the "Privacy Settings" section.
<Frame background="subtle">
![Disable audio saving option](file:f82518d6-629c-4133-8764-d71d816eb141)
</Frame>
</Step>
<Step title="Choose saving option">
Toggle the control to enable or disable audio saving and click save to confirm your selection.
</Step>
<Step title="Review call history">
When audio saving is enabled, calls in the call history allow you to review the audio.
<Frame background="subtle">
![Call with audio saved](file:9b5d7a25-ed98-45dd-b2ca-899741319ef8)
</Frame>
When audio saving is disabled, calls in the call history do not include audio.
<Frame background="subtle">
![Call without audio saved](file:883f69a8-1554-437e-bb9d-6ec0d618168a)
</Frame>
</Step>
</Steps>
<Warning>
Disabling audio saving will prevent new call audio recordings from being stored. Existing
recordings will remain until deleted via [retention
settings](/docs/conversational-ai/customization/privacy/retention).
</Warning>
# HIPAA compliance
> Learn how ElevenLabs Conversational AI supports HIPAA compliance for healthcare applications
<Warning>
This guide is a technical overview of our HIPAA compliance. Please refer to our [compliance
page](https://compliance.elevenlabs.io/) for the latest information.
</Warning>
## Overview
ElevenLabs Conversational AI is one of ElevenLabs’ HIPAA-eligible services, and we offer Business Associate Agreements (BAAs) to eligible customers. This service enables Covered Entities and Business Associates, as defined under HIPAA, to develop AI-powered voice agents capable of handling Protected Health Information (PHI) while ensuring regulatory compliance.
Once a BAA is in place and Zero Retention Mode is enabled, PHI remains securely protected throughout the entire conversation lifecycle, ensuring full compliance with HIPAA’s data protection requirements.
## How HIPAA compliance works
When HIPAA compliance is required for a workspace, the following policies are enabled:
1. **Zero Retention Mode** - All sensitive data from conversations is automatically redacted before storage. This also applies to derivative data like LLM-produced transcript summaries, and tool call parameters and results.
2. **LLM Provider Restrictions** - Only LLM from providers with whom we have a BAA in place are available as preconfigured options
3. **Storage Limitations** - Raw audio files and transcripts containing PHI are not retained
<Note>
If you want to use LLMs that aren't available preconfigured in Zero Retention Mode (e.g., OpenAI's GPT-4o mini), you
can still use them in Conversational AI by:
1. Arranging to sign a BAA directly with the LLM provider you'd like to use
2. Using your API key with our Custom LLM integration
</Note>
ElevenLabs' platform ensures that PHI shared as part of a conversation is not inadvertently stored or logged in any system component, including:
* Conversation transcripts
* Audio recordings
* Tool calls and results
* Data analytics
* System logs
<Warning>
For Conversational AI, your BAA applies only to conversation content. Agent configuration data is
persisted, meaning it is not covered by Zero Retention Mode and should not contain PHI.
</Warning>
### Enabling HIPAA compliance
<Note>
HIPAA compliance is only available on Enterprise tier subscriptions and requires a BAA to be in
place between you and ElevenLabs. Contact your account representative to discuss enabling this
feature for your organization.
</Note>
## HIPAA-Compliant LLMs
When operating in Zero Retention Mode, only the following LLMs are available:
<AccordionGroup>
<Accordion title="Google Models">
* Gemini 2.0 Flash
* Gemini 2.0 Flash Lite
* Gemini 1.5 Flash
* Gemini 1.5 Pro
* Gemini 1.0 Pro
</Accordion>
<Accordion title="Anthropic Models">
* Claude 3.7 Sonnet
* Claude 3.5 Sonnet
* Claude 3.0 Haiku
</Accordion>
<Accordion title="Custom LLMs">
* [Custom LLM](/docs/conversational-ai/customization/custom-llm) (supports any OpenAI-API compatible provider and requires you to bring your own API keys)
</Accordion>
</AccordionGroup>
## Technical implementation
Zero Retention Mode implements several safeguards including but not limited to:
1. **LLM Allowlist** - Prevents use of non-compliant LLMs
2. **PII Redaction** - Automatically redacts sensitive fields before storage
3. **Storage Prevention** - Disables uploading of raw audio files to cloud
## Developer experience
When working with Zero Retention Mode agents:
<Steps>
<Step title="Non-compliant LLMs are disabled in the UI">
<Frame background="subtle" caption="The UI shows disabled LLM options with tooltip explanations">
![Redacted conversation analysis showing Zero Retention Mode in
action](file:0d420f7f-1d54-4f92-956f-b65a26e600e4)
</Frame>
</Step>
<Step title="Content is redacted from content history">
<Frame background="subtle" caption="All sensitive information is redacted and not stored">
![Redacted conversation history showing Zero Retention Mode in
action](file:8c432f4f-ad61-4e45-8aad-f6425e7e25e1)
</Frame>
</Step>
<Step title="Conversation analysis is limited">
<Frame background="subtle" caption="Analysis and summaries maintain HIPAA compliance through Zero Retention Mode">
![Redacted conversation analysis showing HIPAA compliance in
action](file:5ca8cdac-fd1d-46ea-9091-db2aee94fdeb)
</Frame>
</Step>
</Steps>
### API restrictions are enforced
API calls attempting to use non-compliant LLMs will receive an HTTP 400 error. Analytics data will be limited to non-sensitive metrics only.
## FAQ
<AccordionGroup>
<Accordion title="Can I use any LLM if HIPAA compliance is required?">
No. When HIPAA compliance is required, you can only use LLMs from the approved list. Attempts to
use non-compliant LLMs will produce an error. You can always use a custom LLM if you need a
specific model not on the allowlist.
</Accordion>
<Accordion title="How do I know if my workspace is HIPAA compliant?">
HIPAA compliance is only available to enterprise customers. Please refer to your account
executive to check if this is enabled.
</Accordion>
<Accordion title="Does HIPAA compliance affect conversation quality?">
No. HIPAA compliance only affects how data is stored and which LLMs can be used. It does not
impact the quality or functionality of conversations while they are active.
</Accordion>
<Accordion title="Can I still analyze conversation data if my agent is HIPAA compliant?">
Yes, but with limitations. Conversation analytics will only include non-sensitive metadata like
call duration and success rates. Specific content from conversations will be redacted.
</Accordion>
</AccordionGroup>
## Best practices
When building HIPAA-compliant voice agents:
1. **Use Custom LLMs** when possible for maximum control over data processing
2. **Implement proper authentication** for all healthcare applications
3. **Validate configuration** is correct by checking redaction before launching + passing PHI
## Related resources
<CardGroup cols={2}>
<Card title="Conversational AI Security" href="/docs/conversational-ai/customization/authentication">
Learn about securing your Conversational AI agents
</Card>
<Card title="Custom LLM Integration" href="/docs/conversational-ai/customization/custom-llm">
Set up your own LLM for maximum control and compliance
</Card>
</CardGroup>
# Post-call webhooks
> Get notified when calls end and analysis is complete through webhooks.
## Overview
Post-call [Webhooks](/docs/product-guides/administration/webhooks) allow you to receive detailed information about a call after analysis is complete. When enabled, ElevenLabs will send a POST request to your specified endpoint with comprehensive call data, including transcripts, analysis results, and metadata.
The data that is returned is the same data that is returned from the [Conversation API](/docs/conversational-ai/api-reference/conversations/get-conversations).
## Enabling post-call webhooks
Post-call webhooks can be enabled for all agents in your workspace through the Conversational AI [settings page](https://elevenlabs.io/app/conversational-ai/settings).
<Frame background="subtle">
![Post-call webhook settings](file:0d846c05-8494-4cc3-be3a-1124520982de)
</Frame>
<Warning>
Post call webhooks must return a 200 status code to be considered successful. Webhooks that
repeatedly fail are auto disabled if there are 10 or more consecutive failures and the last
successful delivery was more than 7 days ago or has never been successfully delivered.
</Warning>
<Note>
For HIPAA compliance, if a webhook fails we can not retry the webhook.
</Note>
### Authentication
It is important for the listener to validate all incoming webhooks. Webhooks currently support authentication via HMAC signatures. Set up HMAC authentication by:
* Securely storing the shared secret generated upon creation of the webhook
* Verifying the ElevenLabs-Signature header in your endpoint using the shared secret
The ElevenLabs-Signature takes the following format:
```json
t=timestamp,v0=hash
```
The hash is equivalent to the hex encoded sha256 HMAC signature of `timestamp.request_body`. Both the hash and timestamp should be validated, an example is shown here:
<Tabs>
<Tab title="Python">
Example python webhook handler using FastAPI:
```python
from fastapi import FastAPI, Request
import time
import hmac
from hashlib import sha256
app = FastAPI()
# Example webhook handler
@app.post("/webhook")
async def receive_message(request: Request):
payload = await request.body()
headers = request.headers.get("elevenlabs-signature")
if headers is None:
return
timestamp = headers.split(",")[0][2:]
hmac_signature = headers.split(",")[1]
# Validate timestamp
tolerance = int(time.time()) - 30 * 60
if int(timestamp) < tolerance
return
# Validate signature
full_payload_to_sign = f"{timestamp}.{payload.decode('utf-8')}"
mac = hmac.new(
key=secret.encode("utf-8"),
msg=full_payload_to_sign.encode("utf-8"),
digestmod=sha256,
)
digest = 'v0=' + mac.hexdigest()
if hmac_signature != digest:
return
# Continue processing
return {"status": "received"}
```
</Tab>
<Tab title="JavaScript">
<Tabs>
<Tab title="Express">
Example javascript webhook handler using node express framework:
```javascript
const crypto = require('crypto');
const secret = process.env.WEBHOOK_SECRET;
const bodyParser = require('body-parser');
// Ensure express js is parsing the raw body through instead of applying it's own encoding
app.use(bodyParser.raw({ type: '*/*' }));
// Example webhook handler
app.post('/webhook/elevenlabs', async (req, res) => {
const headers = req.headers['ElevenLabs-Signature'].split(',');
const timestamp = headers.find((e) => e.startsWith('t=')).substring(2);
const signature = headers.find((e) => e.startsWith('v0='));
// Validate timestamp
const reqTimestamp = timestamp * 1000;
const tolerance = Date.now() - 30 * 60 * 1000;
if (reqTimestamp < tolerance) {
res.status(403).send('Request expired');
return;
} else {
// Validate hash
const message = `${timestamp}.${req.body}`;
const digest = 'v0=' + crypto.createHmac('sha256', secret).update(message).digest('hex');
if (signature !== digest) {
res.status(401).send('Request unauthorized');
return;
}
}
// Validation passed, continue processing ...
res.status(200).send();
});
```
</Tab>
<Tab title="Next.js">
Example javascript webhook handler using Next.js API route:
```javascript app/api/convai-webhook/route.js
import { NextResponse } from "next/server";
import type { NextRequest } from "next/server";
import crypto from "crypto";
export async function GET() {
return NextResponse.json({ status: "webhook listening" }, { status: 200 });
}
export async function POST(req: NextRequest) {
const secret = process.env.ELEVENLABS_CONVAI_WEBHOOK_SECRET; // Add this to your env variables
const { event, error } = await constructWebhookEvent(req, secret);
if (error) {
return NextResponse.json({ error: error }, { status: 401 });
}
if (event.type === "post_call_transcription") {
console.log("event data", JSON.stringify(event.data, null, 2));
}
return NextResponse.json({ received: true }, { status: 200 });
}
const constructWebhookEvent = async (req: NextRequest, secret?: string) => {
const body = await req.text();
const signature_header = req.headers.get("ElevenLabs-Signature");
console.log(signature_header);
if (!signature_header) {
return { event: null, error: "Missing signature header" };
}
const headers = signature_header.split(",");
const timestamp = headers.find((e) => e.startsWith("t="))?.substring(2);
const signature = headers.find((e) => e.startsWith("v0="));
if (!timestamp || !signature) {
return { event: null, error: "Invalid signature format" };
}
// Validate timestamp
const reqTimestamp = Number(timestamp) * 1000;
const tolerance = Date.now() - 30 * 60 * 1000;
if (reqTimestamp < tolerance) {
return { event: null, error: "Request expired" };
}
// Validate hash
const message = `${timestamp}.${body}`;
if (!secret) {
return { event: null, error: "Webhook secret not configured" };
}
const digest =
"v0=" + crypto.createHmac("sha256", secret).update(message).digest("hex");
console.log({ digest, signature });
if (signature !== digest) {
return { event: null, error: "Invalid signature" };
}
const event = JSON.parse(body);
return { event, error: null };
};
```
</Tab>
</Tabs>
</Tab>
</Tabs>
### IP whitelisting
For additional security, you can whitelist the following static egress IPs from which all ElevenLabs webhook requests originate:
| Region       | IP Address     |
| ------------ | -------------- |
| US (Default) | 34.67.146.145  |
| EU           | 35.204.38.71   |
| Asia         | 35.185.187.110 |
If your infrastructure requires strict IP-based access controls, adding these IPs to your firewall allowlist will ensure you only receive webhook requests from ElevenLabs' systems.
<Note>
These static IPs are used across all ElevenLabs webhook services and will remain consistent. Using
IP whitelisting in combination with HMAC signature validation provides multiple layers of
security.
</Note>
## Webhook response structure
The webhook payload contains the same data you would receive from a GET request to the Conversation API endpoint, with additional fields for event timing and type information.
### Top-level fields
| Field             | Type   | Description                                                    |
| ----------------- | ------ | -------------------------------------------------------------- |
| `type`            | string | Type of event (always `post_call_transcription` in this case)  |
| `data`            | object | Data for the conversation, what would be returned from the API |
| `event_timestamp` | number | When this event occurred in unix time UTC                      |
## Example webhook payload
```json
{
"type": "post_call_transcription",
"event_timestamp": 1739537297,
"data": {
"agent_id": "xyz",
"conversation_id": "abc",
"status": "done",
"transcript": [
{
"role": "agent",
"message": "Hey there angelo. How are you?",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 0,
"conversation_turn_metrics": null
},
{
"role": "user",
"message": "Hey, can you tell me, like, a fun fact about 11 Labs?",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 2,
"conversation_turn_metrics": null
},
{
"role": "agent",
"message": "I do not have access to fun facts about Eleven Labs. However, I can share some general information about the company. Eleven Labs is an AI voice technology platform that specializes in voice cloning and text-to-speech...",
"tool_calls": null,
"tool_results": null,
"feedback": null,
"time_in_call_secs": 9,
"conversation_turn_metrics": {
"convai_llm_service_ttfb": {
"elapsed_time": 0.3704247010173276
},
"convai_llm_service_ttf_sentence": {
"elapsed_time": 0.5551181449554861
}
}
}
],
"metadata": {
"start_time_unix_secs": 1739537297,
"call_duration_secs": 22,
"cost": 296,
"deletion_settings": {
"deletion_time_unix_secs": 1802609320,
"deleted_logs_at_time_unix_secs": null,
"deleted_audio_at_time_unix_secs": null,
"deleted_transcript_at_time_unix_secs": null,
"delete_transcript_and_pii": true,
"delete_audio": true
},
"feedback": {
"overall_score": null,
"likes": 0,
"dislikes": 0
},
"authorization_method": "authorization_header",
"charging": {
"dev_discount": true
},
"termination_reason": ""
},
"analysis": {
"evaluation_criteria_results": {},
"data_collection_results": {},
"call_successful": "success",
"transcript_summary": "The conversation begins with the agent asking how Angelo is, but Angelo redirects the conversation by requesting a fun fact about 11 Labs. The agent acknowledges they don't have specific fun facts about Eleven Labs but offers to provide general information about the company. They briefly describe Eleven Labs as an AI voice technology platform specializing in voice cloning and text-to-speech technology. The conversation is brief and informational, with the agent adapting to the user's request despite not having the exact information asked for."
},
"conversation_initiation_client_data": {
"conversation_config_override": {
"agent": {
"prompt": null,
"first_message": null,
"language": "en"
},
"tts": {
"voice_id": null
}
},
"custom_llm_extra_body": {},
"dynamic_variables": {
"user_name": "angelo"
}
}
}
}
```
## Use cases
### Automated call follow-ups
Post-call webhooks enable you to build automated workflows that trigger immediately after a call ends. Here are some practical applications:
#### CRM integration
Update your customer relationship management system with conversation data as soon as a call completes:
```javascript
// Example webhook handler
app.post('/webhook/elevenlabs', async (req, res) => {
// HMAC validation code
const { data } = req.body;
// Extract key information
const userId = data.metadata.user_id;
const transcriptSummary = data.analysis.transcript_summary;
const callSuccessful = data.analysis.call_successful;
// Update CRM record
await updateCustomerRecord(userId, {
lastInteraction: new Date(),
conversationSummary: transcriptSummary,
callOutcome: callSuccessful,
fullTranscript: data.transcript,
});
res.status(200).send('Webhook received');
});
```
### Stateful conversations
Maintain conversation context across multiple interactions by storing and retrieving state:
1. When a call starts, pass in your user id as a dynamic variable.
2. When a call ends, set up your webhook endpoint to store conversation data in your database, based on the extracted user id from the dynamic\_variables.
3. When the user calls again, you can retrieve this context and pass it to the new conversation into a \{\{previous\_topics}} dynamic variable.
4. This creates a seamless experience where the agent "remembers" previous interactions
```javascript
// Store conversation state when call ends
app.post('/webhook/elevenlabs', async (req, res) => {
// HMAC validation code
const { data } = req.body;
const userId = data.metadata.user_id;
// Store conversation state
await db.userStates.upsert({
userId,
lastConversationId: data.conversation_id,
lastInteractionTimestamp: data.metadata.start_time_unix_secs,
conversationHistory: data.transcript,
previousTopics: extractTopics(data.analysis.transcript_summary),
});
res.status(200).send('Webhook received');
});
// When initiating a new call, retrieve and use the state
async function initiateCall(userId) {
// Get user's conversation state
const userState = await db.userStates.findOne({ userId });
// Start new conversation with context from previous calls
return await elevenlabs.startConversation({
agent_id: 'xyz',
conversation_id: generateNewId(),
dynamic_variables: {
user_name: userState.name,
previous_conversation_id: userState.lastConversationId,
previous_topics: userState.previousTopics.join(', '),
},
});
}
```
# Next.JS
> Learn how to create a web application that enables voice conversations with ElevenLabs AI agents
This tutorial will guide you through creating a web client that can interact with a Conversational AI agent. You'll learn how to implement real-time voice conversations, allowing users to speak with an AI agent that can listen, understand, and respond naturally using voice synthesis.
## What You'll Need
1. An ElevenLabs agent created following [this guide](/docs/conversational-ai/quickstart)
2. `npm` installed on your local system.
3. We'll use Typescript for this tutorial, but you can use Javascript if you prefer.
<Note>
Looking for a complete example? Check out our [Next.js demo on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/nextjs).
</Note>
<Frame background="subtle">
![](file:1c5c02e5-48b7-46b8-a0d7-eef106422283)
</Frame>
## Setup
<Steps>
<Step title="Create a new Next.js project">
Open a terminal window and run the following command:
```bash
npm create next-app my-conversational-agent
```
It will ask you some questions about how to build your project. We'll follow the default suggestions for this tutorial.
</Step>
<Step title="Navigate to project directory">
```shell
cd my-conversational-agent
```
</Step>
<Step title="Install the ElevenLabs dependency">
```shell
npm install @11labs/react
```
</Step>
<Step title="Test the setup">
Run the following command to start the development server and open the provided URL in your browser:
```shell
npm run dev
```
<Frame background="subtle">
![](file:2b42d5ea-fee5-44a6-a35d-958f59f946f3)
</Frame>
</Step>
</Steps>
## Implement Conversational AI
<Steps>
<Step title="Create the conversation component">
Create a new file `app/components/conversation.tsx`:
```tsx app/components/conversation.tsx
'use client';
import { useConversation } from '@11labs/react';
import { useCallback } from 'react';
export function Conversation() {
const conversation = useConversation({
onConnect: () => console.log('Connected'),
onDisconnect: () => console.log('Disconnected'),
onMessage: (message) => console.log('Message:', message),
onError: (error) => console.error('Error:', error),
});
const startConversation = useCallback(async () => {
try {
// Request microphone permission
await navigator.mediaDevices.getUserMedia({ audio: true });
// Start the conversation with your agent
await conversation.startSession({
agentId: 'YOUR_AGENT_ID', // Replace with your agent ID
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}, [conversation]);
const stopConversation = useCallback(async () => {
await conversation.endSession();
}, [conversation]);
return (
<div className="flex flex-col items-center gap-4">
<div className="flex gap-2">
<button
onClick={startConversation}
disabled={conversation.status === 'connected'}
className="px-4 py-2 bg-blue-500 text-white rounded disabled:bg-gray-300"
>
Start Conversation
</button>
<button
onClick={stopConversation}
disabled={conversation.status !== 'connected'}
className="px-4 py-2 bg-red-500 text-white rounded disabled:bg-gray-300"
>
Stop Conversation
</button>
</div>
<div className="flex flex-col items-center">
<p>Status: {conversation.status}</p>
<p>Agent is {conversation.isSpeaking ? 'speaking' : 'listening'}</p>
</div>
</div>
);
}
```
</Step>
<Step title="Update the main page">
Replace the contents of `app/page.tsx` with:
```tsx app/page.tsx
import { Conversation } from './components/conversation';
export default function Home() {
return (
<main className="flex min-h-screen flex-col items-center justify-between p-24">
<div className="z-10 max-w-5xl w-full items-center justify-between font-mono text-sm">
<h1 className="text-4xl font-bold mb-8 text-center">
ElevenLabs Conversational AI
</h1>
<Conversation />
</div>
</main>
);
}
```
</Step>
</Steps>
<Accordion title="(Optional) Authenticate the agents with a signed URL">
<Note>
This authentication step is only required for private agents. If you're using a public agent, you
can skip this section and directly use the `agentId` in the `startSession` call.
</Note>
If you're using a private agent that requires authentication, you'll need to generate
a signed URL from your server. This section explains how to set this up.
### What You'll Need
1. An ElevenLabs account and API key. Sign up [here](https://www.elevenlabs.io/sign-up).
<Steps>
<Step title="Create environment variables">
Create a `.env.local` file in your project root:
```yaml .env.local
ELEVENLABS_API_KEY=your-api-key-here
NEXT_PUBLIC_AGENT_ID=your-agent-id-here
```
<Warning>
1. Make sure to add `.env.local` to your `.gitignore` file to prevent accidentally committing sensitive credentials to version control.
2. Never expose your API key in the client-side code. Always keep it secure on the server.
</Warning>
</Step>
<Step title="Create an API route">
Create a new file `app/api/get-signed-url/route.ts`:
```tsx app/api/get-signed-url/route.ts
import { NextResponse } from 'next/server';
export async function GET() {
try {
const response = await fetch(
`https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=${process.env.NEXT_PUBLIC_AGENT_ID}`,
{
headers: {
'xi-api-key': process.env.ELEVENLABS_API_KEY!,
},
}
);
if (!response.ok) {
throw new Error('Failed to get signed URL');
}
const data = await response.json();
return NextResponse.json({ signedUrl: data.signed_url });
} catch (error) {
return NextResponse.json(
{ error: 'Failed to generate signed URL' },
{ status: 500 }
);
}
}
```
</Step>
<Step title="Update the Conversation component">
Modify your `conversation.tsx` to fetch and use the signed URL:
```tsx app/components/conversation.tsx {5-12,19,23}
// ... existing imports ...
export function Conversation() {
// ... existing conversation setup ...
const getSignedUrl = async (): Promise<string> => {
const response = await fetch("/api/get-signed-url");
if (!response.ok) {
throw new Error(`Failed to get signed url: ${response.statusText}`);
}
const { signedUrl } = await response.json();
return signedUrl;
};
const startConversation = useCallback(async () => {
try {
// Request microphone permission
await navigator.mediaDevices.getUserMedia({ audio: true });
const signedUrl = await getSignedUrl();
// Start the conversation with your signed url
await conversation.startSession({
signedUrl,
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}, [conversation]);
// ... rest of the component ...
}
```
<Warning>
Signed URLs expire after a short period. However, any conversations initiated before expiration will continue uninterrupted. In a production environment, implement proper error handling and URL refresh logic for starting new conversations.
</Warning>
</Step>
</Steps>
</Accordion>
## Next Steps
Now that you have a basic implementation, you can:
1. Add visual feedback for voice activity
2. Implement error handling and retry logic
3. Add a chat history display
4. Customize the UI to match your brand
<Info>
For more advanced features and customization options, check out the
[@11labs/react](https://www.npmjs.com/package/@11labs/react) package.
</Info>
# Vite (Javascript)
> Learn how to create a web application that enables voice conversations with ElevenLabs AI agents
This tutorial will guide you through creating a web client that can interact with a Conversational AI agent. You'll learn how to implement real-time voice conversations, allowing users to speak with an AI agent that can listen, understand, and respond naturally using voice synthesis.
<Note>
Looking to build with React/Next.js? Check out our [Next.js
guide](/docs/conversational-ai/guides/quickstarts/next-js)
</Note>
## What You'll Need
1. An ElevenLabs agent created following [this guide](/docs/conversational-ai/quickstart)
2. `npm` installed on your local system
3. Basic knowledge of JavaScript
<Note>
Looking for a complete example? Check out our [Vanilla JS demo on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/javascript).
</Note>
## Project Setup
<Steps>
<Step title="Create a Project Directory">
Open a terminal and create a new directory for your project:
```bash
mkdir elevenlabs-conversational-ai
cd elevenlabs-conversational-ai
```
</Step>
<Step title="Initialize npm and Install Dependencies">
Initialize a new npm project and install the required packages:
```bash
npm init -y
npm install vite @11labs/client
```
</Step>
<Step title="Set up Basic Project Structure">
Add this to your `package.json`:
```json package.json {4}
{
"scripts": {
...
"dev:frontend": "vite"
}
}
```
Create the following file structure:
```shell {2,3}
elevenlabs-conversational-ai/
├── index.html
├── script.js
├── package-lock.json
├── package.json
└── node_modules
```
</Step>
</Steps>
## Implementing the Voice Chat Interface
<Steps>
<Step title="Create the HTML Interface">
In `index.html`, set up a simple user interface:
<Frame background="subtle">
![](file:d2abe00b-ffe7-449f-90c8-09cd95484cd3)
</Frame>
```html index.html
<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>ElevenLabs Conversational AI</title>
</head>
<body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
<h1>ElevenLabs Conversational AI</h1>
<div style="margin-bottom: 20px;">
<button id="startButton" style="padding: 10px 20px; margin: 5px;">Start Conversation</button>
<button id="stopButton" style="padding: 10px 20px; margin: 5px;" disabled>Stop Conversation</button>
</div>
<div style="font-size: 18px;">
<p>Status: <span id="connectionStatus">Disconnected</span></p>
<p>Agent is <span id="agentStatus">listening</span></p>
</div>
<script type="module" src="../images/script.js"></script>
</body>
</html>
```
</Step>
<Step title="Implement the Conversation Logic">
In `script.js`, implement the functionality:
```javascript script.js
import { Conversation } from '@11labs/client';
const startButton = document.getElementById('startButton');
const stopButton = document.getElementById('stopButton');
const connectionStatus = document.getElementById('connectionStatus');
const agentStatus = document.getElementById('agentStatus');
let conversation;
async function startConversation() {
try {
// Request microphone permission
await navigator.mediaDevices.getUserMedia({ audio: true });
// Start the conversation
conversation = await Conversation.startSession({
agentId: 'YOUR_AGENT_ID', // Replace with your agent ID
onConnect: () => {
connectionStatus.textContent = 'Connected';
startButton.disabled = true;
stopButton.disabled = false;
},
onDisconnect: () => {
connectionStatus.textContent = 'Disconnected';
startButton.disabled = false;
stopButton.disabled = true;
},
onError: (error) => {
console.error('Error:', error);
},
onModeChange: (mode) => {
agentStatus.textContent = mode.mode === 'speaking' ? 'speaking' : 'listening';
},
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}
async function stopConversation() {
if (conversation) {
await conversation.endSession();
conversation = null;
}
}
startButton.addEventListener('click', startConversation);
stopButton.addEventListener('click', stopConversation);
```
</Step>
<Step title="Start the frontend server">
```shell
npm run dev:frontend
```
</Step>
</Steps>
<Note>
Make sure to replace
`'YOUR_AGENT_ID'`
with your actual agent ID from ElevenLabs.
</Note>
<Accordion title="(Optional) Authenticate with a Signed URL">
<Note>
This authentication step is only required for private agents. If you're using a public agent, you can skip this section and directly use the `agentId` in the `startSession` call.
</Note>
<Steps>
<Step title="Create Environment Variables">
Create a `.env` file in your project root:
```env .env
ELEVENLABS_API_KEY=your-api-key-here
AGENT_ID=your-agent-id-here
```
<Warning>
Make sure to add `.env` to your `.gitignore` file to prevent accidentally committing sensitive credentials.
</Warning>
</Step>
<Step title="Setup the Backend">
1. Install additional dependencies:
```bash
npm install express cors dotenv
```
2. Create a new folder called `backend`:
```shell {2}
elevenlabs-conversational-ai/
├── backend
...
```
</Step>
<Step title="Create the Server">
```javascript backend/server.js
require("dotenv").config();
const express = require("express");
const cors = require("cors");
const app = express();
app.use(cors());
app.use(express.json());
const PORT = process.env.PORT || 3001;
app.get("/api/get-signed-url", async (req, res) => {
try {
const response = await fetch(
`https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=${process.env.AGENT_ID}`,
{
headers: {
"xi-api-key": process.env.ELEVENLABS_API_KEY,
},
}
);
if (!response.ok) {
throw new Error("Failed to get signed URL");
}
const data = await response.json();
res.json({ signedUrl: data.signed_url });
} catch (error) {
console.error("Error:", error);
res.status(500).json({ error: "Failed to generate signed URL" });
}
});
app.listen(PORT, () => {
console.log(`Server running on http://localhost:${PORT}`);
});
```
</Step>
<Step title="Update the Client Code">
Modify your `script.js` to fetch and use the signed URL:
```javascript script.js {2-10,16,19,20}
// ... existing imports and variables ...
async function getSignedUrl() {
const response = await fetch('http://localhost:3001/api/get-signed-url');
if (!response.ok) {
throw new Error(`Failed to get signed url: ${response.statusText}`);
}
const { signedUrl } = await response.json();
return signedUrl;
}
async function startConversation() {
try {
await navigator.mediaDevices.getUserMedia({ audio: true });
const signedUrl = await getSignedUrl();
conversation = await Conversation.startSession({
signedUrl,
// agentId has been removed...
onConnect: () => {
connectionStatus.textContent = 'Connected';
startButton.disabled = true;
stopButton.disabled = false;
},
onDisconnect: () => {
connectionStatus.textContent = 'Disconnected';
startButton.disabled = false;
stopButton.disabled = true;
},
onError: (error) => {
console.error('Error:', error);
},
onModeChange: (mode) => {
agentStatus.textContent = mode.mode === 'speaking' ? 'speaking' : 'listening';
},
});
} catch (error) {
console.error('Failed to start conversation:', error);
}
}
// ... rest of the code ...
```
<Warning>
Signed URLs expire after a short period. However, any conversations initiated before expiration will continue uninterrupted. In a production environment, implement proper error handling and URL refresh logic for starting new conversations.
</Warning>
</Step>
<Step title="Update the package.json">
```json package.json {4,5}
{
"scripts": {
...
"dev:backend": "node backend/server.js",
"dev": "npm run dev:frontend & npm run dev:backend"
}
}
```
</Step>
<Step title="Run the Application">
Start the application with:
```bash
npm run dev
```
</Step>
</Steps>
</Accordion>
## Next Steps
Now that you have a basic implementation, you can:
1. Add visual feedback for voice activity
2. Implement error handling and retry logic
3. Add a chat history display
4. Customize the UI to match your brand
<Info>
For more advanced features and customization options, check out the
[@11labs/client](https://www.npmjs.com/package/@11labs/client) package.
</Info>
# Twilio native integration
> Learn how to configure inbound calls for your agent with Twilio.
## Overview
This guide shows you how to connect a Twilio phone number to your conversational AI agent to handle inbound calls.
You will learn to:
* Import an existing Twilio phone number.
* Link it to your agent to handle inbound calls.
## Guide
### Prerequisites
* A [Twilio account](https://twilio.com/).
* A purchased & provisioned Twilio [phone number](https://www.twilio.com/docs/phone-numbers).
<Steps>
<Step title="Import a Twilio phone number">
In the Conversational AI dashboard, go to the [**Phone Numbers**](https://elevenlabs.io/app/conversational-ai/phone-numbers) tab.
<Frame background="subtle">
![Conversational AI phone numbers page](file:28b0209a-ed30-4993-93b0-517cf1802338)
</Frame>
Next, fill in the following details:
* **Label:** A descriptive name (e.g., `Customer Support Line`).
* **Phone Number:** The Twilio number you want to use.
* **Twilio SID:** Your Twilio Account SID.
* **Twilio Token:** Your Twilio Auth Token.
<Note>
You can find your account SID and auth token [**in the Twilio admin console**](https://www.twilio.com/console).
</Note>
<Tabs>
<Tab title="Conversational AI dashboard">
<Frame background="subtle">
![Phone number configuration](file:00b57251-8962-45be-81c2-3d4a6100a1d7)
</Frame>
</Tab>
<Tab title="Twilio admin console">
Copy the Twilio SID and Auth Token from the [Twilio admin
console](https://www.twilio.com/console).
<Frame background="subtle">
![Phone number details](file:9a0e2ea0-27af-48ce-9aab-ff7d5d1a7745)
</Frame>
</Tab>
</Tabs>
<Note>
ElevenLabs automatically configures the Twilio phone number with the correct settings.
</Note>
<Accordion title="Applied settings">
<Frame background="subtle">
![Twilio phone number configuration](file:b8654647-6952-45e5-b246-0685e58a859a)
</Frame>
</Accordion>
</Step>
<Step title="Assign your agent">
Once the number is imported, select the agent that will handle inbound calls for this phone number.
<Frame background="subtle">
![Select agent for inbound calls](file:a5be94ce-cab3-4025-8aab-91c2bda58032)
</Frame>
</Step>
</Steps>
Test the agent by giving the phone number a call. Your agent is now ready to handle inbound calls and engage with your customers.
<Tip>
Monitor your first few calls in the [Calls History
dashboard](https://elevenlabs.io/app/conversational-ai/history) to ensure everything is working as
expected.
</Tip>
# Twilio custom server
> Learn how to integrate a Conversational AI agent with Twilio to create seamless, human-like voice interactions.
<Warning>
Custom server should be used for **outbound calls only**. Please use our [native
integration](/docs/conversational-ai/guides/twilio/dashboard) for **inbound Twilio calls**.
</Warning>
Connect your ElevenLabs Conversational AI agent to phone calls and create human-like voice experiences using Twilio's Voice API.
## What You'll Need
* An [ElevenLabs account](https://elevenlabs.io)
* A configured ElevenLabs Conversational Agent ([create one here](/docs/conversational-ai/quickstart))
* A [Twilio account](https://www.twilio.com/try-twilio) with an active phone number
* Python 3.7+ or Node.js 16+
* [ngrok](https://ngrok.com/) for local development
## Agent Configuration
Before integrating with Twilio, you'll need to configure your agent to use the correct audio format supported by Twilio.
<Steps>
<Step title="Configure TTS Output">
1. Navigate to your agent settings
2. Go to the Voice Section
3. Select "μ-law 8000 Hz" from the dropdown
<Frame background="subtle">
![](file:f070cbb2-3c55-4275-88b0-22f61858b6f6)
</Frame>
</Step>
<Step title="Set Input Format">
1. Navigate to your agent settings
2. Go to the Advanced Section
3. Select "μ-law 8000 Hz" for the input format
<Frame background="subtle">
![](file:386c0ffa-daba-465b-8895-420c99d0c9b1)
</Frame>
</Step>
</Steps>
## Implementation
<Tabs>
<Tab title="Javascript">
<Note>
Looking for a complete example? Check out this [Javascript implementation](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/twilio/javascript) on GitHub.
</Note>
<Steps>
<Step title="Initialize the Project">
First, set up a new Node.js project:
```bash
mkdir conversational-ai-twilio
cd conversational-ai-twilio
npm init -y; npm pkg set type="module";
```
</Step>
<Step title="Install dependencies">
Next, install the required dependencies for the project.
```bash
npm install @fastify/formbody @fastify/websocket dotenv fastify ws
```
</Step>
<Step title="Create the project files">
Create a `.env` & `index.js` file  with the following code:
<CodeGroup>
```text .env
ELEVENLABS_AGENT_ID=<your-agent-id>
```
```javascript index.js
import Fastify from "fastify";
import WebSocket from "ws";
import dotenv from "dotenv";
import fastifyFormBody from "@fastify/formbody";
import fastifyWs from "@fastify/websocket";
// Load environment variables from .env file
dotenv.config();
const { ELEVENLABS_AGENT_ID } = process.env;
// Check for the required ElevenLabs Agent ID
if (!ELEVENLABS_AGENT_ID) {
console.error("Missing ELEVENLABS_AGENT_ID in environment variables");
process.exit(1);
}
// Initialize Fastify server
const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);
const PORT = process.env.PORT || 8000;
// Root route for health check
fastify.get("/", async (_, reply) => {
reply.send({ message: "Server is running" });
});
// Route to handle incoming calls from Twilio
fastify.all("/twilio/inbound_call", async (request, reply) => {
// Generate TwiML response to connect the call to a WebSocket stream
const twimlResponse = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
<Connect>
<Stream url="wss://${request.headers.host}/media-stream" />
</Connect>
</Response>`;
reply.type("text/xml").send(twimlResponse);
});
// WebSocket route for handling media streams from Twilio
fastify.register(async (fastifyInstance) => {
fastifyInstance.get("/media-stream", { websocket: true }, (connection, req) => {
console.info("[Server] Twilio connected to media stream.");
let streamSid = null;
// Connect to ElevenLabs Conversational AI WebSocket
const elevenLabsWs = new WebSocket(
`wss://api.elevenlabs.io/v1/convai/conversation?agent_id=${ELEVENLABS_AGENT_ID}`
);
// Handle open event for ElevenLabs WebSocket
elevenLabsWs.on("open", () => {
console.log("[II] Connected to Conversational AI.");
});
// Handle messages from ElevenLabs
elevenLabsWs.on("message", (data) => {
try {
const message = JSON.parse(data);
handleElevenLabsMessage(message, connection);
} catch (error) {
console.error("[II] Error parsing message:", error);
}
});
// Handle errors from ElevenLabs WebSocket
elevenLabsWs.on("error", (error) => {
console.error("[II] WebSocket error:", error);
});
// Handle close event for ElevenLabs WebSocket
elevenLabsWs.on("close", () => {
console.log("[II] Disconnected.");
});
// Function to handle messages from ElevenLabs
const handleElevenLabsMessage = (message, connection) => {
switch (message.type) {
case "conversation_initiation_metadata":
console.info("[II] Received conversation initiation metadata.");
break;
case "audio":
if (message.audio_event?.audio_base_64) {
// Send audio data to Twilio
const audioData = {
event: "media",
streamSid,
media: {
payload: message.audio_event.audio_base_64,
},
};
connection.send(JSON.stringify(audioData));
}
break;
case "interruption":
// Clear Twilio's audio queue
connection.send(JSON.stringify({ event: "clear", streamSid }));
break;
case "ping":
// Respond to ping events from ElevenLabs
if (message.ping_event?.event_id) {
const pongResponse = {
type: "pong",
event_id: message.ping_event.event_id,
};
elevenLabsWs.send(JSON.stringify(pongResponse));
}
break;
}
};
// Handle messages from Twilio
connection.on("message", async (message) => {
try {
const data = JSON.parse(message);
switch (data.event) {
case "start":
// Store Stream SID when stream starts
streamSid = data.start.streamSid;
console.log(`[Twilio] Stream started with ID: ${streamSid}`);
break;
case "media":
// Route audio from Twilio to ElevenLabs
if (elevenLabsWs.readyState === WebSocket.OPEN) {
// data.media.payload is base64 encoded
const audioMessage = {
user_audio_chunk: Buffer.from(
data.media.payload,
"base64"
).toString("base64"),
};
elevenLabsWs.send(JSON.stringify(audioMessage));
}
break;
case "stop":
// Close ElevenLabs WebSocket when Twilio stream stops
elevenLabsWs.close();
break;
default:
console.log(`[Twilio] Received unhandled event: ${data.event}`);
}
} catch (error) {
console.error("[Twilio] Error processing message:", error);
}
});
// Handle close event from Twilio
connection.on("close", () => {
elevenLabsWs.close();
console.log("[Twilio] Client disconnected");
});
// Handle errors from Twilio WebSocket
connection.on("error", (error) => {
console.error("[Twilio] WebSocket error:", error);
elevenLabsWs.close();
});
});
});
// Start the Fastify server
fastify.listen({ port: PORT }, (err) => {
if (err) {
console.error("Error starting server:", err);
process.exit(1);
}
console.log(`[Server] Listening on port ${PORT}`);
});
```
</CodeGroup>
</Step>
<Step title="Run the server">
You can now run the server with the following command:
```bash
node index.js
```
If the server starts successfully, you should see the message `[Server] Listening on port 8000` (or the port you specified) in your terminal.
</Step>
</Steps>
</Tab>
<Tab title="Python">
<Note>
Looking for a complete example? Check out this [implementation](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/twilio) on GitHub.
</Note>
<Steps>
<Step title="Initialize the Project">
```bash
mkdir conversational-ai-twilio
cd conversational-ai-twilio
```
</Step>
<Step title="Install dependencies">
Next, install the required dependencies for the project.
```bash
pip install fastapi uvicorn python-dotenv twilio elevenlabs websockets
```
</Step>
<Step title="Create the project files">
Create a `.env`, `main.py` & `twilio_audio_interface.py` file  with the following code:
```
conversational-ai-twilio/
├── .env
├── main.py
└── twilio_audio_interface.py
```
<CodeGroup>
```text .env
ELEVENLABS_API_KEY=<api-key-here>
AGENT_ID=<agent-id-here>
```
```python main.py
import json
import traceback
import os
from dotenv import load_dotenv
from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from twilio.twiml.voice_response import VoiceResponse, Connect
from elevenlabs import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation
from twilio_audio_interface import TwilioAudioInterface
# Load environment variables
load_dotenv()
# Initialize FastAPI app
app = FastAPI()
# Initialize ElevenLabs client
eleven_labs_client = ElevenLabs(api_key=os.getenv("ELEVENLABS_API_KEY"))
ELEVEN_LABS_AGENT_ID = os.getenv("AGENT_ID")
@app.get("/")
async def root():
return {"message": "Twilio-ElevenLabs Integration Server"}
@app.api_route("/twilio/inbound_call", methods=["GET", "POST"])
async def handle_incoming_call(request: Request):
"""Handle incoming call and return TwiML response."""
response = VoiceResponse()
host = request.url.hostname
connect = Connect()
connect.stream(url=f"wss://{host}/media-stream-eleven")
response.append(connect)
return HTMLResponse(content=str(response), media_type="application/xml")
@app.websocket("/media-stream-eleven")
async def handle_media_stream(websocket: WebSocket):
await websocket.accept()
print("WebSocket connection established")
audio_interface = TwilioAudioInterface(websocket)
conversation = None
try:
conversation = Conversation(
client=eleven_labs_client,
agent_id=ELEVEN_LABS_AGENT_ID,
requires_auth=False,
audio_interface=audio_interface,
callback_agent_response=lambda text: print(f"Agent said: {text}"),
callback_user_transcript=lambda text: print(f"User said: {text}"),
)
conversation.start_session()
print("Conversation session started")
async for message in websocket.iter_text():
if not message:
continue
try:
data = json.loads(message)
await audio_interface.handle_twilio_message(data)
except Exception as e:
print(f"Error processing message: {str(e)}")
traceback.print_exc()
except WebSocketDisconnect:
print("WebSocket disconnected")
finally:
if conversation:
print("Ending conversation session...")
conversation.end_session()
conversation.wait_for_session_end()
if __name__ == "__main__":
import uvicorn
uvicorn.run(app, host="0.0.0.0", port=8000)
```
```python twilio_audio_interface.py
import asyncio
from typing import Callable
import queue
import threading
import base64
from elevenlabs.conversational_ai.conversation import AudioInterface
import websockets
class TwilioAudioInterface(AudioInterface):
def __init__(self, websocket):
self.websocket = websocket
self.output_queue = queue.Queue()
self.should_stop = threading.Event()
self.stream_sid = None
self.input_callback = None
self.output_thread = None
def start(self, input_callback: Callable[[bytes], None]):
self.input_callback = input_callback
self.output_thread = threading.Thread(target=self._output_thread)
self.output_thread.start()
def stop(self):
self.should_stop.set()
if self.output_thread:
self.output_thread.join(timeout=5.0)
self.stream_sid = None
def output(self, audio: bytes):
self.output_queue.put(audio)
def interrupt(self):
try:
while True:
_ = self.output_queue.get(block=False)
except queue.Empty:
pass
asyncio.run(self._send_clear_message_to_twilio())
async def handle_twilio_message(self, data):
try:
if data["event"] == "start":
self.stream_sid = data["start"]["streamSid"]
print(f"Started stream with stream_sid: {self.stream_sid}")
if data["event"] == "media":
audio_data = base64.b64decode(data["media"]["payload"])
if self.input_callback:
self.input_callback(audio_data)
except Exception as e:
print(f"Error in input_callback: {e}")
def _output_thread(self):
while not self.should_stop.is_set():
asyncio.run(self._send_audio_to_twilio())
async def _send_audio_to_twilio(self):
try:
audio = self.output_queue.get(timeout=0.2)
audio_payload = base64.b64encode(audio).decode("utf-8")
audio_delta = {
"event": "media",
"streamSid": self.stream_sid,
"media": {"payload": audio_payload},
}
await self.websocket.send_json(audio_delta)
except queue.Empty:
pass
except Exception as e:
print(f"Error sending audio: {e}")
async def _send_clear_message_to_twilio(self):
try:
clear_message = {"event": "clear", "streamSid": self.stream_sid}
await self.websocket.send_json(clear_message)
except Exception as e:
print(f"Error sending clear message to Twilio: {e}")
```
</CodeGroup>
</Step>
<Step title="Run the server">
You can now run the server with the following command:
```bash
python main.py
```
</Step>
</Steps>
</Tab>
</Tabs>
## Twilio Setup
<Steps>
<Step title="Create a Public URL">
Use ngrok to make your local server accessible:
```bash
ngrok http --url=<your-url-here> 8000
```
<Frame background="subtle">
![](file:5c026f54-93a9-491c-903f-84342d08e2ef)
</Frame>
</Step>
<Step title="Configure Twilio">
1. Go to the [Twilio Console](https://console.twilio.com)
2. Navigate to `Phone Numbers` → `Manage` → `Active numbers`
3. Select your phone number
4. Under "Voice Configuration", set the webhook for incoming calls to:
`https://your-ngrok-url.ngrok.app/twilio/inbound_call`
5. Set the HTTP method to POST
<Frame background="subtle">
![](file:c4a1610f-3275-45f5-beb9-95e54a18b15f)
</Frame>
</Step>
</Steps>
## Testing
1. Call your Twilio phone number.
2. Start speaking - you'll see the transcripts in the ElevenLabs console.
## Troubleshooting
<AccordionGroup>
<Accordion title="Connection Issues">
If the WebSocket connection fails:
* Verify your ngrok URL is correct in Twilio settings
* Check that your server is running and accessible
* Ensure your firewall isn't blocking WebSocket connections
</Accordion>
<Accordion title="Audio Problems">
If there's no audio output:
* Confirm your ElevenLabs API key is valid
* Verify the AGENT\_ID is correct
* Check audio format settings match Twilio's requirements (μ-law 8kHz)
</Accordion>
</AccordionGroup>
## Security Best Practices
<Warning>
Follow these security guidelines for production deployments:
<>
* Use environment variables for sensitive information - Implement proper authentication for your
endpoints - Use HTTPS for all communications - Regularly rotate API keys - Monitor usage to
prevent abuse
</>
</Warning>
# Twilio outbound calls
> Build an outbound calling AI agent with Twilio and ElevenLabs.
In this guide you will learn how to build an integration with Twilio to initialise outbound calls to your prospects and customers.
<iframe width="100%" height="400" src="https://www.youtube-nocookie.com/embed/fmIvK0Na_IU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen />
<Tip title="Prefer to jump straight to the code?" icon="lightbulb">
Find the [example project on
GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/twilio/javascript).
</Tip>
## What You'll Need
* An [ElevenLabs account](https://elevenlabs.io).
* A configured ElevenLabs Conversational Agent ([create one here](/docs/conversational-ai/quickstart)).
* A [Twilio account](https://www.twilio.com/try-twilio) with an active phone number.
* Node.js 16+
* [ngrok](https://ngrok.com/) for local development.
## Agent Configuration
Before integrating with Twilio, you'll need to configure your agent to use the correct audio format supported by Twilio.
<Steps>
<Step title="Configure TTS Output">
1. Navigate to your agent settings.
2. Go to the Voice section.
3. Select "μ-law 8000 Hz" from the dropdown.
<Frame background="subtle">
![](file:f070cbb2-3c55-4275-88b0-22f61858b6f6)
</Frame>
</Step>
<Step title="Set Input Format">
1. Navigate to your agent settings. 2. Go to the Advanced section. 3. Select "μ-law 8000 Hz" for
the input format.
<Frame background="subtle">![](file:386c0ffa-daba-465b-8895-420c99d0c9b1)</Frame>
</Step>
<Step title="Enable auth and overrides">
1. Navigate to your agent settings.
2. Go to the security section.
3. Toggle on "Enable authentication".
4. In "Enable overrides" toggle on "First message" and "System prompt" as you will be dynamically injecting these values when initiating the call.
<Frame background="subtle">
![](file:63916a5a-e45d-4090-a45d-33711c64a209)
</Frame>
</Step>
</Steps>
## Implementation
<Tabs>
<Tab title="Javascript">
<Note>
Looking for a complete example? Check out this [Javascript implementation](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/twilio/javascript) on GitHub.
</Note>
<Steps>
<Step title="Initialize the Project">
First, set up a new Node.js project:
```bash
mkdir conversational-ai-twilio
cd conversational-ai-twilio
npm init -y; npm pkg set type="module";
```
</Step>
<Step title="Install dependencies">
Next, install the required dependencies for the project.
```bash
npm install @fastify/formbody @fastify/websocket dotenv fastify ws
```
</Step>
<Step title="Create the project files">
Create a `.env` and `outbound.js` file  with the following code:
<CodeGroup>
```text .env
ELEVENLABS_AGENT_ID=<your-agent-id>
ELEVENLABS_API_KEY=<your-api-key>
# Twilio
TWILIO_ACCOUNT_SID=<your-account-sid>
TWILIO_AUTH_TOKEN=<your-auth-token>
TWILIO_PHONE_NUMBER=<your-twilio-phone-number>
```
```javascript outbound.js
import fastifyFormBody from '@fastify/formbody';
import fastifyWs from '@fastify/websocket';
import dotenv from 'dotenv';
import Fastify from 'fastify';
import Twilio from 'twilio';
import WebSocket from 'ws';
// Load environment variables from .env file
dotenv.config();
// Check for required environment variables
const {
ELEVENLABS_API_KEY,
ELEVENLABS_AGENT_ID,
TWILIO_ACCOUNT_SID,
TWILIO_AUTH_TOKEN,
TWILIO_PHONE_NUMBER,
} = process.env;
if (
!ELEVENLABS_API_KEY ||
!ELEVENLABS_AGENT_ID ||
!TWILIO_ACCOUNT_SID ||
!TWILIO_AUTH_TOKEN ||
!TWILIO_PHONE_NUMBER
) {
console.error('Missing required environment variables');
throw new Error('Missing required environment variables');
}
// Initialize Fastify server
const fastify = Fastify();
fastify.register(fastifyFormBody);
fastify.register(fastifyWs);
const PORT = process.env.PORT || 8000;
// Root route for health check
fastify.get('/', async (_, reply) => {
reply.send({ message: 'Server is running' });
});
// Initialize Twilio client
const twilioClient = new Twilio(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN);
// Helper function to get signed URL for authenticated conversations
async function getSignedUrl() {
try {
const response = await fetch(
`https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=${ELEVENLABS_AGENT_ID}`,
{
method: 'GET',
headers: {
'xi-api-key': ELEVENLABS_API_KEY,
},
}
);
if (!response.ok) {
throw new Error(`Failed to get signed URL: ${response.statusText}`);
}
const data = await response.json();
return data.signed_url;
} catch (error) {
console.error('Error getting signed URL:', error);
throw error;
}
}
// Route to initiate outbound calls
fastify.post('/outbound-call', async (request, reply) => {
const { number, prompt, first_message } = request.body;
if (!number) {
return reply.code(400).send({ error: 'Phone number is required' });
}
try {
const call = await twilioClient.calls.create({
from: TWILIO_PHONE_NUMBER,
to: number,
url: `https://${request.headers.host}/outbound-call-twiml?prompt=${encodeURIComponent(
prompt
)}&first_message=${encodeURIComponent(first_message)}`,
});
reply.send({
success: true,
message: 'Call initiated',
callSid: call.sid,
});
} catch (error) {
console.error('Error initiating outbound call:', error);
reply.code(500).send({
success: false,
error: 'Failed to initiate call',
});
}
});
// TwiML route for outbound calls
fastify.all('/outbound-call-twiml', async (request, reply) => {
const prompt = request.query.prompt || '';
const first_message = request.query.first_message || '';
const twimlResponse = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
<Connect>
<Stream url="wss://${request.headers.host}/outbound-media-stream">
<Parameter name="prompt" value="${prompt}" />
<Parameter name="first_message" value="${first_message}" />
</Stream>
</Connect>
</Response>`;
reply.type('text/xml').send(twimlResponse);
});
// WebSocket route for handling media streams
fastify.register(async (fastifyInstance) => {
fastifyInstance.get('/outbound-media-stream', { websocket: true }, (ws, req) => {
console.info('[Server] Twilio connected to outbound media stream');
// Variables to track the call
let streamSid = null;
let callSid = null;
let elevenLabsWs = null;
let customParameters = null; // Add this to store parameters
// Handle WebSocket errors
ws.on('error', console.error);
// Set up ElevenLabs connection
const setupElevenLabs = async () => {
try {
const signedUrl = await getSignedUrl();
elevenLabsWs = new WebSocket(signedUrl);
elevenLabsWs.on('open', () => {
console.log('[ElevenLabs] Connected to Conversational AI');
// Send initial configuration with prompt and first message
const initialConfig = {
type: 'conversation_initiation_client_data',
dynamic_variables: {
user_name: 'Angelo',
user_id: 1234,
},
conversation_config_override: {
agent: {
prompt: {
prompt: customParameters?.prompt || 'you are a gary from the phone store',
},
first_message:
customParameters?.first_message || 'hey there! how can I help you today?',
},
},
};
console.log(
'[ElevenLabs] Sending initial config with prompt:',
initialConfig.conversation_config_override.agent.prompt.prompt
);
// Send the configuration to ElevenLabs
elevenLabsWs.send(JSON.stringify(initialConfig));
});
elevenLabsWs.on('message', (data) => {
try {
const message = JSON.parse(data);
switch (message.type) {
case 'conversation_initiation_metadata':
console.log('[ElevenLabs] Received initiation metadata');
break;
case 'audio':
if (streamSid) {
if (message.audio?.chunk) {
const audioData = {
event: 'media',
streamSid,
media: {
payload: message.audio.chunk,
},
};
ws.send(JSON.stringify(audioData));
} else if (message.audio_event?.audio_base_64) {
const audioData = {
event: 'media',
streamSid,
media: {
payload: message.audio_event.audio_base_64,
},
};
ws.send(JSON.stringify(audioData));
}
} else {
console.log('[ElevenLabs] Received audio but no StreamSid yet');
}
break;
case 'interruption':
if (streamSid) {
ws.send(
JSON.stringify({
event: 'clear',
streamSid,
})
);
}
break;
case 'ping':
if (message.ping_event?.event_id) {
elevenLabsWs.send(
JSON.stringify({
type: 'pong',
event_id: message.ping_event.event_id,
})
);
}
break;
case 'agent_response':
console.log(
`[Twilio] Agent response: ${message.agent_response_event?.agent_response}`
);
break;
case 'user_transcript':
console.log(
`[Twilio] User transcript: ${message.user_transcription_event?.user_transcript}`
);
break;
default:
console.log(`[ElevenLabs] Unhandled message type: ${message.type}`);
}
} catch (error) {
console.error('[ElevenLabs] Error processing message:', error);
}
});
elevenLabsWs.on('error', (error) => {
console.error('[ElevenLabs] WebSocket error:', error);
});
elevenLabsWs.on('close', () => {
console.log('[ElevenLabs] Disconnected');
});
} catch (error) {
console.error('[ElevenLabs] Setup error:', error);
}
};
// Set up ElevenLabs connection
setupElevenLabs();
// Handle messages from Twilio
ws.on('message', (message) => {
try {
const msg = JSON.parse(message);
if (msg.event !== 'media') {
console.log(`[Twilio] Received event: ${msg.event}`);
}
switch (msg.event) {
case 'start':
streamSid = msg.start.streamSid;
callSid = msg.start.callSid;
customParameters = msg.start.customParameters; // Store parameters
console.log(`[Twilio] Stream started - StreamSid: ${streamSid}, CallSid: ${callSid}`);
console.log('[Twilio] Start parameters:', customParameters);
break;
case 'media':
if (elevenLabsWs?.readyState === WebSocket.OPEN) {
const audioMessage = {
user_audio_chunk: Buffer.from(msg.media.payload, 'base64').toString('base64'),
};
elevenLabsWs.send(JSON.stringify(audioMessage));
}
break;
case 'stop':
console.log(`[Twilio] Stream ${streamSid} ended`);
if (elevenLabsWs?.readyState === WebSocket.OPEN) {
elevenLabsWs.close();
}
break;
default:
console.log(`[Twilio] Unhandled event: ${msg.event}`);
}
} catch (error) {
console.error('[Twilio] Error processing message:', error);
}
});
// Handle WebSocket closure
ws.on('close', () => {
console.log('[Twilio] Client disconnected');
if (elevenLabsWs?.readyState === WebSocket.OPEN) {
elevenLabsWs.close();
}
});
});
});
// Start the Fastify server
fastify.listen({ port: PORT }, (err) => {
if (err) {
console.error('Error starting server:', err);
process.exit(1);
}
console.log(`[Server] Listening on port ${PORT}`);
});
```
</CodeGroup>
</Step>
<Step title="Run the server">
You can now run the server with the following command:
```bash
node outbound.js
```
If the server starts successfully, you should see the message `[Server] Listening on port 8000` (or the port you specified) in your terminal.
</Step>
</Steps>
</Tab>
</Tabs>
## Testing
1. In another terminal, run `ngrok http --url=<your-url-here> 8000`.
2. Make a request to the `/outbound-call` endpoint with the customer's phone number, the first message you want to use and the custom prompt:
```bash
curl -X POST https://<your-ngrok-url>/outbound-call \
-H "Content-Type: application/json" \
-d '{
"prompt": "You are Eric, an outbound car sales agent. You are calling to sell a new car to the customer. Be friendly and professional and answer all questions.",
"first_message": "Hello Thor, my name is Eric, I heard you were looking for a new car! What model and color are you looking for?",
"number": "number-to-call"
}'
```
3. You will see the call get initiated in your server terminal window and your phone will ring, starting the conversation once you answer.
## Troubleshooting
<AccordionGroup>
<Accordion title="Connection Issues">
If the WebSocket connection fails:
* Verify your ngrok URL is correct in Twilio settings
* Check that your server is running and accessible
* Ensure your firewall isn't blocking WebSocket connections
</Accordion>
<Accordion title="Audio Problems">
If there's no audio output:
* Confirm your ElevenLabs API key is valid
* Verify the AGENT\_ID is correct
* Check audio format settings match Twilio's requirements (μ-law 8kHz)
</Accordion>
</AccordionGroup>
## Security Best Practices
<Warning>
Follow these security guidelines for production deployments:
<>
* Use environment variables for sensitive information - Implement proper authentication for your
endpoints - Use HTTPS for all communications - Regularly rotate API keys - Monitor usage to
prevent abuse
</>
</Warning>
# Conversational AI in Ghost
> Learn how to deploy a Conversational AI agent to Ghost
This tutorial will guide you through adding your ElevenLabs Conversational AI agent to your Ghost website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/docs/agent-setup)
* A Ghost website (paid plan or self-hosted)
* Access to Ghost admin panel
## Guide
There are two ways to add the widget to your Ghost site:
<Steps>
<Step title="Get your embed code">
Visit the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai) and copy your agent's html widget.
```html
<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</Step>
<Step title="Choose your implementation">
**Option A: Add globally (all pages)**
1. Go to Ghost Admin > Settings > Code Injection
2. Paste the code into Site Footer
3. Save changes
**Option B: Add to specific pages**
1. Edit your desired page/post
2. Click the + sign to add an HTML block
3. Paste your agent's html widget from step 1 into the HTML block. Make sure to fill in the agent-id attribute correctly.
4. Save and publish
</Step>
<Step title="Test the integration">
1. Visit your Ghost website
2. Verify the widget appears and functions correctly
3. Test on different devices and browsers
</Step>
</Steps>
## Troubleshooting
If the widget isn't appearing, verify:
* The code is correctly placed in either Code Injection or HTML block
* Your Ghost plan supports custom code
* No JavaScript conflicts with other scripts
## Next steps
Now that you have added your Conversational AI agent to Ghost, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base
# Conversational AI in Framer
> Learn how to deploy a Conversational AI agent to Framer
This tutorial will guide you through adding your conversational AI agent to your Framer website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/quickstart)
* A Framer account & website, create one [here](https://framer.com)
<Frame background="subtle">
<img alt="Convai Framer Example Project" src="file:34d8f3f6-b172-4f51-91ef-d273bd17d2a2" />
</Frame>
## Guide
<Steps>
<Step title="Visit your Framer editor">
Open your website in the Framer editor and click on the primary desktop on the left.
</Step>
<Step title="Add the Conversational AI component">
Copy and paste the following url into the page you would like to add the Conversational AI agent to:
```
https://framer.com/m/ConversationalAI-iHql.js@y7VwRka75sp0UFqGliIf
```
You'll now see a Conversational AI asset on the 'Layers' bar on the left and the Conversational AI component's details on the right.
</Step>
<Step title="Fill in the agent details">
Enable the Conversational AI agent by filling in the agent ID in the bar on the right.
You can find the agent ID in the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai).
</Step>
</Steps>
Having trouble? Make sure the Conversational AI component is placed below the desktop component in the layers panel.
<Frame background="subtle">
<img alt="Convai Framer Example Project" src="file:f7d06991-ad14-4749-b914-607975cf44b8" />
</Frame>
<Frame background="subtle">
<img alt="Convai Framer Example Project" src="file:caf7dd58-b858-474e-b510-163a5acc4eb8" />
</Frame>
## Next steps
Now that you have added your Conversational AI agent to your Framer website, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base.
# Conversational AI in Squarespace
> Learn how to deploy a Conversational AI agent to Squarespace
This tutorial will guide you through adding your ElevenLabs Conversational AI agent to your Squarespace website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/docs/agent-setup)
* A Squarespace Business or Commerce plan (required for custom code)
* Basic familiarity with Squarespace's editor
## Guide
<Steps>
<Step title="Get your embed code">
Visit the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai) and find your agent's embed widget.
```html
<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</Step>
<Step title="Add the widget to your page">
1. Navigate to your desired page
2. Click + to add a block
3. Select Code from the menu
4. Paste the `<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>` snippet into the Code Block
5. Save the block
</Step>
<Step title="Add the script globally">
1. Go to Settings > Advanced > Code Injection
2. Paste the snippet `<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>` into the Footer section
3. Save changes
4. Publish your site to see the changes
</Step>
</Steps>
Note: The widget will only be visible on your live site, not in the editor preview.
## Troubleshooting
If the widget isn't appearing, verify:
* The `<script>` snippet is in the Footer Code Injection section
* The `<elevenlabs-convai>` snippet is correctly placed in a Code Block
* You've published your site after making changes
## Next steps
Now that you have added your Conversational AI agent to Squarespace, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base
# Conversational AI in Webflow
> Learn how to deploy a Conversational AI agent to Webflow
This tutorial will guide you through adding your ElevenLabs Conversational AI agent to your Webflow website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/docs/agent-setup)
* A Webflow account with Core, Growth, Agency, or Freelancer Workspace (or Site Plan)
* Basic familiarity with Webflow's Designer
## Guide
<Steps>
<Step title="Get your embed code">
Visit the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai) and find your agent's embed widget.
```html
<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</Step>
<Step title="Add the widget to your page">
1. Open your Webflow project in Designer
2. Drag an Embed Element to your desired location
3. Paste the `<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>` snippet into the Embed Element's code editor
4. Save & Close
</Step>
<Step title="Add the script globally">
1. Go to Project Settings > Custom Code
2. Paste the snippet `<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>` into the Footer Code section
3. Save Changes
4. Publish your site to see the changes
</Step>
</Steps>
Note: The widget will only be visible after publishing your site, not in the Designer.
## Troubleshooting
If the widget isn't appearing, verify:
* The `<script>` snippet is in the Footer Code section
* The `<elevenlabs-convai>` snippet is correctly placed in an Embed Element
* You've published your site after making changes
## Next steps
Now that you have added your Conversational AI agent to Webflow, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base
# Conversational AI in Wix
> Learn how to deploy a Conversational AI agent to Wix
This tutorial will guide you through adding your ElevenLabs Conversational AI agent to your Wix website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/docs/agent-setup)
* A Wix Premium account (required for custom code)
* Access to Wix Editor with Dev Mode enabled
## Guide
<Steps>
<Step title="Get your embed code">
Visit the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai) and copy your agent's embed code.
```html
<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</Step>
<Step title="Enable Dev Mode">
1. Open your Wix site in the Editor
2. Click on Dev Mode in the top menu
3. If Dev Mode is not visible, ensure you're using the full Wix Editor, not Wix ADI
</Step>
<Step title="Add the embed snippet">
1. Go to Settings > Custom Code
2. Click + Add Custom Code
3. Paste your ElevenLabs embed snippet from step 1 with the agent-id attribute filled in correctly
4. Select the pages you would like to add the Conversational AI widget to (all pages, or specific pages)
5. Save and publish
</Step>
</Steps>
## Troubleshooting
If the widget isn't appearing, verify:
* You're using a Wix Premium plan
* Your site's domain is properly configured in the ElevenLabs allowlist
* The code is added correctly in the Custom Code section
## Next steps
Now that you have added your Conversational AI agent to Wix, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base
# Conversational AI in WordPress
> Learn how to deploy a Conversational AI agent to WordPress
This tutorial will guide you through adding your ElevenLabs Conversational AI agent to your WordPress website.
## Prerequisites
* An ElevenLabs Conversational AI agent created following [this guide](/docs/conversational-ai/docs/agent-setup)
* A WordPress website with either:
* WordPress.com Business/Commerce plan, or
* Self-hosted WordPress installation
## Guide
<Steps>
<Step title="Get your embed code">
Visit the [ElevenLabs dashboard](https://elevenlabs.io/app/conversational-ai) and find your agent's embed widget.
```html
<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>
<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>
```
</Step>
<Step title="Add the widget to a page">
1. In WordPress, edit your desired page
2. Add a Custom HTML block
3. Paste the `<elevenlabs-convai agent-id="YOUR_AGENT_ID"></elevenlabs-convai>` snippet into the block
4. Update/publish the page
</Step>
<Step title="Add the script globally">
**Option A: Using a plugin**
1. Install Header Footer Code Manager
2. Add the snippet `<script src="https://elevenlabs.io/convai-widget/index.js" async type="text/javascript"></script>` to the Footer section
3. Set it to run on All Pages
**Option B: Direct theme editing**
1. Go to Appearance > Theme Editor
2. Open footer.php
3. Paste the script snippet before `</body>`
</Step>
</Steps>
## Troubleshooting
If the widget isn't appearing, verify:
* The `<script>` snippet is added globally
* The `<elevenlabs-convai>` snippet is correctly placed in your page
* You've published your site after making changes
## Next steps
Now that you have added your Conversational AI agent to WordPress, you can:
1. Customize the widget in the ElevenLabs dashboard to match your brand
2. Add additional languages
3. Add advanced functionality like tools & knowledge base
# Cal.com
> Learn how to integrate our Conversational AI platform with Cal.com for automated meeting scheduling
## Overview
With our Cal.com integration, your AI assistant can seamlessly schedule meetings by checking calendar availability and booking appointments. This integration streamlines the scheduling process by automatically verifying available time slots, collecting attendee information, and creating calendar events. Benefits include eliminating scheduling back-and-forth, reducing manual effort, and enhancing the meeting booking experience.
<div>
<iframe src="https://www.youtube.com/embed/dqPJeec029I" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen title="Cal.com Integration Demo" />
</div>
## How it works
We lay out below how we have configured the Conversational AI agent to schedule meetings by using tool calling to step through the booking process.
Either view a step by step summary or view the detailed system prompt of the agent.
<Tabs>
<Tab title="High level overview ">
<Steps>
<Step title="Initial Inquiry & Meeting Details">
Configure your agent to ask for meeting purpose, preferred date/time, and duration to gather all necessary scheduling information.
</Step>
<Step title="Check Calendar Availability">
Configure the agent to check calendar availability by:
* Using the `get_available_slots` tool to fetch open time slots
* Verifying if the requested time is available
* Suggesting alternatives if the requested time is unavailable
* Confirming the selected time with the caller
</Step>
<Step title="Contact Information Collection">
Once a time is agreed upon:
* Collect and validate the attendee's full name
* Verify email address accuracy
* Confirm time zone information
* Gather any additional required fields for your Cal.com setup
</Step>
<Step title="Meeting Creation">
* Use the `book_meeting` tool after information verification
* Follow the booking template structure
* Confirm meeting creation with the attendee
* Inform them that they will receive a calendar invitation
</Step>
</Steps>
</Tab>
<Tab title="Detailed system prompt">
```
You are a helpful receptionist responsible for scheduling meetings using the Cal.com integration. Be friendly, precise, and concise.
Begin by briefly asking for the purpose of the meeting and the caller's preferred date and time.
Then, ask about the desired meeting duration (15, 30, or 60 minutes), and wait for the user's response before proceeding.
Once you have the meeting details, say you will check calendar availability:
- Call get_available_slots with the appropriate date range
- Verify if the requested time slot is available
- If not available, suggest alternative times from the available slots
- Continue until a suitable time is agreed upon
After confirming a time slot, gather the following contact details:
- The attendee's full name
- A valid email address. Note that the email address is transcribed from voice, so ensure it is formatted correctly.
- The attendee's time zone (in 'Continent/City' format like 'America/New_York')
- Read the email back to the caller to confirm accuracy
Once all details are confirmed, explain that you will create the meeting.
Create the meeting by using the book_meeting tool with the following parameters:
- start: The agreed meeting time in ISO 8601 format
- eventTypeId: The appropriate ID based on the meeting duration (15min: 1351800, 30min: 1351801, 60min: 1351802)
- attendee: An object containing the name, email, and timeZone
Thank the attendee and inform them they will receive a calendar invitation shortly.
Clarifications:
- Do not inform the user that you are formatting the email; simply do it.
- If the caller asks you to proceed with booking, do so with the existing information.
Guardrails:
- Do not share any internal IDs or API details with the caller.
- If booking fails, check for formatting issues in the email or time conflicts.
```
</Tab>
</Tabs>
## Setup
<Steps>
<Step title="Store your cal.com secret">
To make authenticated requests to external APIs like Cal.com, you need to store your API keys securely. Start by generating a new [Cal.com API key](https://cal.com/docs/api-reference/v1/introduction#get-your-api-keys).
Not all APIs have the same authentication structure. For example, the Cal.com API expects the following authentication header:
```plaintext Cal request header structure
'Authorization': 'Bearer YOUR_API_KEY'
```
Once you have your API key, store it in the assistant's secret storage. This ensures that your key is kept secure and accessible when making requests.
<Warning>
To match the expected authentication structure of Cal.com, remember to prepend the API key with `Bearer ` when creating the secret.
</Warning>
<Frame background="subtle">
![Tool secrets](file:491bd3aa-f05c-4111-8585-de15919ddd08)
</Frame>
</Step>
<Step title="Adding tools to the assistant">
To enable your assistant to manage calendar bookings, we'll create two tools:
1. **`get_available_slots`**: When a user asks, *"Is Louis free at 10:30 AM on Tuesday?"*, the assistant should use [Cal.com's "Get available slots" endpoint](https://cal.com/docs/api-reference/v2/slots/find-out-when-is-an-event-type-ready-to-be-booked) to check for available time slots.
2. **`book_meeting`**: After identifying a suitable time, the assistant can proceed to book the meeting using [Cal.com's "Create a booking" endpoint](https://cal.com/docs/api-reference/v2/bookings/create-a-booking#create-a-booking).
First, head to the **Tools** section of your dashboard and choose **Add Tool**. Select **Webhook** as the Tool Type, then fill in the following sections:
<AccordionGroup>
<Accordion title="Tool 1: get_available_slots">
<Tabs>
<Tab title="Configuration">
Metadata used by the assistant to determine when the tool should be called:
| Field       | Value                                                                    |
| ----------- | ------------------------------------------------------------------------ |
| Name        | get\_available\_slots                                                    |
| Description | This tool checks if a particular time slot is available in the calendar. |
| Method      | GET                                                                      |
| URL         | [https://api.cal.com/v2/slots](https://api.cal.com/v2/slots)             |
</Tab>
<Tab title="Headers">
Matches the request headers defined [here](https://cal.com/docs/api-reference/v2/slots/get-available-slots#get-available-slots):
| Type   | Name            | Value                               |
| ------ | --------------- | ----------------------------------- |
| Secret | Authorization   | Select the secret key created above |
| String | cal-api-version | 2024-09-04                          |
</Tab>
<Tab title="Query parameters">
Matches the request query parameters defined [here](https://cal.com/docs/api-reference/v2/slots/get-available-slots#get-available-slots):
| Data Type | Identifier  | Required | Description                                                                                                               |
| --------- | ----------- | -------- | ------------------------------------------------------------------------------------------------------------------------- |
| string    | start       | Yes      | Start date/time (UTC) from which to fetch slots, e.g. '2024-08-13T09:00:00Z'.                                             |
| string    | end         | Yes      | End date/time (UTC) until which to fetch slots, e.g. '2024-08-13T17:00:00Z'.                                              |
| string    | eventTypeId | Yes      | The ID of the event type that is booked. If 15 minutes, return abc. If 30 minutes, return def. If 60 minutes, return xyz. |
</Tab>
</Tabs>
</Accordion>
<Accordion title="Tool 2: book_meeting">
<Tabs>
<Tab title="Configuration">
Metadata used by the assistant to determine when the tool should be called:
| Field       | Value                                                              |
| ----------- | ------------------------------------------------------------------ |
| Name        | book\_meeting                                                      |
| Description | This tool books a meeting in the calendar once a time is agreed.   |
| Method      | POST                                                               |
| URL         | [https://api.cal.com/v2/bookings](https://api.cal.com/v2/bookings) |
</Tab>
<Tab title="Headers">
Matches the request headers defined [here](https://cal.com/docs/api-reference/v2/bookings/create-a-booking#create-a-booking):
| Type   | Name            | Value                               |
| ------ | --------------- | ----------------------------------- |
| Secret | Authorization   | Select the secret key created above |
| String | cal-api-version | 2024-08-13                          |
</Tab>
<Tab title="Body Parameters">
Matches the request body parameters defined [here](https://cal.com/docs/api-reference/v2/bookings/create-a-booking#create-a-booking):
| Identifier  | Data Type | Required | Description                                                                                                               |
| ----------- | --------- | -------- | ------------------------------------------------------------------------------------------------------------------------- |
| start       | String    | Yes      | The start time of the booking in ISO 8601 format in UTC timezone, e.g. ‘2024-08-13T09:00:00Z’.                            |
| eventTypeId | Number    | Yes      | The ID of the event type that is booked. If 15 minutes, return abc. If 30 minutes, return def. If 60 minutes, return xyz. |
| attendee    | Object    | Yes      | The attendee's details. You must collect these fields from the user.                                                      |
<Note>
The `eventTypeId` must correspond to the event types you have available in Cal. Call
[this](https://cal.com/docs/api-reference/v1/event-types/find-all-event-types#find-all-event-types)
endpoint to get a list of your account event types (or create another tool that does this
automatically).
</Note>
**Attendee object:**
| Identifier | Data Type | Required | Description                                                                                                     |
| ---------- | --------- | -------- | --------------------------------------------------------------------------------------------------------------- |
| name       | String    | Yes      | The full name of the person booking the meeting.                                                                |
| email      | String    | Yes      | The email address of the person booking the meeting.                                                            |
| timeZone   | String    | Yes      | The caller's timezone. Should be in the format of 'Continent/City' like 'Europe/London' or 'America/New\_York'. |
</Tab>
</Tabs>
</Accordion>
</AccordionGroup>
<Success>
Test your new assistant by pressing the **Test AI agent** button to ensure everything is working
as expected. Feel free to fine-tune the system prompt.
</Success>
</Step>
<Step title="Enhancements">
By default, the assistant does not have knowledge of the current date or time. To enhance its capabilities, consider implementing one of the following solutions:
1. **Create a time retrieval tool**: Add another tool that fetches the current date and time.
2. **Overrides**: Use the [overrides](/docs/conversational-ai/customization/overrides) functionality to inject the current date and time into the system prompt at the start of each conversation.
</Step>
</Steps>
## Security Considerations
* Use HTTPS endpoints for all webhook calls.
* Store sensitive values as secrets using the ElevenLabs Secrets Manager.
* Validate that all authorization headers follow the required format (`Bearer YOUR_API_KEY`).
* Never expose event type IDs or API details to callers.
## Conclusion
This guide details how to integrate Cal.com into our conversational AI platform for efficient meeting scheduling. By leveraging webhook tools and calendar availability data, the integration streamlines the booking process, reducing scheduling friction and enhancing overall service quality.
For additional details on tool configuration or other integrations, refer to the [Tools Overview](/docs/conversational-ai/customization/tools-events/server-tools).
# Zendesk
> Learn how to integrate our Conversational AI platform with Zendesk for better customer support
## Overview
With our Zendesk integration, your support agent can quickly identify and resolve customer issues by leveraging historical ticket data. This integration streamlines the support process by automatically checking for similar resolved issues, advising customers based on past resolutions, and securely creating new support tickets. Benefits include faster resolutions, reduced manual effort, and enhanced customer satisfaction.
## Demo Video
Watch the demonstration of the Zendesk + Conversational AI integration.
<Frame background="subtle" caption="Zendesk Integration Demo">
<iframe src="https://www.loom.com/embed/109404cb8aa348f5ab019feeec292c95?sid=87f90604-fb6e-421f-abed-09d571b6b46f" frameBorder="0" webkitallowfullscreen mozallowfullscreen allowFullScreen />
</Frame>
## How it works
We lay out below how we have configured the Conversational AI agent to resolve tickets by using tool calling to step through the resolution process.
Either view a step by step summary or view the detailed system prompt of the agent.
<Tabs>
<Tab title="High level overview ">
<Steps>
<Step title="Initial Inquiry & Issue Details">
Configure your agent to ask for a detailed description of the support issue and follow up with focused questions to gather all necessary information.
</Step>
<Step title="Check for Similar Issues">
Configure the agent to check historical tickets for similar issues by:
* Using the `get_resolved_tickets` tool to fetch past tickets
* Finding similar tickets and their resolutions
* Extracting relevant comments via the `get_ticket_comments` tool
* Using this information to suggest proven solutions
</Step>
<Step title="Contact Information Collection">
If the ticket can't be deflected:
* Collect and validate the customer's full name
* Verify email address accuracy
* Confirm any additional required fields for your Zendesk setup
</Step>
<Step title="Ticket Creation">
* Use the `zendesk_open_ticket` tool after information verification
* Follow the ticket template structure
* Confirm ticket creation with the customer
* Inform them that support will be in touch
</Step>
</Steps>
</Tab>
<Tab title="Detailed system prompt">
```
You are a helpful ElevenLabs support agent responsible for gathering information from users and creating support tickets using the zendesk_open_ticket tool. Be friendly, precise, and concise.
Begin by briefly asking asking for a detailed description of the problem.
Then, ask relevant support questions to gather additional details, one question at a time, and wait for the user's response before proceeding.
Once you have a description of the issue, say you will check if there are similar issues and any known resolutions.
- call get_resolved_tickets
- find the ticket which has the most similar issue to that of the caller
- call get_ticket_comments, using the result id from the previous response
- get any learnings from the resolution of this ticket
After this, tell the customer the recommended resolution from a previous similar issue. If they have already tried it or still want to move forward, move to the ticket creation step. Only provide resolution advice derived from the comments.
After capturing the support issue, gather the following contact details:
- The user's name.
- A valid email address for the requestor. Note that the email address is transcribed from voice, so ensure it is formatted correctly.
- Read the email back to the caller to confirm accuracy.
Once the email is confirmed, explain that you will create the ticket.
Create the ticket by using the Tool zendesk_open_ticket. Add these details to the ticket comment body.
Thank the customer and say support will be in touch.
Clarifications:
- Do not inform the user that you are formatting the email; simply do it.
- If the caller asks you to move forward with creating the ticket, do so with the existing information.
Guardrails:
- Do not speak about topics outside of support issues with ElevenLabs.
```
</Tab>
</Tabs>
<Tip>
This integration enhances efficiency by leveraging historical support data. All API calls require
proper secret handling in the authorization headers.
</Tip>
## Tool Configurations
The integration with zendesk employs three webhook tools to create the support agent. Use the tabs below to review each tool's configuration.
<Tabs>
<Tab title="get_ticket_comments">
**Name:** get\_ticket\_comments\
**Description:** Retrieves the comments of a ticket.\
**Method:** GET\
**URL:** `https://your-subdomain.zendesk.com/api/v2/tickets/{ticket_id}/comments.json`
**Headers:**
* **Content-Type:** `application/json`
* **Authorization:** *(Secret: `zendesk_key`)*
**Path Parameters:**
* **ticket\_id:** Extract the value from the `id` field in the get\_resolved\_tickets results.
</Tab>
<Tab title="get_resolved_tickets">
**Name:** get\_resolved\_tickets\
**Description:** Retrieves all resolved support tickets from Zendesk.\
**Method:** GET\
**URL:** `https://your-subdomain.zendesk.com/api/v2/search.json?query=type:ticket+status:solved`
**Headers:**
* **Content-Type:** `application/json`
* **Authorization:** *(Secret: `zendesk_key`)*
</Tab>
<Tab title="zendesk_open_ticket">
**Name:** zendesk\_open\_ticket\
**Description:** Opens a new support ticket.\
**Method:** POST\
**URL:** `https://your-subdomain.zendesk.com/api/v2/tickets.js`
**Headers:**
* **Content-Type:** `application/json`
* **Authorization:** *(Secret: `zendesk_key`)*
**Body Parameters:**
* **ticket:** An object containing:
* **comment:**
* **body:** Detailed description of the support issue.
* **subject:** A short subject line.
* **requester:**
* **name:** The full name of the requester.
* **email:** A valid email address.
</Tab>
</Tabs>
<Warning>
Ensure that you add your workspace's zendesk secret to the agent's secrets.
</Warning>
## Evaluation Configuration
To improve the observability of customer interactions, we configure the agent with the following evaluation criteria and data collection parameters.
<Frame background="subtle" caption="Track how well the AI agent performs against key evaluation criteria like issue relevance, sentiment, and resolution success.">
<img src="file:3232252f-553c-46c5-a7a3-f1176b6048a8" alt="Evaluation criteria for support interactions" />
</Frame>
These settings are added directly to the agent's configuration in the "Analysis" tab to ensure comprehensive monitoring of all customer interactions. This enables us to track performance, identify areas for improvement, and maintain high-quality support standards.
## Impact
With this integration in place, not only can you resolve tickets faster, but you can also reduce the load on your support team by deflecting tickets that are not relevant to your team.
In addition, you can use the Conversational AI platform to monitor the agent's usage.
<Frame background="subtle" caption="Get a high-level overview of each conversation and listen to the conversation's audio recording.">
<img src="file:e731cef4-f289-46d6-9428-94d22a48b936" alt="Support agent conversation summary" />
</Frame>
<Frame background="subtle" caption="Track how well the AI agent performs against key evaluation criteria like issue relevance, sentiment, and resolution success.">
<img src="file:fc5c2a6e-1607-40b7-9c84-46151bd9be53" alt="Evaluation criteria for support interactions" />
</Frame>
<Frame background="subtle" caption="Monitor the data collected during each interaction, including tools used, issue details, and customer information.">
<img src="file:18d64a67-1193-4cc5-841c-1af147dac272" alt="Data collection parameters from conversation transcripts" />
</Frame>
<Frame background="subtle" caption="Review detailed transcripts of conversations to understand agent performance, tool usage and customer interactions.">
<img src="file:65e7ac28-02d9-4a94-9361-7e23608585aa" alt="Detailed conversation transcript example" />
</Frame>
## Security Considerations
* Use HTTPS endpoints for all webhook calls.
* Store sensitive values as secrets using the ElevenLabs Secrets Manager.
* Validate that all authorization headers follow the required format.
## Conclusion
This guide details how to integrate Zendesk into our conversational AI platform for efficient support ticket management. By leveraging webhook tools and historical support data, the integration streamlines the support process, reducing resolution times and enhancing overall service quality.
For additional details on tool configuration or other integrations, refer to the [Tools Overview](/docs/conversational-ai/customization/tools-events/server-tools).
# Python SDK
> Conversational AI SDK: deploy customized, interactive voice agents in minutes.
<Info>
Also see the
[Conversational AI overview](/docs/conversational-ai/overview)
</Info>
## Installation
Install the `elevenlabs` Python package in your project:
```shell
pip install elevenlabs
# or
poetry add elevenlabs
```
If you want to use the default implementation of audio input/output you will also need the `pyaudio` extra:
```shell
pip install "elevenlabs[pyaudio]"
# or
poetry add "elevenlabs[pyaudio]"
```
<Info>
The `pyaudio` package installation might require additional system dependencies.
See [PyAudio package README](https://pypi.org/project/PyAudio/) for more information.
<Tabs>
<Tab title="Linux">
On Debian-based systems you can install the dependencies with:
```shell
sudo apt install portaudio19
```
</Tab>
<Tab title="macOS">
On macOS with Homebrew you can install the dependencies with:
```shell
brew install portaudio
```
</Tab>
</Tabs>
</Info>
## Usage
In this example we will create a simple script that runs a conversation with the ElevenLabs Conversational AI agent.
You can find the full code in the [ElevenLabs examples repository](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/python).
First import the necessary dependencies:
```python
import os
import signal
from elevenlabs.client import ElevenLabs
from elevenlabs.conversational_ai.conversation import Conversation
from elevenlabs.conversational_ai.default_audio_interface import DefaultAudioInterface
```
Next load the agent ID and API key from environment variables:
```python
agent_id = os.getenv("AGENT_ID")
api_key = os.getenv("ELEVENLABS_API_KEY")
```
The API key is only required for non-public agents that have authentication enabled.
You don't have to set it for public agents and the code will work fine without it.
Then create the `ElevenLabs` client instance:
```python
client = ElevenLabs(api_key=api_key)
```
Now we initialize the `Conversation` instance:
```python
conversation = Conversation(
# API client and agent ID.
client,
agent_id,
# Assume auth is required when API_KEY is set.
requires_auth=bool(api_key),
# Use the default audio interface.
audio_interface=DefaultAudioInterface(),
# Simple callbacks that print the conversation to the console.
callback_agent_response=lambda response: print(f"Agent: {response}"),
callback_agent_response_correction=lambda original, corrected: print(f"Agent: {original} -> {corrected}"),
callback_user_transcript=lambda transcript: print(f"User: {transcript}"),
# Uncomment if you want to see latency measurements.
# callback_latency_measurement=lambda latency: print(f"Latency: {latency}ms"),
)
```
We are using the `DefaultAudioInterface` which uses the default system audio input/output devices for the conversation.
You can also implement your own audio interface by subclassing `elevenlabs.conversational_ai.conversation.AudioInterface`.
Now we can start the conversation:
```python
conversation.start_session()
```
To get a clean shutdown when the user presses `Ctrl+C` we can add a signal handler which will call `end_session()`:
```python
signal.signal(signal.SIGINT, lambda sig, frame: conversation.end_session())
```
And lastly we wait for the conversation to end and print out the conversation ID (which can be used for reviewing the conversation history and debugging):
```python
conversation_id = conversation.wait_for_session_end()
print(f"Conversation ID: {conversation_id}")
```
All that is left is to run the script and start talking to the agent:
```shell
# For public agents:
AGENT_ID=youragentid python demo.py
# For private agents:
AGENT_ID=youragentid ELEVENLABS_API_KEY=yourapikey python demo.py
```
# React SDK
> Conversational AI SDK: deploy customized, interactive voice agents in minutes.
<Info>
Also see the
[Conversational AI overview](/docs/conversational-ai/overview)
</Info>
## Installation
Install the package in your project through package manager.
```shell
npm install @11labs/react
# or
yarn add @11labs/react
# or
pnpm install @11labs/react
```
## Usage
### useConversation
React hook for managing websocket connection and audio usage for ElevenLabs Conversational AI.
#### Initialize conversation
First, initialize the Conversation instance.
```tsx
const conversation = useConversation();
```
Note that Conversational AI requires microphone access.
Consider explaining and allowing access in your apps UI before the Conversation kicks off.
```js
// call after explaining to the user why the microphone access is needed
await navigator.mediaDevices.getUserMedia({ audio: true });
```
#### Options
The Conversation can be initialized with certain options. Those are all optional.
```tsx
const conversation = useConversation({
/* options object */
});
```
* **onConnect** - handler called when the conversation websocket connection is established.
* **onDisconnect** - handler called when the conversation websocket connection is ended.
* **onMessage** - handler called when a new message is received. These can be tentative or final transcriptions of user voice, replies produced by LLM, or debug message when a debug option is enabled.
* **onError** - handler called when a error is encountered.
#### Methods
**startSession**
`startSession` method kick off the websocket connection and starts using microphone to communicate with the ElevenLabs Conversational AI agent.
The method accepts options object, with the `url` or `agentId` option being required.
Agent ID can be acquired through [ElevenLabs UI](https://elevenlabs.io/app/conversational-ai) and is always necessary.
```js
const conversation = useConversation();
const conversationId = await conversation.startSession({ url });
```
For the public agents, define `agentId` - no signed link generation necessary.
In case the conversation requires authorization, use the REST API to generate signed links. Use the signed link as a `url` parameter.
`startSession` returns promise resolving to `conversationId`. The value is a globally unique conversation ID you can use to identify separate conversations.
```js
// your server
const requestHeaders: HeadersInit = new Headers();
requestHeaders.set("xi-api-key", process.env.XI_API_KEY); // use your ElevenLabs API key
const response = await fetch(
"https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id={{agent id created through ElevenLabs UI}}",
{
method: "GET",
headers: requestHeaders,
}
);
if (!response.ok) {
return Response.error();
}
const body = await response.json();
const url = body.signed_url; // use this URL for startSession method.
```
**endSession**
A method to manually end the conversation. The method will end the conversation and disconnect from websocket.
```js
await conversation.endSession();
```
**setVolume**
A method to set the output volume of the conversation. Accepts object with volume field between 0 and 1.
```js
await conversation.setVolume({ volume: 0.5 });
```
**status**
A React state containing the current status of the conversation.
```js
const { status } = useConversation();
console.log(status); // "connected" or "disconnected"
```
**isSpeaking**
A React state containing the information of whether the agent is currently speaking.
This is helpful for indicating the mode in your UI.
```js
const { isSpeaking } = useConversation();
console.log(isSpeaking); // boolean
```
# JavaScript SDK
> Conversational AI SDK: deploy customized, interactive voice agents in minutes.
<Info>
Also see the
[Conversational AI overview](/docs/conversational-ai/overview)
</Info>
## Installation
Install the package in your project through package manager.
```shell
npm install @11labs/client
# or
yarn add @11labs/client
# or
pnpm install @11labs/client
```
## Usage
This library is primarily meant for development in vanilla JavaScript projects, or as a base for libraries tailored to specific frameworks.
It is recommended to check whether your specific framework has it's own library.
However, you can use this library in any JavaScript-based project.
### Initialize conversation
First, initialize the Conversation instance:
```js
const conversation = await Conversation.startSession(options);
```
This will kick off the websocket connection and start using microphone to communicate with the ElevenLabs Conversational AI agent. Consider explaining and allowing microphone access in your apps UI before the Conversation kicks off:
```js
// call after explaining to the user why the microphone access is needed
await navigator.mediaDevices.getUserMedia({ audio: true });
```
#### Session configuration
The options passed to `startSession` specifiy how the session is established. There are two ways to start a session:
**Using Agent ID**
Agent ID can be acquired through [ElevenLabs UI](https://elevenlabs.io/app/conversational-ai).
For public agents, you can use the ID directly:
```js
const conversation = await Conversation.startSession({
agentId: '<your-agent-id>',
});
```
**Using a signed URL**
If the conversation requires authorization, you will need to add a dedicated endpoint to your server that
will request a signed url using the [ElevenLabs API](https://elevenlabs.io/docs/introduction) and pass it back to the client.
Here's an example of how it could be set up:
```js
// Node.js server
app.get('/signed-url', yourAuthMiddleware, async (req, res) => {
const response = await fetch(
`https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=${process.env.AGENT_ID}`,
{
method: 'GET',
headers: {
// Requesting a signed url requires your ElevenLabs API key
// Do NOT expose your API key to the client!
'xi-api-key': process.env.XI_API_KEY,
},
}
);
if (!response.ok) {
return res.status(500).send('Failed to get signed URL');
}
const body = await response.json();
res.send(body.signed_url);
});
```
```js
// Client
const response = await fetch('/signed-url', yourAuthHeaders);
const signedUrl = await response.text();
const conversation = await Conversation.startSession({ signedUrl });
```
#### Optional callbacks
The options passed to `startSession` can also be used to register optional callbacks:
* **onConnect** - handler called when the conversation websocket connection is established.
* **onDisconnect** - handler called when the conversation websocket connection is ended.
* **onMessage** - handler called when a new text message is received. These can be tentative or final transcriptions of user voice, replies produced by LLM. Primarily used for handling conversation transcription.
* **onError** - handler called when an error is encountered.
* **onStatusChange** - handler called whenever connection status changes. Can be `connected`, `connecting` and `disconnected` (initial).
* **onModeChange** - handler called when a status changes, eg. agent switches from `speaking` to `listening`, or the other way around.
#### Return value
`startSession` returns a `Conversation` instance that can be used to control the session. The method will throw an error if the session cannot be established. This can happen if the user denies microphone access, or if the websocket connection
fails.
**endSession**
A method to manually end the conversation. The method will end the conversation and disconnect from websocket.
Afterwards the conversation instance will be unusable and can be safely discarded.
```js
await conversation.endSession();
```
**getId**
A method returning the conversation ID.
```js
const id = conversation.getId();
```
**setVolume**
A method to set the output volume of the conversation. Accepts object with volume field between 0 and 1.
```js
await conversation.setVolume({ volume: 0.5 });
```
**getInputVolume / getOutputVolume**
Methods that return the current input/output volume on a scale from `0` to `1` where `0` is -100 dB and `1` is -30 dB.
```js
const inputVolume = await conversation.getInputVolume();
const outputVolume = await conversation.getOutputVolume();
```
**getInputByteFrequencyData / getOutputByteFrequencyData**
Methods that return `Uint8Array`s containg the current input/output frequency data. See [AnalyserNode.getByteFrequencyData](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData) for more information.
# Swift SDK
> Conversational AI SDK: deploy customized, interactive voice agents in your Swift applications.
<Info>
Also see the
[Conversational AI overview](/docs/conversational-ai/overview)
</Info>
## Installation
Add the ElevenLabs Swift SDK to your project using Swift Package Manager:
<Steps>
<Step title="Add the Package Dependency">
<>
1. Open your project in Xcode
2. Go to `File` > `Add Packages...`
3. Enter the repository URL: `https://github.com/elevenlabs/ElevenLabsSwift`
4. Select your desired version
</>
</Step>
<Step title="Import the SDK">
<>
```swift
import ElevenLabsSDK
```
</>
</Step>
</Steps>
<Warning>
Ensure you add `NSMicrophoneUsageDescription` to your Info.plist to explain microphone access to
users.
</Warning>
## Usage
This library is primarily designed for Conversational AI integration in Swift applications. Please use an alternative dependency for other features, such as speech synthesis.
### Initialize Conversation
First, create a session configuration and set up the necessary callbacks:
```swift
// Configure the session
let config = ElevenLabsSDK.SessionConfig(agentId: "your-agent-id")
// Set up callbacks
var callbacks = ElevenLabsSDK.Callbacks()
callbacks.onConnect = { conversationId in
print("Connected with ID: \(conversationId)")
}
callbacks.onDisconnect = {
print("Disconnected")
}
callbacks.onMessage = { message, role in
print("\(role.rawValue): \(message)")
}
callbacks.onError = { error, info in
print("Error: \(error), Info: \(String(describing: info))")
}
callbacks.onStatusChange = { status in
print("Status changed to: \(status.rawValue)")
}
callbacks.onModeChange = { mode in
print("Mode changed to: \(mode.rawValue)")
}
callbacks.onVolumeUpdate = { volume in
print("Volume updated: \(volume)")
}
```
### Session Configuration
There are two ways to initialize a session:
<Tabs>
<Tab title="Using Agent ID">
You can obtain an Agent ID through the [ElevenLabs UI](https://elevenlabs.io/app/conversational-ai):
```swift
let config = ElevenLabsSDK.SessionConfig(agentId: "<your-agent-id>")
```
</Tab>
<Tab title="Using Signed URL">
For conversations requiring authorization, implement a server endpoint that requests a signed URL:
```swift
// Swift example using URLSession
func getSignedUrl() async throws -> String {
let url = URL(string: "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url")!
var request = URLRequest(url: url)
request.setValue("YOUR-API-KEY", forHTTPHeaderField: "xi-api-key")
let (data, _) = try await URLSession.shared.data(for: request)
let response = try JSONDecoder().decode(SignedUrlResponse.self, from: data)
return response.signedUrl
}
// Use the signed URL
let signedUrl = try await getSignedUrl()
let config = ElevenLabsSDK.SessionConfig(signedUrl: signedUrl)
```
</Tab>
</Tabs>
### Client Tools
Client Tools allow you to register custom functions that can be called by your AI agent during conversations. This enables your agent to perform actions in your application.
#### Registering Tools
Register custom tools before starting a conversation:
```swift
// Create client tools instance
var clientTools = ElevenLabsSDK.ClientTools()
// Register a custom tool with an async handler
clientTools.register("generate_joke") { parameters async throws -> String? in
// Parameters is a [String: Any] dictionary
guard let joke = parameters["joke"] as? String else {
throw ElevenLabsSDK.ClientToolError.invalidParameters
}
print("generate_joke tool received joke: \(joke)")
return joke
}
```
<Info>
Remember to setup your agent with the client-tools in the ElevenLabs UI. See the [Client Tools
documentation](/docs/conversational-ai/customization/tools-events/client-tools) for setup
instructions.
</Info>
### Starting the Conversation
Initialize the conversation session asynchronously:
```swift
Task {
do {
let conversation = try await ElevenLabsSDK.Conversation.startSession(
config: config,
callbacks: callbacks,
clientTools: clientTools // Optional: pass the previously configured client tools
)
// Use the conversation instance
} catch {
print("Failed to start conversation: \(error)")
}
}
```
<Note>
The client tools parameter is optional. If you don't need custom tools, you can omit it when
starting the session.
</Note>
### Audio Sample Rates
The ElevenLabs SDK currently uses a default input sample rate of `16,000 Hz`. However, the output sample rate is configurable based on the agent's settings. Ensure that the output sample rate aligns with your specific application's audio requirements for smooth interaction.
<Note>
The SDK does not currently support ulaw format for audio encoding. For compatibility, consider using alternative formats.
</Note>
### Managing the Session
<CodeGroup>
```swift:End Session
// Starts the session
conversation.startSession()
// Ends the session
conversation.endSession()
```
```swift:Recording Controls
// Start recording
conversation.startRecording()
// Stop recording
conversation.stopRecording()
```
</CodeGroup>
### Example Implementation
For a full, working example, check out the [example application on GitHub](https://github.com/elevenlabs/elevenlabs-examples/tree/main/examples/conversational-ai/swift).
Here's an example SwiftUI view implementing the conversation interface:
```swift
struct ConversationalAIView: View {
@State private var conversation: ElevenLabsSDK.Conversation?
@State private var mode: ElevenLabsSDK.Mode = .listening
@State private var status: ElevenLabsSDK.Status = .disconnected
@State private var audioLevel: Float = 0.0
private func startConversation() {
Task {
do {
let config = ElevenLabsSDK.SessionConfig(agentId: "your-agent-id")
var callbacks = ElevenLabsSDK.Callbacks()
callbacks.onConnect = { conversationId in
status = .connected
}
callbacks.onDisconnect = {
status = .disconnected
}
callbacks.onModeChange = { newMode in
DispatchQueue.main.async {
mode = newMode
}
}
callbacks.onVolumeUpdate = { newVolume in
DispatchQueue.main.async {
audioLevel = newVolume
}
}
conversation = try await ElevenLabsSDK.Conversation.startSession(
config: config,
callbacks: callbacks
)
} catch {
print("Failed to start conversation: \(error)")
}
}
}
var body: some View {
VStack {
// Your UI implementation
Button(action: startConversation) {
Text(status == .connected ? "End Call" : "Start Call")
}
}
}
}
```
<Note>
This SDK is currently experimental and under active development. While it's stable enough for
testing and development, it's not recommended for production use yet.
</Note>
# WebSocket
> Create real-time, interactive voice conversations with AI agents
<Note>
This documentation is for developers integrating directly with the ElevenLabs WebSocket API. For
convenience, consider using [the official SDKs provided by
ElevenLabs](/docs/conversational-ai/libraries/python).
</Note>
The ElevenLabs [Conversational AI](https://elevenlabs.io/conversational-ai) WebSocket API enables real-time, interactive voice conversations with AI agents. By establishing a WebSocket connection, you can send audio input and receive audio responses in real-time, creating life-like conversational experiences.
<Note>
Endpoint:
`wss://api.elevenlabs.io/v1/convai/conversation?agent_id={agent_id}`
</Note>
## Authentication
### Using Agent ID
For public agents, you can directly use the `agent_id` in the WebSocket URL without additional authentication:
```bash
wss://api.elevenlabs.io/v1/convai/conversation?agent_id=<your-agent-id>
```
### Using a Signed URL
For private agents or conversations requiring authorization, obtain a signed URL from your server, which securely communicates with the ElevenLabs API using your API key.
### Example using cURL
**Request:**
```bash
curl -X GET "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=<your-agent-id>" \
-H "xi-api-key: <your-api-key>"
```
**Response:**
```json
{
"signed_url": "wss://api.elevenlabs.io/v1/convai/conversation?agent_id=<your-agent-id>&token=<token>"
}
```
<Warning>
Never expose your ElevenLabs API key on the client side.
</Warning>
## WebSocket events
<Card title="WebSocket API Reference" icon="code" iconPosition="left" href="/docs/conversational-ai/api-reference/conversational-ai/websocket">
See the Conversational AI WebSocket API reference documentation for detailed message structures,
parameters, and examples.
</Card>
## Latency Management
To ensure smooth conversations, implement these strategies:
* **Adaptive Buffering:** Adjust audio buffering based on network conditions.
* **Jitter Buffer:** Implement a jitter buffer to smooth out variations in packet arrival times.
* **Ping-Pong Monitoring:** Use ping and pong events to measure round-trip time and adjust accordingly.
## Security Best Practices
* Rotate API keys regularly and use environment variables to store them.
* Implement rate limiting to prevent abuse.
* Clearly explain the intention when prompting users for microphone access.
* Optimized Chunking: Tweak the audio chunk duration to balance latency and efficiency.
## Additional Resources
* [ElevenLabs Conversational AI Documentation](/docs/conversational-ai/overview)
* [ElevenLabs Conversational AI SDKs](/docs/conversational-ai/client-sdk)
# Create agent
```http
POST https://api.elevenlabs.io/v1/convai/agents/create
Content-Type: application/json
```
Create an agent from a config object
## Query Parameters
- UseToolIds (optional): Use tool ids instead of tools specs from request payload.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/agents/create \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"conversation_config": {}
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/create"
payload = { "conversation_config": {} }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/create';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"conversation_config":{}}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/create"
payload := strings.NewReader("{\n  \"conversation_config\": {}\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/create")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"conversation_config\": {}\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/agents/create")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"conversation_config\": {}\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/agents/create', [
'body' => '{
"conversation_config": {}
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/create");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"conversation_config\": {}\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["conversation_config": []] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/create")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"conversation_config": {}
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/create"
querystring = {"use_tool_ids":"true"}
payload = { "conversation_config": {} }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"conversation_config":{}}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true"
payload := strings.NewReader("{\n  \"conversation_config\": {}\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"conversation_config\": {}\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"conversation_config\": {}\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true', [
'body' => '{
"conversation_config": {}
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"conversation_config\": {}\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["conversation_config": []] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/create?use_tool_ids=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get agent
```http
GET https://api.elevenlabs.io/v1/convai/agents/{agent_id}
```
Retrieve config for an agent
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/agents/:agent_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List agents
```http
GET https://api.elevenlabs.io/v1/convai/agents
```
Returns a page of your agents and their metadata.
## Query Parameters
- Cursor (optional): Used for fetching next page. Cursor is returned in the response.
- PageSize (optional): How many Agents to return at maximum. Can not exceed 100, defaults to 30.
- Search (optional): Search by agents name.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/agents \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/agents \
-H "xi-api-key: <apiKey>" \
-d cursor=string \
-d page_size=0
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents"
querystring = {"cursor":"string","page_size":"0"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents?cursor=string&page_size=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update agent
```http
PATCH https://api.elevenlabs.io/v1/convai/agents/{agent_id}
Content-Type: application/json
```
Patches an Agent settings
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Query Parameters
- UseToolIds (optional): Use tool ids instead of tools specs from request payload.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X PATCH https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X PATCH "https://api.elevenlabs.io/v1/convai/agents/:agent_id?use_tool_ids=true" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id"
querystring = {"use_tool_ids":"true"}
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id?use_tool_ids=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete agent
```http
DELETE https://api.elevenlabs.io/v1/convai/agents/{agent_id}
```
Delete an agent
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/agents/:agent_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get link
```http
GET https://api.elevenlabs.io/v1/convai/agents/{agent_id}/link
```
Get the current link used to share the agent with others
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/link")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/agents/:agent_id/link \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/link")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List conversations
```http
GET https://api.elevenlabs.io/v1/convai/conversations
```
Get all conversations of agents that user owns. With option to restrict to a specific agent.
## Query Parameters
- Cursor (optional): Used for fetching next page. Cursor is returned in the response.
- AgentId (optional): The id of the agent you're taking the action on.
- CallSuccessful (optional): The result of the success evaluation
- PageSize (optional): How many conversations to return at maximum. Can not exceed 100, defaults to 30.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/conversations \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/conversations \
-H "xi-api-key: <apiKey>" \
-d cursor=string \
-d agent_id=string
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations"
querystring = {"cursor":"string","agent_id":"string"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations?cursor=string&agent_id=string")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get conversation details
```http
GET https://api.elevenlabs.io/v1/convai/conversations/{conversation_id}
```
Get the details of a particular conversation
## Path Parameters
- ConversationId (required): The id of the conversation you're taking the action on.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/conversations/123 \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/123"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/123';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/123"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/123")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations/123")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations/123', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/123");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/123")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/conversations/:conversation_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete conversation
```http
DELETE https://api.elevenlabs.io/v1/convai/conversations/{conversation_id}
```
Delete a particular conversation
## Path Parameters
- ConversationId (required): The id of the conversation you're taking the action on.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/conversations/:conversation_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get conversation audio
```http
GET https://api.elevenlabs.io/v1/convai/conversations/{conversation_id}/audio
```
Get the audio recording of a particular conversation
## Path Parameters
- ConversationId (required): The id of the conversation you're taking the action on.
## Response Body
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/conversations/:conversation_id/audio \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get signed URL
```http
GET https://api.elevenlabs.io/v1/convai/conversation/get_signed_url
```
Get a signed url to start a conversation with an agent with an agent that requires authorization
## Query Parameters
- AgentId (required): The id of the agent you're taking the action on.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -G https://api.elevenlabs.io/v1/convai/conversation/get_signed_url \
-H "xi-api-key: <apiKey>" \
-d agent_id=21m00Tcm4TlvDq8ikWAM
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url"
querystring = {"agent_id":"21m00Tcm4TlvDq8ikWAM"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/conversation/get_signed_url \
-H "xi-api-key: <apiKey>" \
-d agent_id=string
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url"
querystring = {"agent_id":"string"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversation/get_signed_url?agent_id=string")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Send conversation feedback
```http
POST https://api.elevenlabs.io/v1/convai/conversations/{conversation_id}/feedback
Content-Type: application/json
```
Send the feedback for the given conversation
## Path Parameters
- ConversationId (required): The id of the conversation you're taking the action on.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"feedback": "like"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback"
payload = { "feedback": "like" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"feedback":"like"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback"
payload := strings.NewReader("{\n  \"feedback\": \"like\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"feedback\": \"like\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"feedback\": \"like\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback', [
'body' => '{
"feedback": "like"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"feedback\": \"like\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["feedback": "like"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/21m00Tcm4TlvDq8ikWAM/feedback")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/conversations/:conversation_id/feedback \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"feedback": "like"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback"
payload = { "feedback": "like" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"feedback":"like"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback"
payload := strings.NewReader("{\n  \"feedback\": \"like\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"feedback\": \"like\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"feedback\": \"like\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback', [
'body' => '{
"feedback": "like"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"feedback\": \"like\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["feedback": "like"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/conversations/%3Aconversation_id/feedback")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List knowledge base documents
```http
GET https://api.elevenlabs.io/v1/convai/knowledge-base
```
Get a list of available knowledge base documents
## Query Parameters
- Cursor (optional): Used for fetching next page. Cursor is returned in the response.
- PageSize (optional): How many documents to return at maximum. Can not exceed 100, defaults to 30.
- Search (optional): If specified, the endpoint returns only such knowledge base documents whose names start with this string.
- ShowOnlyOwnedDocuments (optional): If set to true, the endpoint will return only documents owned by you (and not shared from somebody else).
- UseTypesense (optional): If set to true, the endpoint will use typesense DB to search for the documents).
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/knowledge-base \
-H "xi-api-key: <apiKey>" \
-d cursor=string \
-d page_size=0
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base"
querystring = {"cursor":"string","page_size":"0"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base?cursor=string&page_size=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete knowledge base document
```http
DELETE https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}
```
Delete a document from the knowledge base
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get knowledge base document
```http
GET https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}
```
Get details about a specific documentation making up the agent's knowledge base
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create knowledge base document
```http
POST https://api.elevenlabs.io/v1/convai/knowledge-base
Content-Type: multipart/form-data
```
Upload a file or webpage URL to create a knowledge base document. <br> <Note> After creating the document, update the agent's knowledge base by calling [Update agent](/docs/conversational-ai/api-reference/agents/update-agent). </Note>
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/knowledge-base \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F file=@<file1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base"
files = { "file": "open('<file1>', 'rb')" }
payload = {
"name": ,
"url":
}
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, data=payload, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base';
const form = new FormData();
form.append('name', '');
form.append('url', '');
form.append('file', '<file1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/knowledge-base")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/knowledge-base', [
'multipart' => [
[
'name' => 'file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "name",
"value":
],
[
"name": "url",
"value":
],
[
"name": "file",
"fileName": "<file1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/knowledge-base \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base"
payload = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
}
response = requests.post(url, data=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base';
const form = new FormData();
form.append('name', '');
form.append('url', '');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/knowledge-base")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/knowledge-base', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"url\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "name",
"value":
],
[
"name": "url",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Compute RAG index
```http
POST https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}/rag-index
Content-Type: application/json
```
In case the document is not RAG indexed, it triggers rag indexing task, otherwise it just returns the current status.
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
## Query Parameters
- ForceReindex (optional): In case the document is indexed and for some reason you want to reindex it, set this param as true.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"model": "e5_mistral_7b_instruct"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index"
payload = { "model": "e5_mistral_7b_instruct" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"model":"e5_mistral_7b_instruct"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index"
payload := strings.NewReader("{\n  \"model\": \"e5_mistral_7b_instruct\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"model\": \"e5_mistral_7b_instruct\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"model\": \"e5_mistral_7b_instruct\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index', [
'body' => '{
"model": "e5_mistral_7b_instruct"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"model\": \"e5_mistral_7b_instruct\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["model": "e5_mistral_7b_instruct"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/rag-index")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id/rag-index?force_reindex=true" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"model": "e5_mistral_7b_instruct"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index"
querystring = {"force_reindex":"true"}
payload = { "model": "e5_mistral_7b_instruct" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"model":"e5_mistral_7b_instruct"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true"
payload := strings.NewReader("{\n  \"model\": \"e5_mistral_7b_instruct\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"model\": \"e5_mistral_7b_instruct\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"model\": \"e5_mistral_7b_instruct\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true', [
'body' => '{
"model": "e5_mistral_7b_instruct"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"model\": \"e5_mistral_7b_instruct\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["model": "e5_mistral_7b_instruct"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/rag-index?force_reindex=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get dependent agents
```http
GET https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}/dependent-agents
```
Get a list of agents depending on this knowledge base document
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
## Query Parameters
- Cursor (optional): Used for fetching next page. Cursor is returned in the response.
- PageSize (optional): How many documents to return at maximum. Can not exceed 100, defaults to 30.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/dependent-agents")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id/dependent-agents \
-H "xi-api-key: <apiKey>" \
-d cursor=string \
-d page_size=0
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents"
querystring = {"cursor":"string","page_size":"0"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/dependent-agents?cursor=string&page_size=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get document content
```http
GET https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}/content
```
Get the entire content of a document from the knowledge base
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
## Response Body
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id/content \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get document chunk
```http
GET https://api.elevenlabs.io/v1/convai/knowledge-base/{documentation_id}/chunk/{chunk_id}
```
Get details about a specific documentation part used by RAG.
## Path Parameters
- DocumentationId (required): The id of a document from the knowledge base. This is returned on document addition.
- ChunkId (required): The id of a document RAG chunk from the knowledge base.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/21m00Tcm4TlvDq8ikWAM/chunk/chunk_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/knowledge-base/:documentation_id/chunk/:chunk_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/knowledge-base/%3Adocumentation_id/chunk/%3Achunk_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create phone number
```http
POST https://api.elevenlabs.io/v1/convai/phone-numbers/create
Content-Type: application/json
```
Import Phone Number from Twilio configuration
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/phone-numbers/create \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"phone_number": "phone_number",
"provider": "twilio",
"label": "label",
"sid": "sid",
"token": "token"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/create"
payload = {
"phone_number": "phone_number",
"provider": "twilio",
"label": "label",
"sid": "sid",
"token": "token"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/create';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"phone_number":"phone_number","provider":"twilio","label":"label","sid":"sid","token":"token"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/create"
payload := strings.NewReader("{\n  \"phone_number\": \"phone_number\",\n  \"provider\": \"twilio\",\n  \"label\": \"label\",\n  \"sid\": \"sid\",\n  \"token\": \"token\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/create")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"phone_number\": \"phone_number\",\n  \"provider\": \"twilio\",\n  \"label\": \"label\",\n  \"sid\": \"sid\",\n  \"token\": \"token\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/phone-numbers/create")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"phone_number\": \"phone_number\",\n  \"provider\": \"twilio\",\n  \"label\": \"label\",\n  \"sid\": \"sid\",\n  \"token\": \"token\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/phone-numbers/create', [
'body' => '{
"phone_number": "phone_number",
"provider": "twilio",
"label": "label",
"sid": "sid",
"token": "token"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/create");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"phone_number\": \"phone_number\",\n  \"provider\": \"twilio\",\n  \"label\": \"label\",\n  \"sid\": \"sid\",\n  \"token\": \"token\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"phone_number": "phone_number",
"provider": "twilio",
"label": "label",
"sid": "sid",
"token": "token"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/create")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/phone-numbers/create \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"phone_number": "string",
"provider": "twilio",
"label": "string",
"sid": "string",
"token": "string"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/create"
payload = {
"phone_number": "string",
"provider": "twilio",
"label": "string",
"sid": "string",
"token": "string"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/create';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"phone_number":"string","provider":"twilio","label":"string","sid":"string","token":"string"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/create"
payload := strings.NewReader("{\n  \"phone_number\": \"string\",\n  \"provider\": \"twilio\",\n  \"label\": \"string\",\n  \"sid\": \"string\",\n  \"token\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/create")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"phone_number\": \"string\",\n  \"provider\": \"twilio\",\n  \"label\": \"string\",\n  \"sid\": \"string\",\n  \"token\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/phone-numbers/create")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"phone_number\": \"string\",\n  \"provider\": \"twilio\",\n  \"label\": \"string\",\n  \"sid\": \"string\",\n  \"token\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/phone-numbers/create', [
'body' => '{
"phone_number": "string",
"provider": "twilio",
"label": "string",
"sid": "string",
"token": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/create");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"phone_number\": \"string\",\n  \"provider\": \"twilio\",\n  \"label\": \"string\",\n  \"sid\": \"string\",\n  \"token\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"phone_number": "string",
"provider": "twilio",
"label": "string",
"sid": "string",
"token": "string"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/create")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List phone numbers
```http
GET https://api.elevenlabs.io/v1/convai/phone-numbers/
```
Retrieve all Phone Numbers
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/phone-numbers/ \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/phone-numbers/")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/phone-numbers/', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/phone-numbers/ \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/phone-numbers/")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/phone-numbers/', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get phone number
```http
GET https://api.elevenlabs.io/v1/convai/phone-numbers/{phone_number_id}
```
Retrieve Phone Number details by ID
## Path Parameters
- PhoneNumberId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/phone-numbers/:phone_number_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update phone number
```http
PATCH https://api.elevenlabs.io/v1/convai/phone-numbers/{phone_number_id}
Content-Type: application/json
```
Update Phone Number details by ID
## Path Parameters
- PhoneNumberId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X PATCH https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X PATCH https://api.elevenlabs.io/v1/convai/phone-numbers/:phone_number_id \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete phone number
```http
DELETE https://api.elevenlabs.io/v1/convai/phone-numbers/{phone_number_id}
```
Delete Phone Number by ID
## Path Parameters
- PhoneNumberId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/TeaqRRdTcIfIu2i7BYfT")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/phone-numbers/:phone_number_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/phone-numbers/%3Aphone_number_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get widget
```http
GET https://api.elevenlabs.io/v1/convai/agents/{agent_id}/widget
```
Retrieve the widget configuration for an agent
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Query Parameters
- ConversationSignature (optional): An expiring token that enables a conversation to start. These can be generated for an agent using the /v1/convai/conversation/get_signed_url endpoint
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/widget")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/convai/agents/:agent_id/widget \
-H "xi-api-key: <apiKey>" \
-d conversation_signature=string
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget"
querystring = {"conversation_signature":"string"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/widget?conversation_signature=string")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create widget avatar
```http
POST https://api.elevenlabs.io/v1/convai/agents/{agent_id}/avatar
Content-Type: multipart/form-data
```
Sets the avatar for an agent displayed in the widget
## Path Parameters
- AgentId (required): The id of an agent. This is returned on agent creation.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F avatar_file=@<file1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar"
files = { "avatar_file": "open('<file1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar';
const form = new FormData();
form.append('avatar_file', '<file1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar', [
'multipart' => [
[
'name' => 'avatar_file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "avatar_file",
"fileName": "<file1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/21m00Tcm4TlvDq8ikWAM/avatar")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/agents/:agent_id/avatar \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F avatar_file=@<filename1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar"
files = { "avatar_file": "open('<filename1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar';
const form = new FormData();
form.append('avatar_file', '<filename1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar', [
'multipart' => [
[
'name' => 'avatar_file',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"avatar_file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "avatar_file",
"fileName": "<filename1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/agents/%3Aagent_id/avatar")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get settings
```http
GET https://api.elevenlabs.io/v1/convai/settings
```
Retrieve Convai settings for the workspace
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/settings \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/settings"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/settings';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/settings \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/settings"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/settings';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update settings
```http
PATCH https://api.elevenlabs.io/v1/convai/settings
Content-Type: application/json
```
Update Convai settings for the workspace
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X PATCH https://api.elevenlabs.io/v1/convai/settings \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/settings"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/settings';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/settings"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/settings")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/settings', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/settings");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X PATCH https://api.elevenlabs.io/v1/convai/settings \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/settings"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.patch(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/settings';
const options = {
method: 'PATCH',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/settings"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/convai/settings")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/convai/settings', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/settings");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get secrets
```http
GET https://api.elevenlabs.io/v1/convai/secrets
```
Get all workspace secrets for the user
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/convai/secrets \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/secrets")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/secrets', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/convai/secrets \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/convai/secrets")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/convai/secrets', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create secret
```http
POST https://api.elevenlabs.io/v1/convai/secrets
Content-Type: application/json
```
Create a new secret for the workspace
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/secrets \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"type": "new",
"name": "name",
"value": "value"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets"
payload = {
"type": "new",
"name": "name",
"value": "value"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"type":"new","name":"name","value":"value"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets"
payload := strings.NewReader("{\n  \"type\": \"new\",\n  \"name\": \"name\",\n  \"value\": \"value\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"type\": \"new\",\n  \"name\": \"name\",\n  \"value\": \"value\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/secrets")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"type\": \"new\",\n  \"name\": \"name\",\n  \"value\": \"value\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/secrets', [
'body' => '{
"type": "new",
"name": "name",
"value": "value"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"type\": \"new\",\n  \"name\": \"name\",\n  \"value\": \"value\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"type": "new",
"name": "name",
"value": "value"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/convai/secrets \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"type": "new",
"name": "string",
"value": "string"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets"
payload = {
"type": "new",
"name": "string",
"value": "string"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"type":"new","name":"string","value":"string"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets"
payload := strings.NewReader("{\n  \"type\": \"new\",\n  \"name\": \"string\",\n  \"value\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"type\": \"new\",\n  \"name\": \"string\",\n  \"value\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/convai/secrets")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"type\": \"new\",\n  \"name\": \"string\",\n  \"value\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/convai/secrets', [
'body' => '{
"type": "new",
"name": "string",
"value": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"type\": \"new\",\n  \"name\": \"string\",\n  \"value\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"type": "new",
"name": "string",
"value": "string"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete secret
```http
DELETE https://api.elevenlabs.io/v1/convai/secrets/{secret_id}
```
Delete a workspace secret if it's not in use
## Path Parameters
- SecretId (required)
## Response Body
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/secrets/secret_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets/secret_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets/secret_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets/secret_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets/secret_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/secrets/secret_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/secrets/secret_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets/secret_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets/secret_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/convai/secrets/:secret_id \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id"
headers = {"xi-api-key": "<apiKey>"}
response = requests.delete(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id';
const options = {method: 'DELETE', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/convai/secrets/%3Asecret_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Introduction
> Welcome to the ElevenLabs API reference.
## Installation
You can interact with the API through HTTP or Websocket requests from any language, via our official Python bindings or our official Node.js libraries.
To install the official Python bindings, run the following command:
```bash
pip install elevenlabs
```
To install the official Node.js library, run the following command in your Node.js project directory:
```bash
npm install elevenlabs
```
<div id="overview-wave">
<ElevenLabsWaveform color="gray" />
</div>
# Authentication
## API Keys
The ElevenLabs API uses API keys for authentication. Every request to the API must include your API key, used to authenticate your requests and track usage quota.
Each API key can be scoped to one of the following:
1. **Scope restriction:** Set access restrictions by limiting which API endpoints the key can access.
2. **Credit quota:** Define custom credit limits to control usage.
**Remember that your API key is a secret.** Do not share it with others or expose it in any client-side code (browsers, apps).
All API requests should include your API key in an `xi-api-key` HTTP header as follows:
```bash
xi-api-key: ELEVENLABS_API_KEY
```
### Making requests
You can paste the command below into your terminal to run your first API request. Make sure to replace `$ELEVENLABS_API_KEY` with your secret API key.
```bash
curl 'https://api.elevenlabs.io/v1/models' \
-H 'Content-Type: application/json' \
-H 'xi-api-key: $ELEVENLABS_API_KEY'
```
Example with the `elevenlabs` Python package:
```python
from elevenlabs.client import ElevenLabs
client = ElevenLabs(
api_key='YOUR_API_KEY',
)
```
Example with the `elevenlabs` Node.js package:
```javascript
import { ElevenLabsClient } from 'elevenlabs';
const client = new ElevenLabsClient({
apiKey: 'YOUR_API_KEY',
});
```
# Streaming
The ElevenLabs API supports real-time audio streaming for select endpoints, returning raw audio bytes (e.g., MP3 data) directly over HTTP using chunked transfer encoding. This allows clients to process or play audio incrementally as it is generated.
Our official [Node](https://github.com/elevenlabs/elevenlabs-js) and [Python](https://github.com/elevenlabs/elevenlabs-python) libraries include utilities to simplify handling this continuous audio stream.
Streaming is supported for the [Text to Speech API](/docs/api-reference/streaming), [Voice Changer API](/docs/api-reference/speech-to-speech-streaming) & [Audio Isolation API](/docs/api-reference/audio-isolation-stream). This section focuses on how streaming works for requests made to the Text to Speech API.
In Python, a streaming request looks like:
```python
from elevenlabs import stream
from elevenlabs.client import ElevenLabs
client = ElevenLabs()
audio_stream = client.text_to_speech.convert_as_stream(
text="This is a test",
voice_id="JBFqnCBsd6RMkjVDRZzb",
model_id="eleven_multilingual_v2"
)
# option 1: play the streamed audio locally
stream(audio_stream)
# option 2: process the audio bytes manually
for chunk in audio_stream:
if isinstance(chunk, bytes):
print(chunk)
```
In Node / Typescript, a streaming request looks like:
```javascript maxLines=0
import { ElevenLabsClient, stream } from 'elevenlabs';
import { Readable } from 'stream';
const client = new ElevenLabsClient();
async function main() {
const audioStream = await client.textToSpeech.convertAsStream('JBFqnCBsd6RMkjVDRZzb', {
text: 'This is a test',
model_id: 'eleven_multilingual_v2',
});
// option 1: play the streamed audio locally
await stream(Readable.from(audioStream));
// option 2: process the audio manually
for await (const chunk of audioStream) {
console.log(chunk);
}
}
main();
```
# Create speech
```http
POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}
Content-Type: application/json
```
Converts text into speech using a voice of your choice and returns audio.
## Path Parameters
- VoiceId (required): ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: The generated audio file
- 422: Validation Error
## Examples
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convert("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128"
payload := strings.NewReader("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128', [
'body' => '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/:voice_id?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convert("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("{\n  \"text\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0', [
'body' => '{
"text": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create speech with timing
```http
POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/with-timestamps
Content-Type: application/json
```
Generate speech from text with precise character-level timing information for audio-text synchronization.
## Path Parameters
- VoiceId (required): Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "This is a test for the API of ElevenLabs."
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert_with_timestamps(
voice_id="21m00Tcm4TlvDq8ikWAM",
text="This is a test for the API of ElevenLabs.",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convertWithTimestamps("21m00Tcm4TlvDq8ikWAM", {
text: "This is a test for the API of ElevenLabs."
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps"
payload := strings.NewReader("{\n  \"text\": \"This is a test for the API of ElevenLabs.\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"This is a test for the API of ElevenLabs.\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"This is a test for the API of ElevenLabs.\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps', [
'body' => '{
"text": "This is a test for the API of ElevenLabs."
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"This is a test for the API of ElevenLabs.\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "This is a test for the API of ElevenLabs."] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM/with-timestamps")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/:voice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert_with_timestamps(
voice_id="21m00Tcm4TlvDq8ikWAM",
text="This is a test for the API of ElevenLabs.",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convertWithTimestamps("21m00Tcm4TlvDq8ikWAM", {
text: "This is a test for the API of ElevenLabs."
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("{\n  \"text\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0', [
'body' => '{
"text": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/with-timestamps?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Stream speech
```http
POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream
Content-Type: application/json
```
Converts text into speech using a voice of your choice and returns audio as an audio stream.
## Path Parameters
- VoiceId (required): ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: Streaming audio data
- 422: Validation Error
## Examples
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert_as_stream(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convertAsStream("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128"
payload := strings.NewReader("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128', [
'body' => '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/:voice_id/stream?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_speech.convert_as_stream(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSpeech.convertAsStream("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("{\n  \"text\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0', [
'body' => '{
"text": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Stream speech with timing
```http
POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream/with-timestamps
Content-Type: application/json
```
Converts text into speech using a voice of your choice and returns a stream of JSONs containing audio as a base64 encoded string together with information on when which character was spoken.
## Path Parameters
- VoiceId (required): ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: Stream of transcription chunks
- 422: Validation Error
## Examples
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
response = client.text_to_speech.stream_with_timestamps(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
for chunk in response:
yield chunk
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
const response = await client.textToSpeech.streamWithTimestamps("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
for await (const item of response) {
console.log(item);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128"
payload := strings.NewReader("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128', [
'body' => '{
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"The first move is what sets everything in motion.\",\n  \"model_id\": \"eleven_multilingual_v2\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"text": "The first move is what sets everything in motion.",
"model_id": "eleven_multilingual_v2"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/JBFqnCBsd6RMkjVDRZzb/stream/with-timestamps?output_format=mp3_44100_128")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-speech/:voice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
response = client.text_to_speech.stream_with_timestamps(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
text="The first move is what sets everything in motion.",
model_id="eleven_multilingual_v2",
)
for chunk in response:
yield chunk
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
const response = await client.textToSpeech.streamWithTimestamps("JBFqnCBsd6RMkjVDRZzb", {
output_format: "mp3_44100_128",
text: "The first move is what sets everything in motion.",
model_id: "eleven_multilingual_v2"
});
for await (const item of response) {
console.log(item);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("{\n  \"text\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0', [
'body' => '{
"text": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-speech/%3Avoice_id/stream/with-timestamps?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create transcript
```http
POST https://api.elevenlabs.io/v1/speech-to-text
Content-Type: multipart/form-data
```
Transcribe an audio or video file.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/speech-to-text \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F model_id="model_id" \
-F file=@<file1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_text.convert(
model_id="model_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToText.convert({
file: fs.createReadStream("/path/to/your/file"),
model_id: "model_id"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-text"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-text")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-text")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-text', [
'multipart' => [
[
'name' => 'model_id',
'contents' => '"model_id"'
],
[
'name' => 'file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-text");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "model_id",
"value": "\"model_id\""
],
[
"name": "file",
"fileName": "<file1>"
],
[
"name": "language_code",
"value":
],
[
"name": "tag_audio_events",
"value":
],
[
"name": "num_speakers",
"value":
],
[
"name": "timestamps_granularity",
"value":
],
[
"name": "diarize",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-text")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F model_id="string" \
-F file=@<filename1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_text.convert(
model_id="model_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToText.convert({
file: fs.createReadStream("/path/to/your/file"),
model_id: "model_id"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true', [
'multipart' => [
[
'name' => 'model_id',
'contents' => '"string"'
],
[
'name' => 'file',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language_code\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"tag_audio_events\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"timestamps_granularity\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"diarize\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "model_id",
"value": "\"string\""
],
[
"name": "file",
"fileName": "<filename1>"
],
[
"name": "language_code",
"value":
],
[
"name": "tag_audio_events",
"value":
],
[
"name": "num_speakers",
"value":
],
[
"name": "timestamps_granularity",
"value":
],
[
"name": "diarize",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-text?enable_logging=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Voice changer
```http
POST https://api.elevenlabs.io/v1/speech-to-speech/{voice_id}
Content-Type: multipart/form-data
```
Transform audio from one voice to another. Maintain full control over emotion, timing and delivery.
## Path Parameters
- VoiceId (required): ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: The generated audio file
- 422: Validation Error
## Examples
```shell
curl -X POST "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<file1> \
-F model_id="eleven_multilingual_sts_v2"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_speech.convert(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
model_id="eleven_multilingual_sts_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToSpeech.convert("JBFqnCBsd6RMkjVDRZzb", {
audio: fs.createReadStream("/path/to/your/file"),
output_format: "mp3_44100_128",
model_id: "eleven_multilingual_sts_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<file1>',
'contents' => null
],
[
'name' => 'model_id',
'contents' => '"eleven_multilingual_sts_v2"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "audio",
"fileName": "<file1>"
],
[
"name": "model_id",
"value": "\"eleven_multilingual_sts_v2\""
],
[
"name": "voice_settings",
"value":
],
[
"name": "seed",
"value":
],
[
"name": "remove_background_noise",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb?output_format=mp3_44100_128")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/speech-to-speech/:voice_id?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_speech.convert(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
model_id="eleven_multilingual_sts_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToSpeech.convert("JBFqnCBsd6RMkjVDRZzb", {
audio: fs.createReadStream("/path/to/your/file"),
output_format: "mp3_44100_128",
model_id: "eleven_multilingual_sts_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
],
[
"name": "model_id",
"value":
],
[
"name": "voice_settings",
"value":
],
[
"name": "seed",
"value":
],
[
"name": "remove_background_noise",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Voice changer stream
```http
POST https://api.elevenlabs.io/v1/speech-to-speech/{voice_id}/stream
Content-Type: multipart/form-data
```
Stream audio from one voice to another. Maintain full control over emotion, timing and delivery.
## Path Parameters
- VoiceId (required): ID of the voice to be used. Use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- EnableLogging (optional): When enable_logging is set to false zero retention mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Zero retention mode may only be used by enterprise customers.
- OptimizeStreamingLatency (optional): You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values:
0 - default mode (no latency optimizations)
1 - normal latency optimizations (about 50% of possible latency improvement of option 3)
2 - strong latency optimizations (about 75% of possible latency improvement of option 3)
3 - max latency optimizations
4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).
Defaults to None.
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: Streaming audio data
- 422: Validation Error
## Examples
```shell
curl -X POST "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<file1> \
-F model_id="eleven_multilingual_sts_v2"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_speech.convert_as_stream(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
model_id="eleven_multilingual_sts_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToSpeech.convertAsStream("JBFqnCBsd6RMkjVDRZzb", {
audio: fs.createReadStream("/path/to/your/file"),
output_format: "mp3_44100_128",
model_id: "eleven_multilingual_sts_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<file1>',
'contents' => null
],
[
'name' => 'model_id',
'contents' => '"eleven_multilingual_sts_v2"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\"eleven_multilingual_sts_v2\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "audio",
"fileName": "<file1>"
],
[
"name": "model_id",
"value": "\"eleven_multilingual_sts_v2\""
],
[
"name": "voice_settings",
"value":
],
[
"name": "seed",
"value":
],
[
"name": "remove_background_noise",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-speech/JBFqnCBsd6RMkjVDRZzb/stream?output_format=mp3_44100_128")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/speech-to-speech/:voice_id/stream?enable_logging=true&optimize_streaming_latency=0" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.speech_to_speech.convert_as_stream(
voice_id="JBFqnCBsd6RMkjVDRZzb",
output_format="mp3_44100_128",
model_id="eleven_multilingual_sts_v2",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.speechToSpeech.convertAsStream("JBFqnCBsd6RMkjVDRZzb", {
audio: fs.createReadStream("/path/to/your/file"),
output_format: "mp3_44100_128",
model_id: "eleven_multilingual_sts_v2"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_settings\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"seed\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
],
[
"name": "model_id",
"value":
],
[
"name": "voice_settings",
"value":
],
[
"name": "seed",
"value":
],
[
"name": "remove_background_noise",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/speech-to-speech/%3Avoice_id/stream?enable_logging=true&optimize_streaming_latency=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create sound effect
```http
POST https://api.elevenlabs.io/v1/sound-generation
Content-Type: application/json
```
Turn text into sound effects for your videos, voice-overs or video games using the most advanced sound effects model in the world.
## Query Parameters
- OutputFormat (optional): Output format of the generated audio. Formatted as codec_sample_rate_bitrate. So an mp3 with 22.05kHz sample rate at 32kbs is represented as mp3_22050_32. MP3 with 192kbps bitrate requires you to be subscribed to Creator tier or above. PCM with 44.1kHz sample rate requires you to be subscribed to Pro tier or above. Note that the μ-law format (sometimes written mu-law, often approximated as u-law) is commonly used for Twilio audio inputs.
## Response Body
- 200: The generated sound effect as an MP3 file
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/sound-generation \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "Spacious braam suitable for high-impact movie trailer moments"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_sound_effects.convert(
text="Spacious braam suitable for high-impact movie trailer moments",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSoundEffects.convert({
text: "Spacious braam suitable for high-impact movie trailer moments"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/sound-generation"
payload := strings.NewReader("{\n  \"text\": \"Spacious braam suitable for high-impact movie trailer moments\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/sound-generation")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"Spacious braam suitable for high-impact movie trailer moments\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/sound-generation")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"Spacious braam suitable for high-impact movie trailer moments\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/sound-generation', [
'body' => '{
"text": "Spacious braam suitable for high-impact movie trailer moments"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/sound-generation");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"Spacious braam suitable for high-impact movie trailer moments\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "Spacious braam suitable for high-impact movie trailer moments"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/sound-generation")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"text": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_sound_effects.convert(
text="Spacious braam suitable for high-impact movie trailer moments",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToSoundEffects.convert({
text: "Spacious braam suitable for high-impact movie trailer moments"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32"
payload := strings.NewReader("{\n  \"text\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"text\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"text\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32', [
'body' => '{
"text": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"text\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["text": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/sound-generation?output_format=mp3_22050_32")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Audio isolation
```http
POST https://api.elevenlabs.io/v1/audio-isolation
Content-Type: multipart/form-data
```
Removes background noise from audio.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-isolation \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/audio-isolation"
files = { "audio": "open('<filename1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/audio-isolation';
const form = new FormData();
form.append('audio', '<filename1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-isolation"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-isolation")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-isolation")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-isolation', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-isolation");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-isolation")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-isolation \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/audio-isolation"
files = { "audio": "open('<filename1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/audio-isolation';
const form = new FormData();
form.append('audio', '<filename1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-isolation"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-isolation")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-isolation")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-isolation', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-isolation");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-isolation")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Audio isolation stream
```http
POST https://api.elevenlabs.io/v1/audio-isolation/stream
Content-Type: multipart/form-data
```
Removes background noise from audio.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-isolation/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/audio-isolation/stream"
files = { "audio": "open('<filename1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/audio-isolation/stream';
const form = new FormData();
form.append('audio', '<filename1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-isolation/stream"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-isolation/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-isolation/stream")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-isolation/stream', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-isolation/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-isolation/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-isolation/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio=@<filename1>
```
```python
import requests
url = "https://api.elevenlabs.io/v1/audio-isolation/stream"
files = { "audio": "open('<filename1>', 'rb')" }
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, files=files, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/audio-isolation/stream';
const form = new FormData();
form.append('audio', '<filename1>');
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
options.body = form;
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-isolation/stream"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-isolation/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-isolation/stream")
.header("xi-api-key", "<apiKey>")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-isolation/stream', [
'multipart' => [
[
'name' => 'audio',
'filename' => '<filename1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-isolation/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("undefined", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let parameters = [
[
"name": "audio",
"fileName": "<filename1>"
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-isolation/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Voice design
```http
POST https://api.elevenlabs.io/v1/text-to-voice/create-previews
Content-Type: application/json
```
Create a voice from a text prompt.
## Query Parameters
- OutputFormat (optional): The output format of the generated audio.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/text-to-voice/create-previews \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"voice_description": "A sassy squeaky mouse"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_voice.create_previews(
voice_description="A sassy squeaky mouse",
text="Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted.",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToVoice.createPreviews({
voice_description: "A sassy squeaky mouse",
text: "Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted."
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-voice/create-previews"
payload := strings.NewReader("{\n  \"voice_description\": \"A sassy squeaky mouse\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-voice/create-previews")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"voice_description\": \"A sassy squeaky mouse\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-voice/create-previews")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"voice_description\": \"A sassy squeaky mouse\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-voice/create-previews', [
'body' => '{
"voice_description": "A sassy squeaky mouse"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-voice/create-previews");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"voice_description\": \"A sassy squeaky mouse\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["voice_description": "A sassy squeaky mouse"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-voice/create-previews")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST "https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32" \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"voice_description": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_voice.create_previews(
voice_description="A sassy squeaky mouse",
text="Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted.",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToVoice.createPreviews({
voice_description: "A sassy squeaky mouse",
text: "Every act of kindness, no matter how small, carries value and can make a difference, as no gesture of goodwill is ever wasted."
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32"
payload := strings.NewReader("{\n  \"voice_description\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"voice_description\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"voice_description\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32', [
'body' => '{
"voice_description": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"voice_description\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["voice_description": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-voice/create-previews?output_format=mp3_22050_32")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Save a voice preview
```http
POST https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview
Content-Type: application/json
```
Add a generated voice to the voice library.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"voice_name": "Sassy squeaky mouse",
"voice_description": "A sassy squeaky mouse",
"generated_voice_id": "37HceQefKmEi3bGovXjL"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_voice.create_voice_from_preview(
voice_name="Sassy squeaky mouse",
voice_description="A sassy squeaky mouse",
generated_voice_id="37HceQefKmEi3bGovXjL",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToVoice.createVoiceFromPreview({
voice_name: "Sassy squeaky mouse",
voice_description: "A sassy squeaky mouse",
generated_voice_id: "37HceQefKmEi3bGovXjL"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview"
payload := strings.NewReader("{\n  \"voice_name\": \"Sassy squeaky mouse\",\n  \"voice_description\": \"A sassy squeaky mouse\",\n  \"generated_voice_id\": \"37HceQefKmEi3bGovXjL\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"voice_name\": \"Sassy squeaky mouse\",\n  \"voice_description\": \"A sassy squeaky mouse\",\n  \"generated_voice_id\": \"37HceQefKmEi3bGovXjL\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"voice_name\": \"Sassy squeaky mouse\",\n  \"voice_description\": \"A sassy squeaky mouse\",\n  \"generated_voice_id\": \"37HceQefKmEi3bGovXjL\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview', [
'body' => '{
"voice_name": "Sassy squeaky mouse",
"voice_description": "A sassy squeaky mouse",
"generated_voice_id": "37HceQefKmEi3bGovXjL"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"voice_name\": \"Sassy squeaky mouse\",\n  \"voice_description\": \"A sassy squeaky mouse\",\n  \"generated_voice_id\": \"37HceQefKmEi3bGovXjL\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"voice_name": "Sassy squeaky mouse",
"voice_description": "A sassy squeaky mouse",
"generated_voice_id": "37HceQefKmEi3bGovXjL"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"voice_name": "string",
"voice_description": "string",
"generated_voice_id": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.text_to_voice.create_voice_from_preview(
voice_name="Sassy squeaky mouse",
voice_description="A sassy squeaky mouse",
generated_voice_id="37HceQefKmEi3bGovXjL",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.textToVoice.createVoiceFromPreview({
voice_name: "Sassy squeaky mouse",
voice_description: "A sassy squeaky mouse",
generated_voice_id: "37HceQefKmEi3bGovXjL"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview"
payload := strings.NewReader("{\n  \"voice_name\": \"string\",\n  \"voice_description\": \"string\",\n  \"generated_voice_id\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"voice_name\": \"string\",\n  \"voice_description\": \"string\",\n  \"generated_voice_id\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"voice_name\": \"string\",\n  \"voice_description\": \"string\",\n  \"generated_voice_id\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview', [
'body' => '{
"voice_name": "string",
"voice_description": "string",
"generated_voice_id": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"voice_name\": \"string\",\n  \"voice_description\": \"string\",\n  \"generated_voice_id\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"voice_name": "string",
"voice_description": "string",
"generated_voice_id": "string"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/text-to-voice/create-voice-from-preview")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get dubbing resource
```http
GET https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}
```
Given a dubbing ID generated from the '/v1/dubbing' endpoint with studio enabled, returns the dubbing resource.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_dubbing_resource(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getDubbingResource("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_dubbing_resource(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getDubbingResource("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Add language to dubbing resource
```http
POST https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/language
Content-Type: application/json
```
Adds the given ElevenLab Turbo V2/V2.5 language code to the resource. Does not automatically generate transcripts/translations/audio.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 201: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.add_language_to_resource(
dubbing_id="dubbing_id",
language="language",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.addLanguageToResource("dubbing_id", {
language: "language"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/language")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/language \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.add_language_to_resource(
dubbing_id="dubbing_id",
language="language",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.addLanguageToResource("dubbing_id", {
language: "language"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/language")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Add speaker segment to dubbing resource
```http
POST https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/speaker/{speaker_id}/segment
Content-Type: application/json
```
Creates a new segment in dubbing resource with a start and end time for the speaker in every available language. Does not automatically generate transcripts/translations/audio.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
- SpeakerId (required): ID of the speaker.
## Response Body
- 201: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"start_time": 1.1,
"end_time": 1.1
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.create_segment_for_speaker(
dubbing_id="dubbing_id",
speaker_id="speaker_id",
start_time=1.1,
end_time=1.1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.createSegmentForSpeaker("dubbing_id", "speaker_id", {
start_time: 1.1,
end_time: 1.1
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment"
payload := strings.NewReader("{\n  \"start_time\": 1.1,\n  \"end_time\": 1.1\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"start_time\": 1.1,\n  \"end_time\": 1.1\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"start_time\": 1.1,\n  \"end_time\": 1.1\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment', [
'body' => '{
"start_time": 1.1,
"end_time": 1.1
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"start_time\": 1.1,\n  \"end_time\": 1.1\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"start_time": 1.1,
"end_time": 1.1
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/speaker/speaker_id/segment")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/speaker/:speaker_id/segment \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"start_time": 1,
"end_time": 1
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.create_segment_for_speaker(
dubbing_id="dubbing_id",
speaker_id="speaker_id",
start_time=1.1,
end_time=1.1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.createSegmentForSpeaker("dubbing_id", "speaker_id", {
start_time: 1.1,
end_time: 1.1
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment"
payload := strings.NewReader("{\n  \"start_time\": 1,\n  \"end_time\": 1\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"start_time\": 1,\n  \"end_time\": 1\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"start_time\": 1,\n  \"end_time\": 1\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment', [
'body' => '{
"start_time": 1,
"end_time": 1
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"start_time\": 1,\n  \"end_time\": 1\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"start_time": 1,
"end_time": 1
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/speaker/%3Aspeaker_id/segment")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Modify a segment
```http
PATCH https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/segment/{segment_id}/{language}
Content-Type: application/json
```
Modifies a single segment with new text and/or start/end times. Will update the values for only a specific language of a segment. Does not automatically regenerate the dub.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
- SegmentId (required): ID of the segment
- Language (required): ID of the language.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X PATCH https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.update_segment_language(
dubbing_id="dubbing_id",
segment_id="segment_id",
language="language",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.updateSegmentLanguage("dubbing_id", "segment_id", "language");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id/language")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X PATCH https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/segment/:segment_id/:language \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.update_segment_language(
dubbing_id="dubbing_id",
segment_id="segment_id",
language="language",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.updateSegmentLanguage("dubbing_id", "segment_id", "language");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("PATCH", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Patch.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.patch("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('PATCH', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage");
var request = new RestRequest(Method.PATCH);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id/%3Alanguage")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "PATCH"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete a segment
```http
DELETE https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/segment/{segment_id}
```
Deletes a single segment from the dubbing.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
- SegmentId (required): ID of the segment
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.delete_segment(
dubbing_id="dubbing_id",
segment_id="segment_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.deleteSegment("dubbing_id", "segment_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/segment/segment_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/segment/:segment_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.delete_segment(
dubbing_id="dubbing_id",
segment_id="segment_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.deleteSegment("dubbing_id", "segment_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/segment/%3Asegment_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Transcribe segments
```http
POST https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/transcribe
Content-Type: application/json
```
Regenerate the transcriptions for the specified segments. Does not automatically regenerate translations or dubs.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"segments"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.transcribe_segments(
dubbing_id="dubbing_id",
segments=["segments"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.transcribeSegments("dubbing_id", {
segments: ["segments"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe"
payload := strings.NewReader("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"segments\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe', [
'body' => '{
"segments": [
"segments"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"segments\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["segments"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/transcribe")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/transcribe \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.transcribe_segments(
dubbing_id="dubbing_id",
segments=["segments"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.transcribeSegments("dubbing_id", {
segments: ["segments"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe"
payload := strings.NewReader("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe', [
'body' => '{
"segments": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/transcribe")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Translate segments
```http
POST https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/translate
Content-Type: application/json
```
Regenerate the translations for either the entire resource or the specified segments/languages. Will automatically transcribe missing transcriptions. Will not automatically regenerate the dubs.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"segments"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.translate_segments(
dubbing_id="dubbing_id",
segments=["segments"],
languages=["languages"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.translateSegments("dubbing_id", {
segments: ["segments"],
languages: ["languages"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate"
payload := strings.NewReader("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"segments\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate', [
'body' => '{
"segments": [
"segments"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"segments\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["segments"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/translate")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/translate \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.translate_segments(
dubbing_id="dubbing_id",
segments=["segments"],
languages=["languages"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.translateSegments("dubbing_id", {
segments: ["segments"],
languages: ["languages"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate"
payload := strings.NewReader("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate', [
'body' => '{
"segments": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/translate")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Dub segments
```http
POST https://api.elevenlabs.io/v1/dubbing/resource/{dubbing_id}/dub
Content-Type: application/json
```
Regenerate the dubs for either the entire resource or the specified segments/languages. Will automatically transcribe and translate any missing transcriptions and translations.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"segments"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.dub_segments(
dubbing_id="dubbing_id",
segments=["segments"],
languages=["languages"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.dubSegments("dubbing_id", {
segments: ["segments"],
languages: ["languages"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub"
payload := strings.NewReader("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"segments\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"segments\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub', [
'body' => '{
"segments": [
"segments"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"segments\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["segments"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/dubbing_id/dub")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing/resource/:dubbing_id/dub \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"segments": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.dub_segments(
dubbing_id="dubbing_id",
segments=["segments"],
languages=["languages"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.dubSegments("dubbing_id", {
segments: ["segments"],
languages: ["languages"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub"
payload := strings.NewReader("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"segments\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"segments\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub', [
'body' => '{
"segments": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"segments\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["segments": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/resource/%3Adubbing_id/dub")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Dub a video or audio file
```http
POST https://api.elevenlabs.io/v1/dubbing
Content-Type: multipart/form-data
```
Dubs a provided audio or video file into given language.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.dub_a_video_or_an_audio_file(
target_lang="target_lang",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.dubAVideoOrAnAudioFile({
target_lang: "target_lang"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "file",
"value":
],
[
"name": "name",
"value":
],
[
"name": "source_url",
"value":
],
[
"name": "source_lang",
"value":
],
[
"name": "target_lang",
"value":
],
[
"name": "num_speakers",
"value":
],
[
"name": "watermark",
"value":
],
[
"name": "start_time",
"value":
],
[
"name": "end_time",
"value":
],
[
"name": "highest_resolution",
"value":
],
[
"name": "drop_background_audio",
"value":
],
[
"name": "use_profanity_filter",
"value":
],
[
"name": "dubbing_studio",
"value":
],
[
"name": "use_replacement_voices_from_library",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/dubbing \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.dub_a_video_or_an_audio_file(
target_lang="target_lang",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.dubAVideoOrAnAudioFile({
target_lang: "target_lang"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/dubbing")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/dubbing', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_lang\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"num_speakers\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"watermark\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"start_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"end_time\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"highest_resolution\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"drop_background_audio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_profanity_filter\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"dubbing_studio\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"use_replacement_voices_from_library\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "file",
"value":
],
[
"name": "name",
"value":
],
[
"name": "source_url",
"value":
],
[
"name": "source_lang",
"value":
],
[
"name": "target_lang",
"value":
],
[
"name": "num_speakers",
"value":
],
[
"name": "watermark",
"value":
],
[
"name": "start_time",
"value":
],
[
"name": "end_time",
"value":
],
[
"name": "highest_resolution",
"value":
],
[
"name": "drop_background_audio",
"value":
],
[
"name": "use_profanity_filter",
"value":
],
[
"name": "dubbing_studio",
"value":
],
[
"name": "use_replacement_voices_from_library",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get dubbing
```http
GET https://api.elevenlabs.io/v1/dubbing/{dubbing_id}
```
Returns metadata about a dubbing project, including whether it's still in progress or not
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/dubbing/dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_dubbing_project_metadata(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getDubbingProjectMetadata("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/dubbing_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/dubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/dubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/dubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/dubbing_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/dubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/:dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_dubbing_project_metadata(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getDubbingProjectMetadata("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete dubbing
```http
DELETE https://api.elevenlabs.io/v1/dubbing/{dubbing_id}
```
Deletes a dubbing project.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/dubbing/dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.delete_dubbing_project(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.deleteDubbingProject("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/dubbing_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/dubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/dubbing/dubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/dubbing/dubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/dubbing_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/dubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/dubbing/:dubbing_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.delete_dubbing_project(
dubbing_id="dubbing_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.deleteDubbingProject("dubbing_id");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get dubbed audio
```http
GET https://api.elevenlabs.io/v1/dubbing/{dubbing_id}/audio/{language_code}
```
Returns dubbed file as a streamed file. Videos will be returned in MP4 format and audio only dubs will be returned in MP3.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
- LanguageCode (required): ID of the language.
## Response Body
- 200: The dubbed audio or video file
- 403: Permission denied
- 404: Dubbing not found
- 422: Validation Error
- 425: Dubbing not ready
## Examples
```shell
curl https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/dubbing_id/audio/language_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/:dubbing_id/audio/:language_code \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/:dubbing_id/audio/:language_code \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/:dubbing_id/audio/:language_code \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/dubbing/:dubbing_id/audio/:language_code \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/audio/%3Alanguage_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get dubbed transcript
```http
GET https://api.elevenlabs.io/v1/dubbing/{dubbing_id}/transcript/{language_code}
```
Returns transcript for the dub as an SRT or WEBVTT file.
## Path Parameters
- DubbingId (required): ID of the dubbing project.
- LanguageCode (required): ID of the language.
## Query Parameters
- FormatType (optional): Format to use for the subtitle file, either 'srt' or 'webvtt'
## Response Body
- 200: Successful Response
- 403: Anonymous users cannot use this function
- 404: Dubbing or transcript not found
- 422: Validation Error
- 425: Dubbing not ready
## Examples
```shell
curl https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_transcript_for_dub(
dubbing_id="dubbing_id",
language_code="language_code",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getTranscriptForDub("dubbing_id", "language_code");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/dubbing_id/transcript/language_code")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/dubbing/:dubbing_id/transcript/:language_code \
-H "xi-api-key: <apiKey>" \
-d format_type=srt
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_transcript_for_dub(
dubbing_id="dubbing_id",
language_code="language_code",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getTranscriptForDub("dubbing_id", "language_code");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/dubbing/:dubbing_id/transcript/:language_code \
-H "xi-api-key: <apiKey>" \
-d format_type=srt
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_transcript_for_dub(
dubbing_id="dubbing_id",
language_code="language_code",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getTranscriptForDub("dubbing_id", "language_code");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/dubbing/:dubbing_id/transcript/:language_code \
-H "xi-api-key: <apiKey>" \
-d format_type=srt
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_transcript_for_dub(
dubbing_id="dubbing_id",
language_code="language_code",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getTranscriptForDub("dubbing_id", "language_code");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/dubbing/:dubbing_id/transcript/:language_code \
-H "xi-api-key: <apiKey>" \
-d format_type=srt
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.dubbing.get_transcript_for_dub(
dubbing_id="dubbing_id",
language_code="language_code",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.dubbing.getTranscriptForDub("dubbing_id", "language_code");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/dubbing/%3Adubbing_id/transcript/%3Alanguage_code?format_type=srt")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create audio native project
```http
POST https://api.elevenlabs.io/v1/audio-native
Content-Type: multipart/form-data
```
Creates Audio Native enabled project, optionally starts conversion and returns project ID and embeddable HTML snippet.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-native \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="name" \
-F file=@<file1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.create(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.create({
name: "name"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-native")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-native', [
'multipart' => [
[
'name' => 'name',
'contents' => '"name"'
],
[
'name' => 'file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"name\""
],
[
"name": "image",
"value":
],
[
"name": "author",
"value":
],
[
"name": "title",
"value":
],
[
"name": "small",
"value":
],
[
"name": "text_color",
"value":
],
[
"name": "background_color",
"value":
],
[
"name": "sessionization",
"value":
],
[
"name": "voice_id",
"value":
],
[
"name": "model_id",
"value":
],
[
"name": "file",
"fileName": "<file1>"
],
[
"name": "auto_convert",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-native \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="string"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.create(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.create({
name: "name"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-native")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-native', [
'multipart' => [
[
'name' => 'name',
'contents' => '"string"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"image\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"small\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"text_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"background_color\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"sessionization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"voice_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"model_id\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"string\""
],
[
"name": "image",
"value":
],
[
"name": "author",
"value":
],
[
"name": "title",
"value":
],
[
"name": "small",
"value":
],
[
"name": "text_color",
"value":
],
[
"name": "background_color",
"value":
],
[
"name": "sessionization",
"value":
],
[
"name": "voice_id",
"value":
],
[
"name": "model_id",
"value":
],
[
"name": "auto_convert",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Audio Native Project Settings
```http
GET https://api.elevenlabs.io/v1/audio-native/{project_id}/settings
```
Get player settings for the specific project.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.get_settings(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.getSettings("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/audio-native/:project_id/settings \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.get_settings(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.getSettings("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update audio native project
```http
POST https://api.elevenlabs.io/v1/audio-native/{project_id}/content
Content-Type: multipart/form-data
```
Updates content for the specific AudioNative Project.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F file=@<file1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.update_content(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.updateContent("21m00Tcm4TlvDq8ikWAM", {});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content', [
'multipart' => [
[
'name' => 'file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "file",
"fileName": "<file1>"
],
[
"name": "auto_convert",
"value":
],
[
"name": "auto_publish",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native/21m00Tcm4TlvDq8ikWAM/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/audio-native/:project_id/content \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.audio_native.update_content(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.audioNative.updateContent("21m00Tcm4TlvDq8ikWAM", {});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_publish\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "auto_convert",
"value":
],
[
"name": "auto_publish",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/audio-native/%3Aproject_id/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List voices
```http
GET https://api.elevenlabs.io/v1/voices
```
Returns a list of all available voices for a user.
## Query Parameters
- ShowLegacy (optional): If set to true, legacy premade voices will be included in responses from /v1/voices
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/voices \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/voices \
-H "xi-api-key: <apiKey>" \
-d show_legacy=true
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices?show_legacy=true"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices?show_legacy=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices?show_legacy=true")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices?show_legacy=true', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices?show_legacy=true");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices?show_legacy=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get default voice settings
```http
GET https://api.elevenlabs.io/v1/voices/settings/default
```
Gets the default settings for voices. "similarity_boost" corresponds to"Clarity + Similarity Enhancement" in the web app and "stability" corresponds to "Stability" slider in the web app.
## Response Body
- 200: Successful Response
## Examples
```shell
curl https://api.elevenlabs.io/v1/voices/settings/default \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_default_settings()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getDefaultSettings();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/settings/default"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/settings/default")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/settings/default")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/settings/default', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/settings/default");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/settings/default")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get voice settings
```http
GET https://api.elevenlabs.io/v1/voices/{voice_id}/settings
```
Returns the settings for a specific voice. "similarity_boost" corresponds to"Clarity + Similarity Enhancement" in the web app and "stability" corresponds to "Stability" slider in the web app.
## Path Parameters
- VoiceId (required): Voice ID to be used, you can use https://api.elevenlabs.io/v1/voices to list all the available voices.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_settings(
voice_id="JBFqnCBsd6RMkjVDRZzb",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getSettings("JBFqnCBsd6RMkjVDRZzb");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/voices/:voice_id/settings \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_settings(
voice_id="JBFqnCBsd6RMkjVDRZzb",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getSettings("JBFqnCBsd6RMkjVDRZzb");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get voice
```http
GET https://api.elevenlabs.io/v1/voices/{voice_id}
```
Returns metadata about a specific voice.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Query Parameters
- WithSettings (optional): This parameter is now deprecated. It is ignored and will be removed in a future version.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get(
voice_id="JBFqnCBsd6RMkjVDRZzb",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.get("JBFqnCBsd6RMkjVDRZzb");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/voices/:voice_id \
-H "xi-api-key: <apiKey>" \
-d with_settings=true
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get(
voice_id="JBFqnCBsd6RMkjVDRZzb",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.get("JBFqnCBsd6RMkjVDRZzb");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id?with_settings=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete voice
```http
DELETE https://api.elevenlabs.io/v1/voices/{voice_id}
```
Deletes a voice by its ID.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.delete(
voice_id="VOICE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.delete("VOICE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/voices/:voice_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.delete(
voice_id="VOICE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.delete("VOICE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/voices/%3Avoice_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Edit voice settings
```http
POST https://api.elevenlabs.io/v1/voices/{voice_id}/settings/edit
Content-Type: application/json
```
Edit your settings for a specific voice. "similarity_boost" corresponds to "Clarity + Similarity Enhancement" in the web app and "stability" corresponds to "Stability" slider in the web app.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"stability": 1,
"similarity_boost": 1,
"style": 0,
"use_speaker_boost": true,
"speed": 1
}'
```
```python
from elevenlabs import ElevenLabs, VoiceSettings
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.edit_settings(
voice_id="VOICE_ID",
request=VoiceSettings(
stability=0.1,
similarity_boost=0.3,
style=0.2,
),
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.editSettings("VOICE_ID", {
stability: 0.1,
similarity_boost: 0.3,
style: 0.2
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit"
payload := strings.NewReader("{\n  \"stability\": 1,\n  \"similarity_boost\": 1,\n  \"style\": 0,\n  \"use_speaker_boost\": true,\n  \"speed\": 1\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"stability\": 1,\n  \"similarity_boost\": 1,\n  \"style\": 0,\n  \"use_speaker_boost\": true,\n  \"speed\": 1\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"stability\": 1,\n  \"similarity_boost\": 1,\n  \"style\": 0,\n  \"use_speaker_boost\": true,\n  \"speed\": 1\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit', [
'body' => '{
"stability": 1,
"similarity_boost": 1,
"style": 0,
"use_speaker_boost": true,
"speed": 1
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"stability\": 1,\n  \"similarity_boost\": 1,\n  \"style\": 0,\n  \"use_speaker_boost\": true,\n  \"speed\": 1\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"stability": 1,
"similarity_boost": 1,
"style": 0,
"use_speaker_boost": true,
"speed": 1
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/settings/edit")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/:voice_id/settings/edit \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs, VoiceSettings
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.edit_settings(
voice_id="VOICE_ID",
request=VoiceSettings(
stability=0.1,
similarity_boost=0.3,
style=0.2,
),
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.editSettings("VOICE_ID", {
stability: 0.1,
similarity_boost: 0.3,
style: 0.2
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id/settings/edit")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create voice clone
```http
POST https://api.elevenlabs.io/v1/voices/add
Content-Type: multipart/form-data
```
Create a voice clone and add it to your Voices
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/add \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="name"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.add(
name="Alex",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.add({
files: [fs.createReadStream("/path/to/your/file")],
name: "Alex"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/add"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/add")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/add")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/add', [
'multipart' => [
[
'name' => 'name',
'contents' => '"name"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/add");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"name\""
],
[
"name": "remove_background_noise",
"value":
],
[
"name": "description",
"value":
],
[
"name": "labels",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/add")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/add \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="string" \
-F "files[]"=@<filename1> \
-F "files[]"=@<filename2>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.add(
name="Alex",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
import * as fs from "fs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.add({
files: [fs.createReadStream("/path/to/your/file")],
name: "Alex"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/add"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename2>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/add")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename2>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/add")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename2>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/add', [
'multipart' => [
[
'name' => 'name',
'contents' => '"string"'
],
[
'name' => 'files',
'filename' => '<filename1>',
'contents' => null
],
[
'name' => 'files',
'filename' => '<filename2>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/add");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"files\"; filename=\"<filename2>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"string\""
],
[
"name": "files",
"fileName": "<filename1>"
],
[
"name": "files",
"fileName": "<filename2>"
],
[
"name": "remove_background_noise",
"value":
],
[
"name": "description",
"value":
],
[
"name": "labels",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/add")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Edit voice
```http
POST https://api.elevenlabs.io/v1/voices/{voice_id}/edit
Content-Type: multipart/form-data
```
Edit a voice created by you.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="name"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.edit(
voice_id="VOICE_ID",
name="George",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.edit("VOICE_ID", {
name: "George"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit', [
'multipart' => [
[
'name' => 'name',
'contents' => '"name"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"name\""
],
[
"name": "remove_background_noise",
"value":
],
[
"name": "description",
"value":
],
[
"name": "labels",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/edit")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/:voice_id/edit \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="string"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.edit(
voice_id="VOICE_ID",
name="George",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.edit("VOICE_ID", {
name: "George"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit', [
'multipart' => [
[
'name' => 'name',
'contents' => '"string"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"remove_background_noise\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"labels\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"string\""
],
[
"name": "remove_background_noise",
"value":
],
[
"name": "description",
"value":
],
[
"name": "labels",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id/edit")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List similar voices
```http
POST https://api.elevenlabs.io/v1/similar-voices
Content-Type: multipart/form-data
```
Returns a list of shared voices similar to the provided audio sample. If neither similarity_threshold nor top_k is provided, we will apply default values.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/similar-voices \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F audio_file=@<file1>
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_similar_library_voices()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getSimilarLibraryVoices({});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/similar-voices"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/similar-voices")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/similar-voices")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/similar-voices', [
'multipart' => [
[
'name' => 'audio_file',
'filename' => '<file1>',
'contents' => null
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/similar-voices");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"audio_file\"; filename=\"<file1>\"\r\nContent-Type: application/octet-stream\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "audio_file",
"fileName": "<file1>"
],
[
"name": "similarity_threshold",
"value":
],
[
"name": "top_k",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/similar-voices")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/similar-voices \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_similar_library_voices()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getSimilarLibraryVoices({});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/similar-voices"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/similar-voices")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/similar-voices")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/similar-voices', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/similar-voices");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"similarity_threshold\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"top_k\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "similarity_threshold",
"value":
],
[
"name": "top_k",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/similar-voices")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get a profile page
```http
GET https://api.elevenlabs.io/profile/{handle}
```
Gets a profile page based on a handle
## Path Parameters
- Handle (required): Handle for a VA's profile page
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/profile/talexgeorge \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_a_profile_page(
handle="talexgeorge",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getAProfilePage("talexgeorge");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/profile/talexgeorge"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/profile/talexgeorge")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/profile/talexgeorge")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/profile/talexgeorge', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/profile/talexgeorge");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/profile/talexgeorge")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/profile/:handle \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_a_profile_page(
handle="talexgeorge",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getAProfilePage("talexgeorge");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/profile/%3Ahandle"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/profile/%3Ahandle")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/profile/%3Ahandle")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/profile/%3Ahandle', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/profile/%3Ahandle");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/profile/%3Ahandle")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get generated items
```http
GET https://api.elevenlabs.io/v1/history
```
Returns a list of your generated audio.
## Query Parameters
- PageSize (optional): How many history items to return at maximum. Can not exceed 1000, defaults to 100.
- StartAfterHistoryItemId (optional): After which ID to start fetching, use this parameter to paginate across a large collection of history items. In case this parameter is not provided history items will be fetched starting from the most recently created one ordered descending by their creation date.
- VoiceId (optional): ID of the voice to be filtered for. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
- Search (optional): Search term used for filtering history items. If provided, source becomes required.
- Source (optional): Source of the generated history item
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/history \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/history \
-H "xi-api-key: <apiKey>" \
-d page_size=0 \
-d start_after_history_item_id=string
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history?page_size=0&start_after_history_item_id=string")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get history item
```http
GET https://api.elevenlabs.io/v1/history/{history_item_id}
```
Retrieves a history item.
## Path Parameters
- HistoryItemId (required): ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.get("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/history/:history_item_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.get("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history/%3Ahistory_item_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete history item
```http
DELETE https://api.elevenlabs.io/v1/history/{history_item_id}
```
Delete a history item by its ID
## Path Parameters
- HistoryItemId (required): ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.delete(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.delete("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/VW7YKqPnjY4h39yTbx2L")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/history/:history_item_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.delete(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.delete("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/history/%3Ahistory_item_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get audio from history item
```http
GET https://api.elevenlabs.io/v1/history/{history_item_id}/audio
```
Returns the audio of an history item.
## Path Parameters
- HistoryItemId (required): ID of the history item to be used. You can use the [Get generated items](/docs/api-reference/history/get-all) endpoint to retrieve a list of history items.
## Response Body
- 200: The audio file of the history item.
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/history/history_item_id/audio \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get_audio(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.getAudio("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/history_item_id/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/history_item_id/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history/history_item_id/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history/history_item_id/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/history_item_id/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/history_item_id/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/history/:history_item_id/audio \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.get_audio(
history_item_id="HISTORY_ITEM_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.getAudio("HISTORY_ITEM_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/%3Ahistory_item_id/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Download history items
```http
POST https://api.elevenlabs.io/v1/history/download
Content-Type: application/json
```
Download one or more history items. If one history item ID is provided, we will return a single audio file. If more than one history item IDs are provided, we will provide the history items packed into a .zip file.
## Response Body
- 200: The requested audio file, or a zip file containing multiple audio files when multiple history items are requested.
- 400: Invalid request
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/history/download \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"history_item_ids": [
"history_item_ids",
"history_item_ids"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.download(
history_item_ids=["HISTORY_ITEM_ID"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.download({
history_item_ids: ["HISTORY_ITEM_ID"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/download"
payload := strings.NewReader("{\n  \"history_item_ids\": [\n    \"history_item_ids\",\n    \"history_item_ids\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/download")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"history_item_ids\": [\n    \"history_item_ids\",\n    \"history_item_ids\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/history/download")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"history_item_ids\": [\n    \"history_item_ids\",\n    \"history_item_ids\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/history/download', [
'body' => '{
"history_item_ids": [
"history_item_ids",
"history_item_ids"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/download");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"history_item_ids\": [\n    \"history_item_ids\",\n    \"history_item_ids\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["history_item_ids": ["history_item_ids", "history_item_ids"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/download")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/history/download \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"history_item_ids": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.download(
history_item_ids=["HISTORY_ITEM_ID"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.download({
history_item_ids: ["HISTORY_ITEM_ID"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/download"
payload := strings.NewReader("{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/download")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/history/download")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/history/download', [
'body' => '{
"history_item_ids": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/download");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["history_item_ids": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/download")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/history/download \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"history_item_ids": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.history.download(
history_item_ids=["HISTORY_ITEM_ID"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.history.download({
history_item_ids: ["HISTORY_ITEM_ID"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/history/download"
payload := strings.NewReader("{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/history/download")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/history/download")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/history/download', [
'body' => '{
"history_item_ids": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/history/download");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"history_item_ids\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["history_item_ids": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/history/download")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List models
```http
GET https://api.elevenlabs.io/v1/models
```
Gets a list of available models.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/models \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.models.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.models.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/models"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/models")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/models")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/models', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/models");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/models")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/models \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.models.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.models.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/models"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/models")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/models")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/models', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/models");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/models")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Studio API
<Note>
The Studio API is only available upon request. To get access, [contact
sales](https://elevenlabs.io/contact-sales).
</Note>
# List Studio Projects
```http
GET https://api.elevenlabs.io/v1/studio/projects
```
Returns a list of your Studio projects with metadata.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_all()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getAll();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update Studio Project
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}
Content-Type: application/json
```
Updates the specified Studio project by setting the values of the parameters passed.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"name": "Project 1",
"default_title_voice_id": "21m00Tcm4TlvDq8ikWAM",
"default_paragraph_voice_id": "21m00Tcm4TlvDq8ikWAM"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_metadata(
project_id="21m00Tcm4TlvDq8ikWAM",
name="Project 1",
default_title_voice_id="21m00Tcm4TlvDq8ikWAM",
default_paragraph_voice_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updateMetadata("21m00Tcm4TlvDq8ikWAM", {
name: "Project 1",
default_title_voice_id: "21m00Tcm4TlvDq8ikWAM",
default_paragraph_voice_id: "21m00Tcm4TlvDq8ikWAM"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM"
payload := strings.NewReader("{\n  \"name\": \"Project 1\",\n  \"default_title_voice_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"default_paragraph_voice_id\": \"21m00Tcm4TlvDq8ikWAM\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"name\": \"Project 1\",\n  \"default_title_voice_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"default_paragraph_voice_id\": \"21m00Tcm4TlvDq8ikWAM\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"name\": \"Project 1\",\n  \"default_title_voice_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"default_paragraph_voice_id\": \"21m00Tcm4TlvDq8ikWAM\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM', [
'body' => '{
"name": "Project 1",
"default_title_voice_id": "21m00Tcm4TlvDq8ikWAM",
"default_paragraph_voice_id": "21m00Tcm4TlvDq8ikWAM"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"name\": \"Project 1\",\n  \"default_title_voice_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"default_paragraph_voice_id\": \"21m00Tcm4TlvDq8ikWAM\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"name": "Project 1",
"default_title_voice_id": "21m00Tcm4TlvDq8ikWAM",
"default_paragraph_voice_id": "21m00Tcm4TlvDq8ikWAM"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"name": "string",
"default_title_voice_id": "string",
"default_paragraph_voice_id": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_metadata(
project_id="21m00Tcm4TlvDq8ikWAM",
name="Project 1",
default_title_voice_id="21m00Tcm4TlvDq8ikWAM",
default_paragraph_voice_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updateMetadata("21m00Tcm4TlvDq8ikWAM", {
name: "Project 1",
default_title_voice_id: "21m00Tcm4TlvDq8ikWAM",
default_paragraph_voice_id: "21m00Tcm4TlvDq8ikWAM"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id"
payload := strings.NewReader("{\n  \"name\": \"string\",\n  \"default_title_voice_id\": \"string\",\n  \"default_paragraph_voice_id\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"name\": \"string\",\n  \"default_title_voice_id\": \"string\",\n  \"default_paragraph_voice_id\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"name\": \"string\",\n  \"default_title_voice_id\": \"string\",\n  \"default_paragraph_voice_id\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id', [
'body' => '{
"name": "string",
"default_title_voice_id": "string",
"default_paragraph_voice_id": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"name\": \"string\",\n  \"default_title_voice_id\": \"string\",\n  \"default_paragraph_voice_id\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"name": "string",
"default_title_voice_id": "string",
"default_paragraph_voice_id": "string"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Studio Project
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}
```
Returns information about a specific Studio project. This endpoint returns more detailed information about a project than `GET /v1/studio`.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.get("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.get("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create Studio Project
```http
POST https://api.elevenlabs.io/v1/studio/projects
Content-Type: multipart/form-data
```
Creates a new Studio project, it can be either initialized as blank, from a document or from a URL.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="name" \
-F default_title_voice_id="default_title_voice_id" \
-F default_paragraph_voice_id="default_paragraph_voice_id" \
-F default_model_id="default_model_id"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.add(
name="name",
default_title_voice_id="default_title_voice_id",
default_paragraph_voice_id="default_paragraph_voice_id",
default_model_id="default_model_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.add({
name: "name",
default_title_voice_id: "default_title_voice_id",
default_paragraph_voice_id: "default_paragraph_voice_id",
default_model_id: "default_model_id"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"default_title_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"default_paragraph_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"default_model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"default_title_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"default_paragraph_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"default_model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"default_title_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"default_paragraph_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"default_model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects', [
'multipart' => [
[
'name' => 'name',
'contents' => '"name"'
],
[
'name' => 'default_title_voice_id',
'contents' => '"default_title_voice_id"'
],
[
'name' => 'default_paragraph_voice_id',
'contents' => '"default_paragraph_voice_id"'
],
[
'name' => 'default_model_id',
'contents' => '"default_model_id"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"default_title_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"default_paragraph_voice_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"default_model_id\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"name\""
],
[
"name": "default_title_voice_id",
"value": "\"default_title_voice_id\""
],
[
"name": "default_paragraph_voice_id",
"value": "\"default_paragraph_voice_id\""
],
[
"name": "default_model_id",
"value": "\"default_model_id\""
],
[
"name": "from_url",
"value":
],
[
"name": "from_document",
"value":
],
[
"name": "quality_preset",
"value":
],
[
"name": "title",
"value":
],
[
"name": "author",
"value":
],
[
"name": "description",
"value":
],
[
"name": "genres",
"value":
],
[
"name": "target_audience",
"value":
],
[
"name": "language",
"value":
],
[
"name": "content_type",
"value":
],
[
"name": "original_publication_date",
"value":
],
[
"name": "mature_content",
"value":
],
[
"name": "isbn_number",
"value":
],
[
"name": "acx_volume_normalization",
"value":
],
[
"name": "volume_normalization",
"value":
],
[
"name": "pronunciation_dictionary_locators",
"value":
],
[
"name": "callback_url",
"value":
],
[
"name": "fiction",
"value":
],
[
"name": "apply_text_normalization",
"value":
],
[
"name": "auto_convert",
"value":
],
[
"name": "auto_assign_voices",
"value":
],
[
"name": "source_type",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="string" \
-F default_title_voice_id="string" \
-F default_paragraph_voice_id="string" \
-F default_model_id="string"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.add(
name="name",
default_title_voice_id="default_title_voice_id",
default_paragraph_voice_id="default_paragraph_voice_id",
default_model_id="default_model_id",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.add({
name: "name",
default_title_voice_id: "default_title_voice_id",
default_paragraph_voice_id: "default_paragraph_voice_id",
default_model_id: "default_model_id"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects', [
'multipart' => [
[
'name' => 'name',
'contents' => '"string"'
],
[
'name' => 'default_title_voice_id',
'contents' => '"string"'
],
[
'name' => 'default_paragraph_voice_id',
'contents' => '"string"'
],
[
'name' => 'default_model_id',
'contents' => '"string"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_title_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_paragraph_voice_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"default_model_id\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"quality_preset\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"title\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"author\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"genres\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"target_audience\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"language\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"content_type\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"original_publication_date\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"mature_content\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"isbn_number\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"acx_volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"volume_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"pronunciation_dictionary_locators\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"callback_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"fiction\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"apply_text_normalization\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_assign_voices\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"source_type\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"string\""
],
[
"name": "default_title_voice_id",
"value": "\"string\""
],
[
"name": "default_paragraph_voice_id",
"value": "\"string\""
],
[
"name": "default_model_id",
"value": "\"string\""
],
[
"name": "from_url",
"value":
],
[
"name": "from_document",
"value":
],
[
"name": "quality_preset",
"value":
],
[
"name": "title",
"value":
],
[
"name": "author",
"value":
],
[
"name": "description",
"value":
],
[
"name": "genres",
"value":
],
[
"name": "target_audience",
"value":
],
[
"name": "language",
"value":
],
[
"name": "content_type",
"value":
],
[
"name": "original_publication_date",
"value":
],
[
"name": "mature_content",
"value":
],
[
"name": "isbn_number",
"value":
],
[
"name": "acx_volume_normalization",
"value":
],
[
"name": "volume_normalization",
"value":
],
[
"name": "pronunciation_dictionary_locators",
"value":
],
[
"name": "callback_url",
"value":
],
[
"name": "fiction",
"value":
],
[
"name": "apply_text_normalization",
"value":
],
[
"name": "auto_convert",
"value":
],
[
"name": "auto_assign_voices",
"value":
],
[
"name": "source_type",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete Studio Project
```http
DELETE https://api.elevenlabs.io/v1/studio/projects/{project_id}
```
Deletes a Studio project.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.delete(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.delete("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/studio/projects/:project_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.delete(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.delete("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Convert Studio Project
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/convert
```
Starts conversion of a Studio project and all of its chapters.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.convert(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.convert("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/convert")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/convert \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.convert(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.convert("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/convert")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update Studio Project Content
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/content
Content-Type: multipart/form-data
```
Updates Studio project content.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_content(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updateContent("21m00Tcm4TlvDq8ikWAM", {});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "from_url",
"value":
],
[
"name": "from_document",
"value":
],
[
"name": "auto_convert",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/content \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_content(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updateContent("21m00Tcm4TlvDq8ikWAM", {});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content', [
'headers' => [
'Content-Type' => 'multipart/form-data; boundary=---011000010111000001101001',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "multipart/form-data; boundary=---011000010111000001101001");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_url\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"from_document\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"auto_convert\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "from_url",
"value":
],
[
"name": "from_document",
"value":
],
[
"name": "auto_convert",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/content")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List Studio Project Snapshots
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/snapshots
```
Retrieves a list of snapshots for a Studio project.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_snapshots(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getSnapshots("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/snapshots \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_snapshots(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getSnapshots("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Stream Studio Project Audio
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/snapshots/{project_snapshot_id}/stream
Content-Type: application/json
```
Stream the audio from a Studio project snapshot.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ProjectSnapshotId (required): The ID of the Studio project snapshot.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.stream_audio(
project_id="21m00Tcm4TlvDq8ikWAM",
project_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.streamAudio("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/snapshots/:project_snapshot_id/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.stream_audio(
project_id="21m00Tcm4TlvDq8ikWAM",
project_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.streamAudio("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Stream Archive With Studio Project Audio
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/snapshots/{project_snapshot_id}/archive
```
Returns a compressed archive of the Studio project's audio.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ProjectSnapshotId (required): The ID of the Studio project snapshot.
## Response Body
- 200: Streaming archive data
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive"
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive';
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/project_id/snapshots/project_snapshot_id/archive")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/snapshots/:project_snapshot_id/archive \
-H "xi-api-key: <apiKey>"
```
```python
import requests
url = "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive"
headers = {"xi-api-key": "<apiKey>"}
response = requests.post(url, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive';
const options = {method: 'POST', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id/archive")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List Chapters
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters
```
Returns a list of a Studio project's chapters.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_all(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getAll("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_all(
project_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getAll("21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Chapter
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}
```
Returns information about a specific chapter.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.get("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.get("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create Chapter
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters
Content-Type: application/json
```
Creates a new chapter either as blank or from a URL.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"name": "Chapter 1"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.create(
project_id="21m00Tcm4TlvDq8ikWAM",
name="Chapter 1",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.create("21m00Tcm4TlvDq8ikWAM", {
name: "Chapter 1"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters"
payload := strings.NewReader("{\n  \"name\": \"Chapter 1\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"name\": \"Chapter 1\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"name\": \"Chapter 1\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters', [
'body' => '{
"name": "Chapter 1"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"name\": \"Chapter 1\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["name": "Chapter 1"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"name": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.create(
project_id="21m00Tcm4TlvDq8ikWAM",
name="Chapter 1",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.create("21m00Tcm4TlvDq8ikWAM", {
name: "Chapter 1"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters"
payload := strings.NewReader("{\n  \"name\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"name\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"name\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters', [
'body' => '{
"name": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"name\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["name": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update Chapter
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}
Content-Type: application/json
```
Updates a chapter.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.edit(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.edit("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.edit(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.edit("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete Chapter
```http
DELETE https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}
```
Deletes a chapter.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.delete(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.delete("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.delete(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.delete("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Convert Chapter
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}/convert
```
Starts conversion of a specific chapter.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.convert(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.convert("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/convert")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id/convert \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.convert(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.convert("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert"
req, _ := http.NewRequest("POST", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/convert")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List Chapter Snapshots
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots
```
Gets information about all the snapshots of a chapter. Each snapshot can be downloaded as audio. Whenever a chapter is converted a snapshot will automatically be created.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_all_snapshots(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getAllSnapshots("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id/snapshots \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_all_snapshots(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getAllSnapshots("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Stream Chapter Audio
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots/{chapter_snapshot_id}/stream
Content-Type: application/json
```
Stream the audio from a chapter snapshot. Use `GET /v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots` to return the snapshots of a chapter.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
- ChapterId (required): The ID of the chapter to be used. You can use the [List project chapters](/docs/api-reference/studio/get-chapters) endpoint to list all the available chapters.
- ChapterSnapshotId (required): The ID of the chapter snapshot to be used. You can use the [List project chapter snapshots](/docs/api-reference/studio/get-snapshots) endpoint to list all the available snapshots.
## Response Body
- 200: Streaming audio data
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/project_id/chapters/chapter_id/snapshots/chapter_snapshot_id/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id/snapshots/:chapter_snapshot_id/stream \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream"
payload = {}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream"
payload := strings.NewReader("{}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream', [
'body' => '{}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id/stream")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create Pronunciation Dictionaries
```http
POST https://api.elevenlabs.io/v1/studio/projects/{project_id}/pronunciation-dictionaries
Content-Type: application/json
```
Create a set of pronunciation dictionaries acting on a project. This will automatically mark text within this project as requiring reconverting where the new dictionary would apply or the old one no longer does.
## Path Parameters
- ProjectId (required): The ID of the project to be used. You can use the [List projects](/docs/api-reference/studio/get-projects) endpoint to list all the available projects.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"pronunciation_dictionary_locators": [
{
"pronunciation_dictionary_id": "pronunciation_dictionary_id",
"version_id": "version_id"
}
]
}'
```
```python
from elevenlabs import ElevenLabs, PronunciationDictionaryVersionLocator
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_pronunciation_dictionaries(
project_id="21m00Tcm4TlvDq8ikWAM",
pronunciation_dictionary_locators=[
PronunciationDictionaryVersionLocator(
pronunciation_dictionary_id="pronunciation_dictionary_id",
version_id="version_id",
)
],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updatePronunciationDictionaries("21m00Tcm4TlvDq8ikWAM", {
pronunciation_dictionary_locators: [{
pronunciation_dictionary_id: "pronunciation_dictionary_id",
version_id: "version_id"
}]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries"
payload := strings.NewReader("{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"pronunciation_dictionary_id\",\n      \"version_id\": \"version_id\"\n    }\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"pronunciation_dictionary_id\",\n      \"version_id\": \"version_id\"\n    }\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"pronunciation_dictionary_id\",\n      \"version_id\": \"version_id\"\n    }\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries', [
'body' => '{
"pronunciation_dictionary_locators": [
{
"pronunciation_dictionary_id": "pronunciation_dictionary_id",
"version_id": "version_id"
}
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"pronunciation_dictionary_id\",\n      \"version_id\": \"version_id\"\n    }\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["pronunciation_dictionary_locators": [
[
"pronunciation_dictionary_id": "pronunciation_dictionary_id",
"version_id": "version_id"
]
]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/pronunciation-dictionaries")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/projects/:project_id/pronunciation-dictionaries \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"pronunciation_dictionary_locators": [
{
"pronunciation_dictionary_id": "string",
"version_id": "string"
}
]
}'
```
```python
from elevenlabs import ElevenLabs, PronunciationDictionaryVersionLocator
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.update_pronunciation_dictionaries(
project_id="21m00Tcm4TlvDq8ikWAM",
pronunciation_dictionary_locators=[
PronunciationDictionaryVersionLocator(
pronunciation_dictionary_id="pronunciation_dictionary_id",
version_id="version_id",
)
],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.updatePronunciationDictionaries("21m00Tcm4TlvDq8ikWAM", {
pronunciation_dictionary_locators: [{
pronunciation_dictionary_id: "pronunciation_dictionary_id",
version_id: "version_id"
}]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries"
payload := strings.NewReader("{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"string\",\n      \"version_id\": \"string\"\n    }\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"string\",\n      \"version_id\": \"string\"\n    }\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"string\",\n      \"version_id\": \"string\"\n    }\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries', [
'body' => '{
"pronunciation_dictionary_locators": [
{
"pronunciation_dictionary_id": "string",
"version_id": "string"
}
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"pronunciation_dictionary_locators\": [\n    {\n      \"pronunciation_dictionary_id\": \"string\",\n      \"version_id\": \"string\"\n    }\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["pronunciation_dictionary_locators": [
[
"pronunciation_dictionary_id": "string",
"version_id": "string"
]
]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/pronunciation-dictionaries")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create Podcast
```http
POST https://api.elevenlabs.io/v1/studio/podcasts
Content-Type: application/json
```
Create and auto-convert a podcast project. Currently, the LLM cost is covered by us but you will still be charged for the audio generation. In the future, you will be charged for both the LLM and audio generation costs.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/podcasts \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"model_id": "21m00Tcm4TlvDq8ikWAM",
"mode": {
"type": "conversation",
"conversation": {
"host_voice_id": "aw1NgEzBg83R7vgmiJt6",
"guest_voice_id": "aw1NgEzBg83R7vgmiJt7"
}
},
"source": {
"text": "This is a test podcast."
}
}'
```
```python
from elevenlabs import (
ElevenLabs,
PodcastConversationModeData,
PodcastTextSource,
)
from elevenlabs.studio import (
BodyCreatePodcastV1StudioPodcastsPostMode_Conversation,
)
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.create_podcast(
model_id="21m00Tcm4TlvDq8ikWAM",
mode=BodyCreatePodcastV1StudioPodcastsPostMode_Conversation(
conversation=PodcastConversationModeData(
host_voice_id="aw1NgEzBg83R7vgmiJt6",
guest_voice_id="aw1NgEzBg83R7vgmiJt7",
),
),
source=PodcastTextSource(
text="This is a test podcast.",
),
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.createPodcast({
model_id: "21m00Tcm4TlvDq8ikWAM",
mode: {
type: "conversation",
conversation: {
host_voice_id: "aw1NgEzBg83R7vgmiJt6",
guest_voice_id: "aw1NgEzBg83R7vgmiJt7"
}
},
source: {
text: "This is a test podcast."
}
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/podcasts"
payload := strings.NewReader("{\n  \"model_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"aw1NgEzBg83R7vgmiJt6\",\n      \"guest_voice_id\": \"aw1NgEzBg83R7vgmiJt7\"\n    }\n  },\n  \"source\": {\n    \"text\": \"This is a test podcast.\"\n  }\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/podcasts")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"model_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"aw1NgEzBg83R7vgmiJt6\",\n      \"guest_voice_id\": \"aw1NgEzBg83R7vgmiJt7\"\n    }\n  },\n  \"source\": {\n    \"text\": \"This is a test podcast.\"\n  }\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/podcasts")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"model_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"aw1NgEzBg83R7vgmiJt6\",\n      \"guest_voice_id\": \"aw1NgEzBg83R7vgmiJt7\"\n    }\n  },\n  \"source\": {\n    \"text\": \"This is a test podcast.\"\n  }\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/podcasts', [
'body' => '{
"model_id": "21m00Tcm4TlvDq8ikWAM",
"mode": {
"type": "conversation",
"conversation": {
"host_voice_id": "aw1NgEzBg83R7vgmiJt6",
"guest_voice_id": "aw1NgEzBg83R7vgmiJt7"
}
},
"source": {
"text": "This is a test podcast."
}
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/podcasts");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"model_id\": \"21m00Tcm4TlvDq8ikWAM\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"aw1NgEzBg83R7vgmiJt6\",\n      \"guest_voice_id\": \"aw1NgEzBg83R7vgmiJt7\"\n    }\n  },\n  \"source\": {\n    \"text\": \"This is a test podcast.\"\n  }\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"model_id": "21m00Tcm4TlvDq8ikWAM",
"mode": [
"type": "conversation",
"conversation": [
"host_voice_id": "aw1NgEzBg83R7vgmiJt6",
"guest_voice_id": "aw1NgEzBg83R7vgmiJt7"
]
],
"source": ["text": "This is a test podcast."]
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/podcasts")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/studio/podcasts \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"model_id": "string",
"mode": {
"type": "conversation",
"conversation": {
"host_voice_id": "string",
"guest_voice_id": "string"
}
},
"source": {
"text": "string"
}
}'
```
```python
from elevenlabs import (
ElevenLabs,
PodcastConversationModeData,
PodcastTextSource,
)
from elevenlabs.studio import (
BodyCreatePodcastV1StudioPodcastsPostMode_Conversation,
)
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.create_podcast(
model_id="21m00Tcm4TlvDq8ikWAM",
mode=BodyCreatePodcastV1StudioPodcastsPostMode_Conversation(
conversation=PodcastConversationModeData(
host_voice_id="aw1NgEzBg83R7vgmiJt6",
guest_voice_id="aw1NgEzBg83R7vgmiJt7",
),
),
source=PodcastTextSource(
text="This is a test podcast.",
),
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.createPodcast({
model_id: "21m00Tcm4TlvDq8ikWAM",
mode: {
type: "conversation",
conversation: {
host_voice_id: "aw1NgEzBg83R7vgmiJt6",
guest_voice_id: "aw1NgEzBg83R7vgmiJt7"
}
},
source: {
text: "This is a test podcast."
}
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/podcasts"
payload := strings.NewReader("{\n  \"model_id\": \"string\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"string\",\n      \"guest_voice_id\": \"string\"\n    }\n  },\n  \"source\": {\n    \"text\": \"string\"\n  }\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/podcasts")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"model_id\": \"string\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"string\",\n      \"guest_voice_id\": \"string\"\n    }\n  },\n  \"source\": {\n    \"text\": \"string\"\n  }\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/studio/podcasts")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"model_id\": \"string\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"string\",\n      \"guest_voice_id\": \"string\"\n    }\n  },\n  \"source\": {\n    \"text\": \"string\"\n  }\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/studio/podcasts', [
'body' => '{
"model_id": "string",
"mode": {
"type": "conversation",
"conversation": {
"host_voice_id": "string",
"guest_voice_id": "string"
}
},
"source": {
"text": "string"
}
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/podcasts");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"model_id\": \"string\",\n  \"mode\": {\n    \"type\": \"conversation\",\n    \"conversation\": {\n      \"host_voice_id\": \"string\",\n      \"guest_voice_id\": \"string\"\n    }\n  },\n  \"source\": {\n    \"text\": \"string\"\n  }\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"model_id": "string",
"mode": [
"type": "conversation",
"conversation": [
"host_voice_id": "string",
"guest_voice_id": "string"
]
],
"source": ["text": "string"]
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/podcasts")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Chapter Snapshot
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/chapters/{chapter_id}/snapshots/{chapter_snapshot_id}
```
Returns the chapter snapshot.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
- ChapterId (required): The ID of the chapter.
- ChapterSnapshotId (required): The ID of the chapter snapshot.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_chapter_snapshot(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
chapter_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getChapterSnapshot("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/chapters/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/chapters/:chapter_id/snapshots/:chapter_snapshot_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.chapters.get_chapter_snapshot(
project_id="21m00Tcm4TlvDq8ikWAM",
chapter_id="21m00Tcm4TlvDq8ikWAM",
chapter_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.chapters.getChapterSnapshot("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/chapters/%3Achapter_id/snapshots/%3Achapter_snapshot_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Project Snapshot
```http
GET https://api.elevenlabs.io/v1/studio/projects/{project_id}/snapshots/{project_snapshot_id}
```
Returns the project snapshot.
## Path Parameters
- ProjectId (required): The ID of the Studio project.
- ProjectSnapshotId (required): The ID of the Studio project snapshot.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_project_snapshot(
project_id="21m00Tcm4TlvDq8ikWAM",
project_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getProjectSnapshot("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/21m00Tcm4TlvDq8ikWAM/snapshots/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/studio/projects/:project_id/snapshots/:project_snapshot_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.studio.projects.get_project_snapshot(
project_id="21m00Tcm4TlvDq8ikWAM",
project_snapshot_id="21m00Tcm4TlvDq8ikWAM",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.studio.projects.getProjectSnapshot("21m00Tcm4TlvDq8ikWAM", "21m00Tcm4TlvDq8ikWAM");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/studio/projects/%3Aproject_id/snapshots/%3Aproject_snapshot_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Create a pronunciation dictionary
```http
POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file
Content-Type: multipart/form-data
```
Creates a new pronunciation dictionary from a lexicon .PLS file
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="name"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.add_from_file(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.addFromFile({
name: "name"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file', [
'multipart' => [
[
'name' => 'name',
'contents' => '"name"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"name\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"name\""
],
[
"name": "file",
"value":
],
[
"name": "description",
"value":
],
[
"name": "workspace_access",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: multipart/form-data" \
-F name="string"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.add_from_file(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.addFromFile({
name: "name"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file"
payload := strings.NewReader("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'multipart/form-data; boundary=---011000010111000001101001'
request.body = "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "multipart/form-data; boundary=---011000010111000001101001")
.body("-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file', [
'multipart' => [
[
'name' => 'name',
'contents' => '"string"'
]
]
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddParameter("multipart/form-data; boundary=---011000010111000001101001", "-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"name\"\r\n\r\n\"string\"\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"file\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"description\"\r\n\r\n\r\n-----011000010111000001101001\r\nContent-Disposition: form-data; name=\"workspace_access\"\r\n\r\n\r\n-----011000010111000001101001--\r\n", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "multipart/form-data; boundary=---011000010111000001101001"
]
let parameters = [
[
"name": "name",
"value": "\"string\""
],
[
"name": "file",
"value":
],
[
"name": "description",
"value":
],
[
"name": "workspace_access",
"value":
]
]
let boundary = "---011000010111000001101001"
var body = ""
var error: NSError? = nil
for param in parameters {
let paramName = param["name"]!
body += "--\(boundary)\r\n"
body += "Content-Disposition:form-data; name=\"\(paramName)\""
if let filename = param["fileName"] {
let contentType = param["content-type"]!
let fileContent = String(contentsOfFile: filename, encoding: String.Encoding.utf8)
if (error != nil) {
print(error as Any)
}
body += "; filename=\"\(filename)\"\r\n"
body += "Content-Type: \(contentType)\r\n\r\n"
body += fileContent
} else if let paramValue = param["value"] {
body += "\r\n\r\n\(paramValue)"
}
}
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/add-from-file")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Add pronunciation dictionary rules
```http
POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/{pronunciation_dictionary_id}/add-rules
Content-Type: application/json
```
Add rules to the pronunciation dictionary
## Path Parameters
- PronunciationDictionaryId (required): The id of the pronunciation dictionary
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"rules": [
{
"type": "alias",
"alias": "tie-land",
"string_to_replace": "Thailand"
}
]
}'
```
```python
from elevenlabs import ElevenLabs
from elevenlabs.pronunciation_dictionary import (
PronunciationDictionaryRule_Alias,
)
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.add_rules(
pronunciation_dictionary_id="21m00Tcm4TlvDq8ikWAM",
rules=[
PronunciationDictionaryRule_Alias(
string_to_replace="Thailand",
alias="tie-land",
)
],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.addRules("21m00Tcm4TlvDq8ikWAM", {
rules: [{
type: "alias",
string_to_replace: "Thailand",
alias: "tie-land"
}]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules"
payload := strings.NewReader("{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"tie-land\",\n      \"string_to_replace\": \"Thailand\"\n    }\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"tie-land\",\n      \"string_to_replace\": \"Thailand\"\n    }\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"tie-land\",\n      \"string_to_replace\": \"Thailand\"\n    }\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules', [
'body' => '{
"rules": [
{
"type": "alias",
"alias": "tie-land",
"string_to_replace": "Thailand"
}
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"tie-land\",\n      \"string_to_replace\": \"Thailand\"\n    }\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["rules": [
[
"type": "alias",
"alias": "tie-land",
"string_to_replace": "Thailand"
]
]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/add-rules")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/:pronunciation_dictionary_id/add-rules \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"rules": [
{
"type": "alias",
"alias": "string",
"string_to_replace": "string"
}
]
}'
```
```python
from elevenlabs import ElevenLabs
from elevenlabs.pronunciation_dictionary import (
PronunciationDictionaryRule_Alias,
)
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.add_rules(
pronunciation_dictionary_id="21m00Tcm4TlvDq8ikWAM",
rules=[
PronunciationDictionaryRule_Alias(
string_to_replace="Thailand",
alias="tie-land",
)
],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.addRules("21m00Tcm4TlvDq8ikWAM", {
rules: [{
type: "alias",
string_to_replace: "Thailand",
alias: "tie-land"
}]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules"
payload := strings.NewReader("{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"string\",\n      \"string_to_replace\": \"string\"\n    }\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"string\",\n      \"string_to_replace\": \"string\"\n    }\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"string\",\n      \"string_to_replace\": \"string\"\n    }\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules', [
'body' => '{
"rules": [
{
"type": "alias",
"alias": "string",
"string_to_replace": "string"
}
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"rules\": [\n    {\n      \"type\": \"alias\",\n      \"alias\": \"string\",\n      \"string_to_replace\": \"string\"\n    }\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["rules": [
[
"type": "alias",
"alias": "string",
"string_to_replace": "string"
]
]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/add-rules")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Remove pronunciation dictionary rules
```http
POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/{pronunciation_dictionary_id}/remove-rules
Content-Type: application/json
```
Remove rules from the pronunciation dictionary
## Path Parameters
- PronunciationDictionaryId (required): The id of the pronunciation dictionary
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"rule_strings": [
"rule_strings"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.remove_rules(
pronunciation_dictionary_id="21m00Tcm4TlvDq8ikWAM",
rule_strings=["rule_strings"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.removeRules("21m00Tcm4TlvDq8ikWAM", {
rule_strings: ["rule_strings"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules"
payload := strings.NewReader("{\n  \"rule_strings\": [\n    \"rule_strings\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"rule_strings\": [\n    \"rule_strings\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"rule_strings\": [\n    \"rule_strings\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules', [
'body' => '{
"rule_strings": [
"rule_strings"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"rule_strings\": [\n    \"rule_strings\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["rule_strings": ["rule_strings"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/remove-rules")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/pronunciation-dictionaries/:pronunciation_dictionary_id/remove-rules \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"rule_strings": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.remove_rules(
pronunciation_dictionary_id="21m00Tcm4TlvDq8ikWAM",
rule_strings=["rule_strings"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.removeRules("21m00Tcm4TlvDq8ikWAM", {
rule_strings: ["rule_strings"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules"
payload := strings.NewReader("{\n  \"rule_strings\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"rule_strings\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"rule_strings\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules', [
'body' => '{
"rule_strings": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"rule_strings\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["rule_strings": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/remove-rules")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get pronunciation dictionary by version
```http
GET https://api.elevenlabs.io/v1/pronunciation-dictionaries/{dictionary_id}/{version_id}/download
```
Get a PLS file with a pronunciation dictionary version rules
## Path Parameters
- DictionaryId (required): The id of the pronunciation dictionary
- VersionId (required): The id of the version of the pronunciation dictionary
## Response Body
- 200: The PLS file containing pronunciation dictionary rules
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.download(
dictionary_id="Fm6AvNgS53NXe6Kqxp3e",
version_id="KZFyRUq3R6kaqhKI146w",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.download("Fm6AvNgS53NXe6Kqxp3e", "KZFyRUq3R6kaqhKI146w");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/dictionary_id/version_id/download")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/pronunciation-dictionaries/:dictionary_id/:version_id/download \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.download(
dictionary_id="Fm6AvNgS53NXe6Kqxp3e",
version_id="KZFyRUq3R6kaqhKI146w",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.download("Fm6AvNgS53NXe6Kqxp3e", "KZFyRUq3R6kaqhKI146w");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Adictionary_id/%3Aversion_id/download")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get pronunciation dictionary
```http
GET https://api.elevenlabs.io/v1/pronunciation-dictionaries/{pronunciation_dictionary_id}/
```
Get metadata for a pronunciation dictionary
## Path Parameters
- PronunciationDictionaryId (required): The id of the pronunciation dictionary
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/ \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.get(
pronunciation_dictionary_id="Fm6AvNgS53NXe6Kqxp3e",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.get("Fm6AvNgS53NXe6Kqxp3e");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/21m00Tcm4TlvDq8ikWAM/")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/pronunciation-dictionaries/:pronunciation_dictionary_id/ \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.get(
pronunciation_dictionary_id="Fm6AvNgS53NXe6Kqxp3e",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.get("Fm6AvNgS53NXe6Kqxp3e");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/%3Apronunciation_dictionary_id/")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# List pronunciation dictionaries
```http
GET https://api.elevenlabs.io/v1/pronunciation-dictionaries/
```
Get a list of the pronunciation dictionaries you have access to and their metadata
## Query Parameters
- Cursor (optional): Used for fetching next page. Cursor is returned in the response.
- PageSize (optional): How many pronunciation dictionaries to return at maximum. Can not exceed 100, defaults to 30.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/pronunciation-dictionaries/ \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.get_all(
page_size=1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.getAll({
page_size: 1
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/pronunciation-dictionaries/ \
-H "xi-api-key: <apiKey>" \
-d cursor=string \
-d page_size=0
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.pronunciation_dictionary.get_all(
page_size=1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.pronunciationDictionary.getAll({
page_size: 1
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/pronunciation-dictionaries/?cursor=string&page_size=0")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete voice sample
```http
DELETE https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}
```
Removes a sample by its ID.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
- SampleId (required): ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.samples.delete(
voice_id="VOICE_ID",
sample_id="SAMPLE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.samples.delete("VOICE_ID", "SAMPLE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/21m00Tcm4TlvDq8ikWAM/samples/VW7YKqPnjY4h39yTbx2L")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/voices/:voice_id/samples/:sample_id \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.samples.delete(
voice_id="VOICE_ID",
sample_id="SAMPLE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.samples.delete("VOICE_ID", "SAMPLE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id"
req, _ := http.NewRequest("DELETE", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get audio from sample
```http
GET https://api.elevenlabs.io/v1/voices/{voice_id}/samples/{sample_id}/audio
```
Returns the audio corresponding to a sample attached to a voice.
## Path Parameters
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
- SampleId (required): ID of the sample to be used. You can use the [Get voices](/docs/api-reference/voices/get) endpoint list all the available samples for a voice.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.samples.get_audio(
voice_id="VOICE_ID",
sample_id="SAMPLE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.samples.getAudio("VOICE_ID", "SAMPLE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/voice_id/samples/sample_id/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/voices/:voice_id/samples/:sample_id/audio \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.samples.get_audio(
voice_id="VOICE_ID",
sample_id="SAMPLE_ID",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.samples.getAudio("VOICE_ID", "SAMPLE_ID");
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/%3Avoice_id/samples/%3Asample_id/audio")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get character usage metrics
```http
GET https://api.elevenlabs.io/v1/usage/character-stats
```
Returns the credit usage metrics for the current user or the entire workspace they are part of. The response will return a time axis with unix timestamps for each day and daily usage along that axis. The usage will be broken down by the specified breakdown type. For example, breakdown type "voice" will return the usage of each voice along the time axis.
## Query Parameters
- StartUnix (required): UTC Unix timestamp for the start of the usage window, in milliseconds. To include the first day of the window, the timestamp should be at 00:00:00 of that day.
- EndUnix (required): UTC Unix timestamp for the end of the usage window, in milliseconds. To include the last day of the window, the timestamp should be at 23:59:59 of that day.
- IncludeWorkspaceMetrics (optional): Whether or not to include the statistics of the entire workspace.
- BreakdownType (optional): How to break down the information. Cannot be "user" if include_workspace_metrics is False.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -G https://api.elevenlabs.io/v1/usage/character-stats \
-H "xi-api-key: <apiKey>" \
-d start_unix=1 \
-d end_unix=1
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.usage.get_characters_usage_metrics(
start_unix=1,
end_unix=1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.usage.getCharactersUsageMetrics({
start_unix: 1,
end_unix: 1
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/usage/character-stats?start_unix=1&end_unix=1")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/usage/character-stats \
-H "xi-api-key: <apiKey>" \
-d start_unix=0 \
-d end_unix=0 \
-d include_workspace_metrics=true \
-d breakdown_type=none
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.usage.get_characters_usage_metrics(
start_unix=1,
end_unix=1,
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.usage.getCharactersUsageMetrics({
start_unix: 1,
end_unix: 1
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/usage/character-stats?start_unix=0&end_unix=0&include_workspace_metrics=true&breakdown_type=none")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get user subscription
```http
GET https://api.elevenlabs.io/v1/user/subscription
```
Gets extended information about the users subscription
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/user/subscription \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.user.get_subscription()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.user.getSubscription();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/user/subscription"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/user/subscription")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/user/subscription")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/user/subscription', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/user/subscription");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/user/subscription")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/user/subscription \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.user.get_subscription()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.user.getSubscription();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/user/subscription"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/user/subscription")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/user/subscription")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/user/subscription', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/user/subscription");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/user/subscription")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get user
```http
GET https://api.elevenlabs.io/v1/user
```
Gets information about the user
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl https://api.elevenlabs.io/v1/user \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.user.get()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.user.get();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/user"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/user")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/user")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/user', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/user");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/user")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl https://api.elevenlabs.io/v1/user \
-H "xi-api-key: <apiKey>"
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.user.get()
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.user.get();
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/user"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/user")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/user")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/user', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/user");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/user")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get shared voices
```http
GET https://api.elevenlabs.io/v1/shared-voices
```
Retrieves a list of shared voices.
## Query Parameters
- PageSize (optional): How many shared voices to return at maximum. Can not exceed 100, defaults to 30.
- Category (optional): Voice category used for filtering
- Gender (optional): Gender used for filtering
- Age (optional): Age used for filtering
- Accent (optional): Accent used for filtering
- Language (optional): Language used for filtering
- Search (optional): Search term used for filtering
- UseCases (optional): Use-case used for filtering
- Descriptives (optional): Search term used for filtering
- Featured (optional): Filter featured voices
- MinNoticePeriodDays (optional): Filter voices with a minimum notice period of the given number of days.
- ReaderAppEnabled (optional): Filter voices that are enabled for the reader app
- OwnerId (optional): Filter voices by public owner ID
- Sort (optional): Sort criteria
- Page (optional)
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -G https://api.elevenlabs.io/v1/shared-voices \
-H "xi-api-key: <apiKey>" \
-d featured=true \
-d reader_app_enabled=true
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_shared(
page_size=1,
gender="female",
language="en",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getShared({
page_size: 1,
gender: "female",
language: "en"
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/shared-voices?featured=true&reader_app_enabled=true")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/shared-voices \
-H "xi-api-key: <apiKey>" \
-d page_size=0 \
-d category=professional
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.get_shared(
page_size=1,
gender="female",
language="en",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.getShared({
page_size: 1,
gender: "female",
language: "en"
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/shared-voices?page_size=0&category=professional")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Add shared voice
```http
POST https://api.elevenlabs.io/v1/voices/add/{public_user_id}/{voice_id}
Content-Type: application/json
```
Add a shared voice to your collection of Voices
## Path Parameters
- PublicUserId (required): Public user ID used to publicly identify ElevenLabs users.
- VoiceId (required): ID of the voice to be used. You can use the [Get voices](/docs/api-reference/voices/get-all) endpoint list all the available voices.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"new_name": "John Smith"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.add_sharing_voice(
public_user_id="63e84100a6bf7874ba37a1bab9a31828a379ec94b891b401653b655c5110880f",
voice_id="sB1b5zUrxQVAFl2PhZFp",
new_name="Alita",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.addSharingVoice("63e84100a6bf7874ba37a1bab9a31828a379ec94b891b401653b655c5110880f", "sB1b5zUrxQVAFl2PhZFp", {
new_name: "Alita"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM"
payload := strings.NewReader("{\n  \"new_name\": \"John Smith\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"new_name\": \"John Smith\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"new_name\": \"John Smith\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM', [
'body' => '{
"new_name": "John Smith"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"new_name\": \"John Smith\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["new_name": "John Smith"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/add/63e06b7e7cafdc46be4d2e0b3f045940231ae058d508589653d74d1265a574ca/21m00Tcm4TlvDq8ikWAM")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/voices/add/:public_user_id/:voice_id \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"new_name": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.voices.add_sharing_voice(
public_user_id="63e84100a6bf7874ba37a1bab9a31828a379ec94b891b401653b655c5110880f",
voice_id="sB1b5zUrxQVAFl2PhZFp",
new_name="Alita",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.voices.addSharingVoice("63e84100a6bf7874ba37a1bab9a31828a379ec94b891b401653b655c5110880f", "sB1b5zUrxQVAFl2PhZFp", {
new_name: "Alita"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id"
payload := strings.NewReader("{\n  \"new_name\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"new_name\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"new_name\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id', [
'body' => '{
"new_name": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"new_name\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["new_name": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/voices/add/%3Apublic_user_id/%3Avoice_id")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Search user group
```http
GET https://api.elevenlabs.io/v1/workspace/groups/search
```
Searches for user groups in the workspace. Multiple or no groups may be returned.
## Query Parameters
- Name (required): Name of the target group.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -G https://api.elevenlabs.io/v1/workspace/groups/search \
-H "xi-api-key: <apiKey>" \
-d name=name
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.search_user_groups(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.searchUserGroups({
name: "name"
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/search?name=name"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/search?name=name")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/workspace/groups/search?name=name")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/workspace/groups/search?name=name', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/search?name=name");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/search?name=name")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/workspace/groups/search \
-H "xi-api-key: <apiKey>" \
-d name=string
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.search_user_groups(
name="name",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.searchUserGroups({
name: "name"
});
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/search?name=string"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/search?name=string")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/workspace/groups/search?name=string")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/workspace/groups/search?name=string', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/search?name=string");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/search?name=string")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Remove member from user group
```http
POST https://api.elevenlabs.io/v1/workspace/groups/{group_id}/members/remove
Content-Type: application/json
```
Removes a member from the specified group. This endpoint may only be called by workspace administrators.
## Path Parameters
- GroupId (required): The ID of the target group.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "email"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.delete_member_from_user_group(
group_id="group_id",
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.deleteMemberFromUserGroup("group_id", {
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove"
payload := strings.NewReader("{\n  \"email\": \"email\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"email\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"email\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove', [
'body' => '{
"email": "email"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"email\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "email"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/group_id/members/remove")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/groups/:group_id/members/remove \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.delete_member_from_user_group(
group_id="group_id",
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.deleteMemberFromUserGroup("group_id", {
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove"
payload := strings.NewReader("{\n  \"email\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove', [
'body' => '{
"email": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members/remove")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Add member to user group
```http
POST https://api.elevenlabs.io/v1/workspace/groups/{group_id}/members
Content-Type: application/json
```
Adds a member of your workspace to the specified group. This endpoint may only be called by workspace administrators.
## Path Parameters
- GroupId (required): The ID of the target group.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/groups/group_id/members \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "email"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.add_member_to_user_group(
group_id="group_id",
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.addMemberToUserGroup("group_id", {
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/group_id/members"
payload := strings.NewReader("{\n  \"email\": \"email\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/group_id/members")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"email\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/groups/group_id/members")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"email\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/groups/group_id/members', [
'body' => '{
"email": "email"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/group_id/members");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"email\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "email"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/group_id/members")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/groups/:group_id/members \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.add_member_to_user_group(
group_id="group_id",
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.addMemberToUserGroup("group_id", {
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members"
payload := strings.NewReader("{\n  \"email\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members', [
'body' => '{
"email": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/groups/%3Agroup_id/members")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Invite user
```http
POST https://api.elevenlabs.io/v1/workspace/invites/add
Content-Type: application/json
```
Sends an email invitation to join your workspace to the provided email. If the user doesn't have an account they will be prompted to create one. If the user accepts this invite they will be added as a user to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators. If the user is already in the workspace a 400 error will be returned.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/invites/add \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "john.doe@testmail.com"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.invite_user(
email="john.doe@testmail.com",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.inviteUser({
email: "john.doe@testmail.com"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites/add"
payload := strings.NewReader("{\n  \"email\": \"john.doe@testmail.com\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites/add")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"john.doe@testmail.com\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/invites/add")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"john.doe@testmail.com\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/invites/add', [
'body' => '{
"email": "john.doe@testmail.com"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites/add");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"john.doe@testmail.com\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "john.doe@testmail.com"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites/add")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/invites/add \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.invite_user(
email="john.doe@testmail.com",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.inviteUser({
email: "john.doe@testmail.com"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites/add"
payload := strings.NewReader("{\n  \"email\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites/add")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/invites/add")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/invites/add', [
'body' => '{
"email": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites/add");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites/add")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Invite Multiple Users
```http
POST https://api.elevenlabs.io/v1/workspace/invites/add-bulk
Content-Type: application/json
```
Sends email invitations to join your workspace to the provided emails. Requires all email addresses to be part of a verified domain. If the users don't have an account they will be prompted to create one. If the users accept these invites they will be added as users to your workspace and your subscription using one of your seats. This endpoint may only be called by workspace administrators.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/invites/add-bulk \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"emails": [
"emails"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.invite_multiple_users(
emails=["emails"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.inviteMultipleUsers({
emails: ["emails"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites/add-bulk"
payload := strings.NewReader("{\n  \"emails\": [\n    \"emails\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites/add-bulk")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"emails\": [\n    \"emails\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/invites/add-bulk")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"emails\": [\n    \"emails\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/invites/add-bulk', [
'body' => '{
"emails": [
"emails"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites/add-bulk");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"emails\": [\n    \"emails\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["emails": ["emails"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites/add-bulk")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/invites/add-bulk \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"emails": [
"string"
]
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.invite_multiple_users(
emails=["emails"],
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.inviteMultipleUsers({
emails: ["emails"]
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites/add-bulk"
payload := strings.NewReader("{\n  \"emails\": [\n    \"string\"\n  ]\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites/add-bulk")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"emails\": [\n    \"string\"\n  ]\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/invites/add-bulk")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"emails\": [\n    \"string\"\n  ]\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/invites/add-bulk', [
'body' => '{
"emails": [
"string"
]
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites/add-bulk");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"emails\": [\n    \"string\"\n  ]\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["emails": ["string"]] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites/add-bulk")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Delete invite
```http
DELETE https://api.elevenlabs.io/v1/workspace/invites
Content-Type: application/json
```
Invalidates an existing email invitation. The invitation will still show up in the inbox it has been delivered to, but activating it to join the workspace won't work. This endpoint may only be called by workspace administrators.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X DELETE https://api.elevenlabs.io/v1/workspace/invites \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "john.doe@testmail.com"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.delete_existing_invitation(
email="john.doe@testmail.com",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.deleteExistingInvitation({
email: "john.doe@testmail.com"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites"
payload := strings.NewReader("{\n  \"email\": \"john.doe@testmail.com\"\n}")
req, _ := http.NewRequest("DELETE", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"john.doe@testmail.com\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/workspace/invites")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"john.doe@testmail.com\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/workspace/invites', [
'body' => '{
"email": "john.doe@testmail.com"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"john.doe@testmail.com\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "john.doe@testmail.com"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X DELETE https://api.elevenlabs.io/v1/workspace/invites \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.delete_existing_invitation(
email="john.doe@testmail.com",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.deleteExistingInvitation({
email: "john.doe@testmail.com"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/invites"
payload := strings.NewReader("{\n  \"email\": \"string\"\n}")
req, _ := http.NewRequest("DELETE", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/invites")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Delete.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.delete("https://api.elevenlabs.io/v1/workspace/invites")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('DELETE', 'https://api.elevenlabs.io/v1/workspace/invites', [
'body' => '{
"email": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/invites");
var request = new RestRequest(Method.DELETE);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/invites")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "DELETE"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Update member
```http
POST https://api.elevenlabs.io/v1/workspace/members
Content-Type: application/json
```
Updates attributes of a workspace member. Apart from the email identifier, all parameters will remain unchanged unless specified. This endpoint may only be called by workspace administrators.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/members \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "email"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.update_member(
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.updateMember({
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/members"
payload := strings.NewReader("{\n  \"email\": \"email\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/members")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"email\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/members")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"email\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/members', [
'body' => '{
"email": "email"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/members");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"email\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "email"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/members")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/members \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"email": "string"
}'
```
```python
from elevenlabs import ElevenLabs
client = ElevenLabs(
api_key="YOUR_API_KEY",
)
client.workspace.update_member(
email="email",
)
```
```typescript
import { ElevenLabsClient } from "elevenlabs";
const client = new ElevenLabsClient({ apiKey: "YOUR_API_KEY" });
await client.workspace.updateMember({
email: "email"
});
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/members"
payload := strings.NewReader("{\n  \"email\": \"string\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/members")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"email\": \"string\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/members")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"email\": \"string\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/members', [
'body' => '{
"email": "string"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/members");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"email\": \"string\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["email": "string"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/members")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Get Resource
```http
GET https://api.elevenlabs.io/v1/workspace/resources/{resource_id}
```
Gets the metadata of a resource by ID.
## Path Parameters
- ResourceId (required): The ID of the target resource.
## Query Parameters
- ResourceType (required): Resource type of the target resource.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -G https://api.elevenlabs.io/v1/workspace/resources/resource_id \
-H "xi-api-key: <apiKey>" \
-d resource_type=voice
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/resource_id"
querystring = {"resource_type":"voice"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/resource_id?resource_type=voice")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -G https://api.elevenlabs.io/v1/workspace/resources/:resource_id \
-H "xi-api-key: <apiKey>" \
-d resource_type=voice
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id"
querystring = {"resource_type":"voice"}
headers = {"xi-api-key": "<apiKey>"}
response = requests.get(url, headers=headers, params=querystring)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice';
const options = {method: 'GET', headers: {'xi-api-key': '<apiKey>'}};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice"
req, _ := http.NewRequest("GET", url, nil)
req.Header.Add("xi-api-key", "<apiKey>")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Get.new(url)
request["xi-api-key"] = '<apiKey>'
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.get("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice")
.header("xi-api-key", "<apiKey>")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('GET', 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice', [
'headers' => [
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice");
var request = new RestRequest(Method.GET);
request.AddHeader("xi-api-key", "<apiKey>");
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = ["xi-api-key": "<apiKey>"]
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id?resource_type=voice")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "GET"
request.allHTTPHeaderFields = headers
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Share Workspace Resource
```http
POST https://api.elevenlabs.io/v1/workspace/resources/{resource_id}/share
Content-Type: application/json
```
Grants a role on a workspace resource to a user or a group. It overrides any existing role this user/group has on the resource. To target a user, pass only the user email. To target a group, pass only the group id. The user must be in your workspace. You must have admin access to the resource to share it.
## Path Parameters
- ResourceId (required): The ID of the target resource.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/resources/resource_id/share \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"role": "admin",
"resource_type": "voice"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/resource_id/share"
payload = {
"role": "admin",
"resource_type": "voice"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/resource_id/share';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"role":"admin","resource_type":"voice"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/resource_id/share"
payload := strings.NewReader("{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/resource_id/share")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/resources/resource_id/share")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/resources/resource_id/share', [
'body' => '{
"role": "admin",
"resource_type": "voice"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/resource_id/share");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"role": "admin",
"resource_type": "voice"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/resource_id/share")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/resources/:resource_id/share \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"role": "admin",
"resource_type": "voice"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share"
payload = {
"role": "admin",
"resource_type": "voice"
}
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"role":"admin","resource_type":"voice"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share"
payload := strings.NewReader("{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share', [
'body' => '{
"role": "admin",
"resource_type": "voice"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"role\": \"admin\",\n  \"resource_type\": \"voice\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = [
"role": "admin",
"resource_type": "voice"
] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/share")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
# Unshare Workspace Resource
```http
POST https://api.elevenlabs.io/v1/workspace/resources/{resource_id}/unshare
Content-Type: application/json
```
Removes any existing role on a workspace resource from a user or a group. To target a user, pass only the user email. To target a group, pass only the group id. The user must be in your workspace. You must have admin access to the resource to unshare it. You cannot remove permissions from the user who created the resource.
## Path Parameters
- ResourceId (required): The ID of the target resource.
## Response Body
- 200: Successful Response
- 422: Validation Error
## Examples
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"resource_type": "voice"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare"
payload = { "resource_type": "voice" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"resource_type":"voice"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare"
payload := strings.NewReader("{\n  \"resource_type\": \"voice\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"resource_type\": \"voice\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"resource_type\": \"voice\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare', [
'body' => '{
"resource_type": "voice"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"resource_type\": \"voice\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["resource_type": "voice"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/resource_id/unshare")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```
```shell
curl -X POST https://api.elevenlabs.io/v1/workspace/resources/:resource_id/unshare \
-H "xi-api-key: <apiKey>" \
-H "Content-Type: application/json" \
-d '{
"resource_type": "voice"
}'
```
```python
import requests
url = "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare"
payload = { "resource_type": "voice" }
headers = {
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
}
response = requests.post(url, json=payload, headers=headers)
print(response.json())
```
```javascript
const url = 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare';
const options = {
method: 'POST',
headers: {'xi-api-key': '<apiKey>', 'Content-Type': 'application/json'},
body: '{"resource_type":"voice"}'
};
try {
const response = await fetch(url, options);
const data = await response.json();
console.log(data);
} catch (error) {
console.error(error);
}
```
```go
package main
import (
"fmt"
"strings"
"net/http"
"io"
)
func main() {
url := "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare"
payload := strings.NewReader("{\n  \"resource_type\": \"voice\"\n}")
req, _ := http.NewRequest("POST", url, payload)
req.Header.Add("xi-api-key", "<apiKey>")
req.Header.Add("Content-Type", "application/json")
res, _ := http.DefaultClient.Do(req)
defer res.Body.Close()
body, _ := io.ReadAll(res.Body)
fmt.Println(res)
fmt.Println(string(body))
}
```
```ruby
require 'uri'
require 'net/http'
url = URI("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare")
http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true
request = Net::HTTP::Post.new(url)
request["xi-api-key"] = '<apiKey>'
request["Content-Type"] = 'application/json'
request.body = "{\n  \"resource_type\": \"voice\"\n}"
response = http.request(request)
puts response.read_body
```
```java
HttpResponse<String> response = Unirest.post("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare")
.header("xi-api-key", "<apiKey>")
.header("Content-Type", "application/json")
.body("{\n  \"resource_type\": \"voice\"\n}")
.asString();
```
```php
<?php
$client = new \GuzzleHttp\Client();
$response = $client->request('POST', 'https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare', [
'body' => '{
"resource_type": "voice"
}',
'headers' => [
'Content-Type' => 'application/json',
'xi-api-key' => '<apiKey>',
],
]);
echo $response->getBody();
```
```csharp
var client = new RestClient("https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare");
var request = new RestRequest(Method.POST);
request.AddHeader("xi-api-key", "<apiKey>");
request.AddHeader("Content-Type", "application/json");
request.AddParameter("application/json", "{\n  \"resource_type\": \"voice\"\n}", ParameterType.RequestBody);
IRestResponse response = client.Execute(request);
```
```swift
import Foundation
let headers = [
"xi-api-key": "<apiKey>",
"Content-Type": "application/json"
]
let parameters = ["resource_type": "voice"] as [String : Any]
let postData = JSONSerialization.data(withJSONObject: parameters, options: [])
let request = NSMutableURLRequest(url: NSURL(string: "https://api.elevenlabs.io/v1/workspace/resources/%3Aresource_id/unshare")! as URL,
cachePolicy: .useProtocolCachePolicy,
timeoutInterval: 10.0)
request.httpMethod = "POST"
request.allHTTPHeaderFields = headers
request.httpBody = postData as Data
let session = URLSession.shared
let dataTask = session.dataTask(with: request as URLRequest, completionHandler: { (data, response, error) -> Void in
if (error != nil) {
print(error as Any)
} else {
let httpResponse = response as? HTTPURLResponse
print(httpResponse)
}
})
dataTask.resume()
```